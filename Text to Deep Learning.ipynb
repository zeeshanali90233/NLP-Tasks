{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66b21568-2672-4bae-94c3-d9e705c0163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense,TimeDistributed,Dropout, BatchNormalization, LayerNormalization,Bidirectional\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2c96c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "qna_dataset=pd.read_csv(\"Network-QA-Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a1165b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        str_text=f.read().lower()\n",
    "    return str_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5070982b-caee-4a1f-9020-f25c49a622a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=read_file(\"./four_days.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "58020308-b0a3-4000-a88f-c9e622c34d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a4b859d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,  61,  62],\n",
       "       [  0,   0,   0, ...,  61,  62, 106],\n",
       "       [  0,   0,   0, ...,  62, 106,  63],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 105,  68,   4],\n",
       "       [  0,   0,   0, ...,  68,   4, 658],\n",
       "       [  0,   0,   0, ...,   4, 658, 659]], dtype=int32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create input sequences\n",
    "input_sequences = []\n",
    "\n",
    "for line in text.split(\"\\n\"):\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# Pad sequences\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "input_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "10c48a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into features and labels\n",
    "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
    "y = np.eye(total_words)[y]  # One-hot encode output\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "21ebe717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zeeshan Ali\\Desktop\\NLP Practice\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: Build the LSTM Model\n",
    "model = Sequential([\n",
    "    Embedding(total_words, 100, input_length=max_sequence_len-1),\n",
    "    LSTM(150, return_sequences=True),\n",
    "    LSTM(100),\n",
    "    Dense(total_words, activation='softmax')\n",
    "])\n",
    "\n",
    "model.build(input_shape=(None, max_sequence_len-1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "589b3de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">460</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">460</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,660</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_10 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m460\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │        \u001b[38;5;34m66,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_18 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m460\u001b[0m, \u001b[38;5;34m150\u001b[0m)       │       \u001b[38;5;34m150,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_19 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m100,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m660\u001b[0m)            │        \u001b[38;5;34m66,660\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">383,660</span> (1.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m383,660\u001b[0m (1.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">383,660</span> (1.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m383,660\u001b[0m (1.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "df2b983c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 453ms/step - accuracy: 0.0285 - loss: 6.3272\n",
      "Epoch 2/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 424ms/step - accuracy: 0.0517 - loss: 5.7003\n",
      "Epoch 3/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 430ms/step - accuracy: 0.0495 - loss: 5.6797\n",
      "Epoch 4/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 428ms/step - accuracy: 0.0465 - loss: 5.6827\n",
      "Epoch 5/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 432ms/step - accuracy: 0.0417 - loss: 5.6559\n",
      "Epoch 6/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 427ms/step - accuracy: 0.0445 - loss: 5.4884\n",
      "Epoch 7/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 433ms/step - accuracy: 0.0492 - loss: 5.3737\n",
      "Epoch 8/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 432ms/step - accuracy: 0.0624 - loss: 5.2711\n",
      "Epoch 9/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 430ms/step - accuracy: 0.0651 - loss: 5.1499\n",
      "Epoch 10/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 426ms/step - accuracy: 0.0566 - loss: 5.1448\n",
      "Epoch 11/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 429ms/step - accuracy: 0.0781 - loss: 4.9533\n",
      "Epoch 12/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 473ms/step - accuracy: 0.0699 - loss: 5.0000\n",
      "Epoch 13/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 490ms/step - accuracy: 0.0800 - loss: 4.8741\n",
      "Epoch 14/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 489ms/step - accuracy: 0.0850 - loss: 4.7843\n",
      "Epoch 15/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 546ms/step - accuracy: 0.0812 - loss: 4.7596\n",
      "Epoch 16/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 529ms/step - accuracy: 0.0731 - loss: 4.6584\n",
      "Epoch 17/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 499ms/step - accuracy: 0.0976 - loss: 4.5707\n",
      "Epoch 18/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 473ms/step - accuracy: 0.0833 - loss: 4.5574\n",
      "Epoch 19/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 456ms/step - accuracy: 0.0962 - loss: 4.4690\n",
      "Epoch 20/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 483ms/step - accuracy: 0.1019 - loss: 4.3362\n",
      "Epoch 21/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 484ms/step - accuracy: 0.0977 - loss: 4.3290\n",
      "Epoch 22/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 499ms/step - accuracy: 0.1034 - loss: 4.2650\n",
      "Epoch 23/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 484ms/step - accuracy: 0.1218 - loss: 4.2190\n",
      "Epoch 24/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 458ms/step - accuracy: 0.1203 - loss: 4.1430\n",
      "Epoch 25/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 442ms/step - accuracy: 0.1234 - loss: 4.0816\n",
      "Epoch 26/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 449ms/step - accuracy: 0.1335 - loss: 4.0549\n",
      "Epoch 27/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 457ms/step - accuracy: 0.1289 - loss: 4.0061\n",
      "Epoch 28/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 453ms/step - accuracy: 0.1510 - loss: 3.8775\n",
      "Epoch 29/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 452ms/step - accuracy: 0.1409 - loss: 3.9033\n",
      "Epoch 30/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 443ms/step - accuracy: 0.1704 - loss: 3.7529\n",
      "Epoch 31/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 454ms/step - accuracy: 0.1642 - loss: 3.7595\n",
      "Epoch 32/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 471ms/step - accuracy: 0.1863 - loss: 3.6819\n",
      "Epoch 33/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 492ms/step - accuracy: 0.1965 - loss: 3.5750\n",
      "Epoch 34/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 480ms/step - accuracy: 0.2001 - loss: 3.4893\n",
      "Epoch 35/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 453ms/step - accuracy: 0.2052 - loss: 3.4887\n",
      "Epoch 36/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 488ms/step - accuracy: 0.2343 - loss: 3.3701\n",
      "Epoch 37/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 457ms/step - accuracy: 0.2392 - loss: 3.3164\n",
      "Epoch 38/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 478ms/step - accuracy: 0.2695 - loss: 3.2705\n",
      "Epoch 39/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 505ms/step - accuracy: 0.2608 - loss: 3.2460\n",
      "Epoch 40/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 479ms/step - accuracy: 0.2748 - loss: 3.1882\n",
      "Epoch 41/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 490ms/step - accuracy: 0.3028 - loss: 3.0919\n",
      "Epoch 42/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 458ms/step - accuracy: 0.3138 - loss: 3.0107\n",
      "Epoch 43/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 480ms/step - accuracy: 0.3258 - loss: 2.9768\n",
      "Epoch 44/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 472ms/step - accuracy: 0.3388 - loss: 2.9504\n",
      "Epoch 45/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 438ms/step - accuracy: 0.3317 - loss: 2.9490\n",
      "Epoch 46/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 464ms/step - accuracy: 0.3692 - loss: 2.8550\n",
      "Epoch 47/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 432ms/step - accuracy: 0.3993 - loss: 2.7787\n",
      "Epoch 48/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 429ms/step - accuracy: 0.4184 - loss: 2.6777\n",
      "Epoch 49/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 429ms/step - accuracy: 0.4546 - loss: 2.6726\n",
      "Epoch 50/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 431ms/step - accuracy: 0.4509 - loss: 2.6122\n",
      "Epoch 51/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 428ms/step - accuracy: 0.4776 - loss: 2.5319\n",
      "Epoch 52/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 426ms/step - accuracy: 0.4800 - loss: 2.5043\n",
      "Epoch 53/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 431ms/step - accuracy: 0.4980 - loss: 2.3968\n",
      "Epoch 54/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 432ms/step - accuracy: 0.5400 - loss: 2.3486\n",
      "Epoch 55/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 437ms/step - accuracy: 0.5502 - loss: 2.3352\n",
      "Epoch 56/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 438ms/step - accuracy: 0.5350 - loss: 2.3135\n",
      "Epoch 57/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 437ms/step - accuracy: 0.5711 - loss: 2.2211\n",
      "Epoch 58/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 438ms/step - accuracy: 0.5794 - loss: 2.1749\n",
      "Epoch 59/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 431ms/step - accuracy: 0.5949 - loss: 2.1302\n",
      "Epoch 60/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 432ms/step - accuracy: 0.5886 - loss: 2.1345\n",
      "Epoch 61/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 431ms/step - accuracy: 0.6151 - loss: 2.0527\n",
      "Epoch 62/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 431ms/step - accuracy: 0.6610 - loss: 1.9491\n",
      "Epoch 63/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 430ms/step - accuracy: 0.6596 - loss: 1.8945\n",
      "Epoch 64/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 429ms/step - accuracy: 0.6972 - loss: 1.8388\n",
      "Epoch 65/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 429ms/step - accuracy: 0.7007 - loss: 1.8267\n",
      "Epoch 66/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 427ms/step - accuracy: 0.6946 - loss: 1.7638\n",
      "Epoch 67/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 428ms/step - accuracy: 0.6998 - loss: 1.7461\n",
      "Epoch 68/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 433ms/step - accuracy: 0.7219 - loss: 1.7182\n",
      "Epoch 69/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 443ms/step - accuracy: 0.7371 - loss: 1.6726\n",
      "Epoch 70/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 439ms/step - accuracy: 0.7529 - loss: 1.5949\n",
      "Epoch 71/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 443ms/step - accuracy: 0.7570 - loss: 1.5688\n",
      "Epoch 72/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 446ms/step - accuracy: 0.7660 - loss: 1.5120\n",
      "Epoch 73/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 439ms/step - accuracy: 0.7593 - loss: 1.5082\n",
      "Epoch 74/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 431ms/step - accuracy: 0.7670 - loss: 1.5097\n",
      "Epoch 75/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 433ms/step - accuracy: 0.7813 - loss: 1.4063\n",
      "Epoch 76/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 433ms/step - accuracy: 0.8161 - loss: 1.3239\n",
      "Epoch 77/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 432ms/step - accuracy: 0.8111 - loss: 1.3473\n",
      "Epoch 78/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 434ms/step - accuracy: 0.8174 - loss: 1.2945\n",
      "Epoch 79/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 431ms/step - accuracy: 0.8224 - loss: 1.2539\n",
      "Epoch 80/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 432ms/step - accuracy: 0.8322 - loss: 1.2269\n",
      "Epoch 81/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 431ms/step - accuracy: 0.8286 - loss: 1.2025\n",
      "Epoch 82/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 437ms/step - accuracy: 0.8525 - loss: 1.1631\n",
      "Epoch 83/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 433ms/step - accuracy: 0.8546 - loss: 1.1412\n",
      "Epoch 84/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 435ms/step - accuracy: 0.8647 - loss: 1.0982\n",
      "Epoch 85/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 435ms/step - accuracy: 0.8573 - loss: 1.0811\n",
      "Epoch 86/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 435ms/step - accuracy: 0.8694 - loss: 1.0390\n",
      "Epoch 87/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 436ms/step - accuracy: 0.8663 - loss: 1.0235\n",
      "Epoch 88/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 433ms/step - accuracy: 0.8908 - loss: 0.9783\n",
      "Epoch 89/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 434ms/step - accuracy: 0.8722 - loss: 0.9577\n",
      "Epoch 90/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 436ms/step - accuracy: 0.8862 - loss: 0.9254\n",
      "Epoch 91/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 436ms/step - accuracy: 0.8964 - loss: 0.8908\n",
      "Epoch 92/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 431ms/step - accuracy: 0.8883 - loss: 0.8960\n",
      "Epoch 93/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 432ms/step - accuracy: 0.9053 - loss: 0.8466\n",
      "Epoch 94/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 434ms/step - accuracy: 0.8964 - loss: 0.8311\n",
      "Epoch 95/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 428ms/step - accuracy: 0.9183 - loss: 0.7926\n",
      "Epoch 96/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 437ms/step - accuracy: 0.9308 - loss: 0.7671\n",
      "Epoch 97/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 434ms/step - accuracy: 0.9268 - loss: 0.7370\n",
      "Epoch 98/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 430ms/step - accuracy: 0.9303 - loss: 0.7148\n",
      "Epoch 99/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 430ms/step - accuracy: 0.9292 - loss: 0.6907\n",
      "Epoch 100/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 434ms/step - accuracy: 0.9393 - loss: 0.6542\n",
      "Epoch 101/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 429ms/step - accuracy: 0.9400 - loss: 0.6482\n",
      "Epoch 102/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 428ms/step - accuracy: 0.9432 - loss: 0.6589\n",
      "Epoch 103/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 446ms/step - accuracy: 0.9403 - loss: 0.6239\n",
      "Epoch 104/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 445ms/step - accuracy: 0.9362 - loss: 0.6067\n",
      "Epoch 105/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 437ms/step - accuracy: 0.9509 - loss: 0.5767\n",
      "Epoch 106/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 429ms/step - accuracy: 0.9432 - loss: 0.5746\n",
      "Epoch 107/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 426ms/step - accuracy: 0.9519 - loss: 0.5478\n",
      "Epoch 108/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 427ms/step - accuracy: 0.9702 - loss: 0.5210\n",
      "Epoch 109/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 428ms/step - accuracy: 0.9656 - loss: 0.5142\n",
      "Epoch 110/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 432ms/step - accuracy: 0.9590 - loss: 0.4986\n",
      "Epoch 111/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 429ms/step - accuracy: 0.9606 - loss: 0.4822\n",
      "Epoch 112/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 430ms/step - accuracy: 0.9693 - loss: 0.4662\n",
      "Epoch 113/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 428ms/step - accuracy: 0.9604 - loss: 0.4584\n",
      "Epoch 114/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 427ms/step - accuracy: 0.9735 - loss: 0.4517\n",
      "Epoch 115/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 428ms/step - accuracy: 0.9788 - loss: 0.4185\n",
      "Epoch 116/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 429ms/step - accuracy: 0.9745 - loss: 0.4022\n",
      "Epoch 117/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 430ms/step - accuracy: 0.9827 - loss: 0.4098\n",
      "Epoch 118/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 443ms/step - accuracy: 0.9812 - loss: 0.3708\n",
      "Epoch 119/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 517ms/step - accuracy: 0.9763 - loss: 0.3713\n",
      "Epoch 120/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 463ms/step - accuracy: 0.9831 - loss: 0.3522\n",
      "Epoch 121/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 455ms/step - accuracy: 0.9830 - loss: 0.3572\n",
      "Epoch 122/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 459ms/step - accuracy: 0.9775 - loss: 0.3341\n",
      "Epoch 123/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 451ms/step - accuracy: 0.9878 - loss: 0.3206\n",
      "Epoch 124/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 457ms/step - accuracy: 0.9852 - loss: 0.3123\n",
      "Epoch 125/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 455ms/step - accuracy: 0.9867 - loss: 0.3029\n",
      "Epoch 126/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 463ms/step - accuracy: 0.9900 - loss: 0.2789\n",
      "Epoch 127/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 451ms/step - accuracy: 0.9877 - loss: 0.2830\n",
      "Epoch 128/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 446ms/step - accuracy: 0.9894 - loss: 0.2593\n",
      "Epoch 129/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 431ms/step - accuracy: 0.9871 - loss: 0.2684\n",
      "Epoch 130/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 431ms/step - accuracy: 0.9877 - loss: 0.2569\n",
      "Epoch 131/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 433ms/step - accuracy: 0.9936 - loss: 0.2402\n",
      "Epoch 132/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 431ms/step - accuracy: 0.9912 - loss: 0.2380\n",
      "Epoch 133/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 432ms/step - accuracy: 0.9942 - loss: 0.2226\n",
      "Epoch 134/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 437ms/step - accuracy: 0.9947 - loss: 0.2226\n",
      "Epoch 135/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 437ms/step - accuracy: 0.9950 - loss: 0.2079\n",
      "Epoch 136/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 440ms/step - accuracy: 0.9945 - loss: 0.2099\n",
      "Epoch 137/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 432ms/step - accuracy: 0.9964 - loss: 0.1896\n",
      "Epoch 138/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 437ms/step - accuracy: 0.9954 - loss: 0.1827\n",
      "Epoch 139/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 439ms/step - accuracy: 0.9949 - loss: 0.1833\n",
      "Epoch 140/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 431ms/step - accuracy: 0.9929 - loss: 0.1765\n",
      "Epoch 141/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 434ms/step - accuracy: 0.9983 - loss: 0.1659\n",
      "Epoch 142/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 433ms/step - accuracy: 0.9975 - loss: 0.1635\n",
      "Epoch 143/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 430ms/step - accuracy: 0.9968 - loss: 0.1564\n",
      "Epoch 144/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 428ms/step - accuracy: 0.9988 - loss: 0.1525\n",
      "Epoch 145/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 429ms/step - accuracy: 0.9987 - loss: 0.1438\n",
      "Epoch 146/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 434ms/step - accuracy: 0.9992 - loss: 0.1349\n",
      "Epoch 147/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 432ms/step - accuracy: 0.9987 - loss: 0.1361\n",
      "Epoch 148/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 435ms/step - accuracy: 0.9968 - loss: 0.1344\n",
      "Epoch 149/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 434ms/step - accuracy: 0.9990 - loss: 0.1277\n",
      "Epoch 150/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 430ms/step - accuracy: 0.9995 - loss: 0.1211\n",
      "Epoch 151/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 431ms/step - accuracy: 0.9973 - loss: 0.1224\n",
      "Epoch 152/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 432ms/step - accuracy: 1.0000 - loss: 0.1140\n",
      "Epoch 153/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 432ms/step - accuracy: 0.9999 - loss: 0.1095\n",
      "Epoch 154/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 434ms/step - accuracy: 0.9998 - loss: 0.1079\n",
      "Epoch 155/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 435ms/step - accuracy: 0.9991 - loss: 0.1059\n",
      "Epoch 156/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 439ms/step - accuracy: 0.9997 - loss: 0.0997\n",
      "Epoch 157/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 441ms/step - accuracy: 0.9994 - loss: 0.0971\n",
      "Epoch 158/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 439ms/step - accuracy: 0.9993 - loss: 0.0947\n",
      "Epoch 159/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 441ms/step - accuracy: 0.9991 - loss: 0.0944\n",
      "Epoch 160/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 438ms/step - accuracy: 0.9999 - loss: 0.0851\n",
      "Epoch 161/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 439ms/step - accuracy: 0.9996 - loss: 0.0782\n",
      "Epoch 162/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 439ms/step - accuracy: 0.9999 - loss: 0.0768\n",
      "Epoch 163/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 443ms/step - accuracy: 0.9993 - loss: 0.0774\n",
      "Epoch 164/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 435ms/step - accuracy: 0.9997 - loss: 0.0743\n",
      "Epoch 165/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 434ms/step - accuracy: 1.0000 - loss: 0.0749\n",
      "Epoch 166/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 435ms/step - accuracy: 0.9995 - loss: 0.0669\n",
      "Epoch 167/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 432ms/step - accuracy: 0.9998 - loss: 0.0658\n",
      "Epoch 168/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 430ms/step - accuracy: 1.0000 - loss: 0.0680\n",
      "Epoch 169/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 433ms/step - accuracy: 0.9998 - loss: 0.0620\n",
      "Epoch 170/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 432ms/step - accuracy: 1.0000 - loss: 0.0610\n",
      "Epoch 171/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 430ms/step - accuracy: 1.0000 - loss: 0.0589\n",
      "Epoch 172/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 432ms/step - accuracy: 1.0000 - loss: 0.0583\n",
      "Epoch 173/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 431ms/step - accuracy: 1.0000 - loss: 0.0567\n",
      "Epoch 174/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 433ms/step - accuracy: 1.0000 - loss: 0.0535\n",
      "Epoch 175/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 429ms/step - accuracy: 1.0000 - loss: 0.0509\n",
      "Epoch 176/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 434ms/step - accuracy: 1.0000 - loss: 0.0532\n",
      "Epoch 177/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 430ms/step - accuracy: 1.0000 - loss: 0.0489\n",
      "Epoch 178/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 433ms/step - accuracy: 1.0000 - loss: 0.0474\n",
      "Epoch 179/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 431ms/step - accuracy: 1.0000 - loss: 0.0452\n",
      "Epoch 180/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 432ms/step - accuracy: 1.0000 - loss: 0.0442\n",
      "Epoch 181/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 431ms/step - accuracy: 1.0000 - loss: 0.0428\n",
      "Epoch 182/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 432ms/step - accuracy: 1.0000 - loss: 0.0414\n",
      "Epoch 183/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 431ms/step - accuracy: 1.0000 - loss: 0.0418\n",
      "Epoch 184/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 433ms/step - accuracy: 1.0000 - loss: 0.0400\n",
      "Epoch 185/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 432ms/step - accuracy: 1.0000 - loss: 0.0380\n",
      "Epoch 186/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 428ms/step - accuracy: 1.0000 - loss: 0.0369\n",
      "Epoch 187/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 429ms/step - accuracy: 1.0000 - loss: 0.0360\n",
      "Epoch 188/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 427ms/step - accuracy: 1.0000 - loss: 0.0349\n",
      "Epoch 189/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 431ms/step - accuracy: 1.0000 - loss: 0.0342\n",
      "Epoch 190/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 434ms/step - accuracy: 1.0000 - loss: 0.0330\n",
      "Epoch 191/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 434ms/step - accuracy: 1.0000 - loss: 0.0319\n",
      "Epoch 192/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 435ms/step - accuracy: 1.0000 - loss: 0.0313\n",
      "Epoch 193/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 434ms/step - accuracy: 1.0000 - loss: 0.0302\n",
      "Epoch 194/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 432ms/step - accuracy: 1.0000 - loss: 0.0293\n",
      "Epoch 195/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 429ms/step - accuracy: 1.0000 - loss: 0.0275\n",
      "Epoch 196/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 437ms/step - accuracy: 1.0000 - loss: 0.0270\n",
      "Epoch 197/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 435ms/step - accuracy: 1.0000 - loss: 0.0260\n",
      "Epoch 198/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 432ms/step - accuracy: 1.0000 - loss: 0.0251\n",
      "Epoch 199/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 433ms/step - accuracy: 1.0000 - loss: 0.0249\n",
      "Epoch 200/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 435ms/step - accuracy: 1.0000 - loss: 0.0241\n",
      "Epoch 201/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 435ms/step - accuracy: 1.0000 - loss: 0.0238\n",
      "Epoch 202/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 432ms/step - accuracy: 1.0000 - loss: 0.0229\n",
      "Epoch 203/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 433ms/step - accuracy: 1.0000 - loss: 0.0218\n",
      "Epoch 204/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 430ms/step - accuracy: 1.0000 - loss: 0.0221\n",
      "Epoch 205/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 424ms/step - accuracy: 1.0000 - loss: 0.0210\n",
      "Epoch 206/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 426ms/step - accuracy: 1.0000 - loss: 0.0202\n",
      "Epoch 207/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 425ms/step - accuracy: 1.0000 - loss: 0.0197\n",
      "Epoch 208/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 429ms/step - accuracy: 1.0000 - loss: 0.0186\n",
      "Epoch 209/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 427ms/step - accuracy: 1.0000 - loss: 0.0186\n",
      "Epoch 210/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 426ms/step - accuracy: 1.0000 - loss: 0.0185\n",
      "Epoch 211/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 428ms/step - accuracy: 1.0000 - loss: 0.0173\n",
      "Epoch 212/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 425ms/step - accuracy: 1.0000 - loss: 0.0164\n",
      "Epoch 213/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 429ms/step - accuracy: 1.0000 - loss: 0.0160\n",
      "Epoch 214/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 428ms/step - accuracy: 1.0000 - loss: 0.0159\n",
      "Epoch 215/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 426ms/step - accuracy: 1.0000 - loss: 0.0156\n",
      "Epoch 216/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 429ms/step - accuracy: 1.0000 - loss: 0.0147\n",
      "Epoch 217/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 429ms/step - accuracy: 1.0000 - loss: 0.0147\n",
      "Epoch 218/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 431ms/step - accuracy: 1.0000 - loss: 0.0139\n",
      "Epoch 219/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 430ms/step - accuracy: 1.0000 - loss: 0.0139\n",
      "Epoch 220/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 431ms/step - accuracy: 1.0000 - loss: 0.0132\n",
      "Epoch 221/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 429ms/step - accuracy: 1.0000 - loss: 0.0133\n",
      "Epoch 222/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 429ms/step - accuracy: 1.0000 - loss: 0.0129\n",
      "Epoch 223/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 429ms/step - accuracy: 1.0000 - loss: 0.0123\n",
      "Epoch 224/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 428ms/step - accuracy: 1.0000 - loss: 0.0119\n",
      "Epoch 225/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 433ms/step - accuracy: 1.0000 - loss: 0.0114\n",
      "Epoch 226/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 428ms/step - accuracy: 1.0000 - loss: 0.0114\n",
      "Epoch 227/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 428ms/step - accuracy: 1.0000 - loss: 0.0111\n",
      "Epoch 228/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 438ms/step - accuracy: 1.0000 - loss: 0.0105\n",
      "Epoch 229/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 502ms/step - accuracy: 1.0000 - loss: 0.0104\n",
      "Epoch 230/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 460ms/step - accuracy: 1.0000 - loss: 0.0102\n",
      "Epoch 231/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 447ms/step - accuracy: 1.0000 - loss: 0.0096\n",
      "Epoch 232/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 438ms/step - accuracy: 1.0000 - loss: 0.0094\n",
      "Epoch 233/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 464ms/step - accuracy: 1.0000 - loss: 0.0092\n",
      "Epoch 234/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 443ms/step - accuracy: 1.0000 - loss: 0.0091\n",
      "Epoch 235/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 434ms/step - accuracy: 1.0000 - loss: 0.0086\n",
      "Epoch 236/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 441ms/step - accuracy: 1.0000 - loss: 0.0085\n",
      "Epoch 237/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 444ms/step - accuracy: 1.0000 - loss: 0.0082\n",
      "Epoch 238/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 444ms/step - accuracy: 1.0000 - loss: 0.0082\n",
      "Epoch 239/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 458ms/step - accuracy: 1.0000 - loss: 0.0077\n",
      "Epoch 240/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 455ms/step - accuracy: 1.0000 - loss: 0.0081\n",
      "Epoch 241/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 445ms/step - accuracy: 1.0000 - loss: 0.0075\n",
      "Epoch 242/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 469ms/step - accuracy: 1.0000 - loss: 0.0071\n",
      "Epoch 243/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 450ms/step - accuracy: 1.0000 - loss: 0.0068\n",
      "Epoch 244/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 445ms/step - accuracy: 1.0000 - loss: 0.0068\n",
      "Epoch 245/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 436ms/step - accuracy: 1.0000 - loss: 0.0065\n",
      "Epoch 246/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 438ms/step - accuracy: 1.0000 - loss: 0.0066\n",
      "Epoch 247/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 445ms/step - accuracy: 1.0000 - loss: 0.0063\n",
      "Epoch 248/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 432ms/step - accuracy: 1.0000 - loss: 0.0060\n",
      "Epoch 249/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 428ms/step - accuracy: 1.0000 - loss: 0.0061\n",
      "Epoch 250/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 428ms/step - accuracy: 1.0000 - loss: 0.0058\n",
      "Epoch 251/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 431ms/step - accuracy: 1.0000 - loss: 0.0058\n",
      "Epoch 252/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 428ms/step - accuracy: 1.0000 - loss: 0.0054\n",
      "Epoch 253/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 429ms/step - accuracy: 1.0000 - loss: 0.0053\n",
      "Epoch 254/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 430ms/step - accuracy: 1.0000 - loss: 0.0052\n",
      "Epoch 255/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 431ms/step - accuracy: 1.0000 - loss: 0.0050\n",
      "Epoch 256/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 429ms/step - accuracy: 1.0000 - loss: 0.0048\n",
      "Epoch 257/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 432ms/step - accuracy: 1.0000 - loss: 0.0047\n",
      "Epoch 258/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 427ms/step - accuracy: 1.0000 - loss: 0.0047\n",
      "Epoch 259/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 430ms/step - accuracy: 1.0000 - loss: 0.0044\n",
      "Epoch 260/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 429ms/step - accuracy: 1.0000 - loss: 0.0044\n",
      "Epoch 261/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 439ms/step - accuracy: 1.0000 - loss: 0.0043\n",
      "Epoch 262/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 437ms/step - accuracy: 1.0000 - loss: 0.0041\n",
      "Epoch 263/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 435ms/step - accuracy: 1.0000 - loss: 0.0041\n",
      "Epoch 264/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 448ms/step - accuracy: 1.0000 - loss: 0.0040\n",
      "Epoch 265/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 438ms/step - accuracy: 1.0000 - loss: 0.0038\n",
      "Epoch 266/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 451ms/step - accuracy: 1.0000 - loss: 0.0037\n",
      "Epoch 267/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 446ms/step - accuracy: 1.0000 - loss: 0.0037\n",
      "Epoch 268/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 442ms/step - accuracy: 1.0000 - loss: 0.0035\n",
      "Epoch 269/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 451ms/step - accuracy: 1.0000 - loss: 0.0034\n",
      "Epoch 270/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 438ms/step - accuracy: 1.0000 - loss: 0.0033\n",
      "Epoch 271/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 436ms/step - accuracy: 1.0000 - loss: 0.0033\n",
      "Epoch 272/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 434ms/step - accuracy: 1.0000 - loss: 0.0031\n",
      "Epoch 273/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 443ms/step - accuracy: 1.0000 - loss: 0.0031\n",
      "Epoch 274/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 439ms/step - accuracy: 1.0000 - loss: 0.0031\n",
      "Epoch 275/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 430ms/step - accuracy: 1.0000 - loss: 0.0029\n",
      "Epoch 276/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 431ms/step - accuracy: 1.0000 - loss: 0.0028\n",
      "Epoch 277/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 430ms/step - accuracy: 1.0000 - loss: 0.0028\n",
      "Epoch 278/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 431ms/step - accuracy: 1.0000 - loss: 0.0027\n",
      "Epoch 279/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 434ms/step - accuracy: 1.0000 - loss: 0.0026\n",
      "Epoch 280/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 434ms/step - accuracy: 1.0000 - loss: 0.0025\n",
      "Epoch 281/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 478ms/step - accuracy: 1.0000 - loss: 0.0025\n",
      "Epoch 282/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 454ms/step - accuracy: 1.0000 - loss: 0.0023\n",
      "Epoch 283/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 434ms/step - accuracy: 1.0000 - loss: 0.0023\n",
      "Epoch 284/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 438ms/step - accuracy: 1.0000 - loss: 0.0023\n",
      "Epoch 285/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 452ms/step - accuracy: 1.0000 - loss: 0.0022\n",
      "Epoch 286/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 441ms/step - accuracy: 1.0000 - loss: 0.0021\n",
      "Epoch 287/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 440ms/step - accuracy: 1.0000 - loss: 0.0021\n",
      "Epoch 288/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 431ms/step - accuracy: 1.0000 - loss: 0.0020\n",
      "Epoch 289/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 430ms/step - accuracy: 1.0000 - loss: 0.0020\n",
      "Epoch 290/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 431ms/step - accuracy: 1.0000 - loss: 0.0019\n",
      "Epoch 291/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 431ms/step - accuracy: 1.0000 - loss: 0.0020\n",
      "Epoch 292/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 427ms/step - accuracy: 1.0000 - loss: 0.0018\n",
      "Epoch 293/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 437ms/step - accuracy: 1.0000 - loss: 0.0018\n",
      "Epoch 294/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 427ms/step - accuracy: 1.0000 - loss: 0.0018\n",
      "Epoch 295/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 431ms/step - accuracy: 1.0000 - loss: 0.0017\n",
      "Epoch 296/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 441ms/step - accuracy: 1.0000 - loss: 0.0017\n",
      "Epoch 297/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 454ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 298/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 457ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 299/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 445ms/step - accuracy: 1.0000 - loss: 0.0015\n",
      "Epoch 300/300\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 442ms/step - accuracy: 0.9998 - loss: 0.0021\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Train the Model\n",
    "history=model.fit(X, y, epochs=300, verbose=1)\n",
    "\n",
    "model.save(\"model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e33acce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ad41227e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "The rest of his toilet was soon achieved and he\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Predict Next Tokens\n",
    "def predict_next_words(seed_text, num_words):\n",
    "    for _ in range(num_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "        output_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += ' ' + output_word\n",
    "    return seed_text\n",
    "\n",
    "# Example prediction\n",
    "print(predict_next_words(\"The rest of his toilet\", 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ccea6e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load QnA from JSON file\n",
    "with open(\"qna.json\", \"r\") as file:\n",
    "    qna=json.load(file)\n",
    "    qna_data = qna.get(\"QnA\")\n",
    "\n",
    "# Convert JSON to DataFrame\n",
    "df = pd.DataFrame(qna_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1808aed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who is Queequeg?</td>\n",
       "      <td>Queequeg is a character in the novel 'Moby-Dic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why did Queequeg hug the narrator during sleep?</td>\n",
       "      <td>Queequeg hugged the narrator in his sleep out ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the significance of the tattoo on Quee...</td>\n",
       "      <td>The tattoo on Queequeg's arm resembles a Creta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What does the patchwork counterpane symbolize?</td>\n",
       "      <td>The patchwork counterpane symbolizes diversity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How does the narrator feel upon waking up to Q...</td>\n",
       "      <td>The narrator feels a mixture of discomfort and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What childhood memory does the narrator recall...</td>\n",
       "      <td>The narrator recalls a memory of being punishe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What literary technique is used when describin...</td>\n",
       "      <td>The technique used is symbolism and metaphor. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What is the tone of the passage describing Que...</td>\n",
       "      <td>The tone is humorous and light-hearted, as the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Why does the narrator compare Queequeg to both...</td>\n",
       "      <td>The narrator sees Queequeg as being in a trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What does the narrator admire about Queequeg d...</td>\n",
       "      <td>The narrator admires Queequegâ€™s innate sense...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How does the author use humor in this passage?</td>\n",
       "      <td>Humor is used through the narratorâ€™s comical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What is Queequeg's reaction upon waking up?</td>\n",
       "      <td>Queequeg is initially confused and does not im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Why does the narrator feel uncomfortable when ...</td>\n",
       "      <td>The narrator feels uncomfortable due to the un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What does Queequeg use to shave his face?</td>\n",
       "      <td>Queequeg uses his harpoon to shave his face, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What theme does the relationship between Ishma...</td>\n",
       "      <td>Their relationship reflects themes of friendsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Why is the imagery of the labyrinth on Queeque...</td>\n",
       "      <td>The labyrinth symbolizes complexity, mystery, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>What does the story reveal about the narratorâ...</td>\n",
       "      <td>The narratorâ€™s perception of civilization is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Why does the narrator feel guilt when staring ...</td>\n",
       "      <td>The narrator feels guilty because he believes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What literary device is used when the narrator...</td>\n",
       "      <td>The literary device used is a **simile**, comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What does the narratorâ€™s memory of his stepm...</td>\n",
       "      <td>The memory indicates that the narratorâ€™s chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What is the significance of Queequeg wearing h...</td>\n",
       "      <td>This behavior reflects Queequegâ€™s struggle t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>What does the narrator learn from observing Qu...</td>\n",
       "      <td>The narrator learns to appreciate Queequegâ€™s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>What does the description of the morning routi...</td>\n",
       "      <td>It reveals Queequeg's sense of independence, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What does Queequegâ€™s politeness despite his ...</td>\n",
       "      <td>It symbolizes the complexity of human nature a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>How does the narratorâ€™s initial discomfort e...</td>\n",
       "      <td>The narratorâ€™s initial discomfort gradually ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0                                    Who is Queequeg?   \n",
       "1     Why did Queequeg hug the narrator during sleep?   \n",
       "2   What is the significance of the tattoo on Quee...   \n",
       "3      What does the patchwork counterpane symbolize?   \n",
       "4   How does the narrator feel upon waking up to Q...   \n",
       "5   What childhood memory does the narrator recall...   \n",
       "6   What literary technique is used when describin...   \n",
       "7   What is the tone of the passage describing Que...   \n",
       "8   Why does the narrator compare Queequeg to both...   \n",
       "9   What does the narrator admire about Queequeg d...   \n",
       "10     How does the author use humor in this passage?   \n",
       "11        What is Queequeg's reaction upon waking up?   \n",
       "12  Why does the narrator feel uncomfortable when ...   \n",
       "13          What does Queequeg use to shave his face?   \n",
       "14  What theme does the relationship between Ishma...   \n",
       "15  Why is the imagery of the labyrinth on Queeque...   \n",
       "16  What does the story reveal about the narratorâ...   \n",
       "17  Why does the narrator feel guilt when staring ...   \n",
       "18  What literary device is used when the narrator...   \n",
       "19  What does the narratorâ€™s memory of his stepm...   \n",
       "20  What is the significance of Queequeg wearing h...   \n",
       "21  What does the narrator learn from observing Qu...   \n",
       "22  What does the description of the morning routi...   \n",
       "23  What does Queequegâ€™s politeness despite his ...   \n",
       "24  How does the narratorâ€™s initial discomfort e...   \n",
       "\n",
       "                                               answer  \n",
       "0   Queequeg is a character in the novel 'Moby-Dic...  \n",
       "1   Queequeg hugged the narrator in his sleep out ...  \n",
       "2   The tattoo on Queequeg's arm resembles a Creta...  \n",
       "3   The patchwork counterpane symbolizes diversity...  \n",
       "4   The narrator feels a mixture of discomfort and...  \n",
       "5   The narrator recalls a memory of being punishe...  \n",
       "6   The technique used is symbolism and metaphor. ...  \n",
       "7   The tone is humorous and light-hearted, as the...  \n",
       "8   The narrator sees Queequeg as being in a trans...  \n",
       "9   The narrator admires Queequegâ€™s innate sense...  \n",
       "10  Humor is used through the narratorâ€™s comical...  \n",
       "11  Queequeg is initially confused and does not im...  \n",
       "12  The narrator feels uncomfortable due to the un...  \n",
       "13  Queequeg uses his harpoon to shave his face, s...  \n",
       "14  Their relationship reflects themes of friendsh...  \n",
       "15  The labyrinth symbolizes complexity, mystery, ...  \n",
       "16  The narratorâ€™s perception of civilization is...  \n",
       "17  The narrator feels guilty because he believes ...  \n",
       "18  The literary device used is a **simile**, comp...  \n",
       "19  The memory indicates that the narratorâ€™s chi...  \n",
       "20  This behavior reflects Queequegâ€™s struggle t...  \n",
       "21  The narrator learns to appreciate Queequegâ€™s...  \n",
       "22  It reveals Queequeg's sense of independence, p...  \n",
       "23  It symbolizes the complexity of human nature a...  \n",
       "24  The narratorâ€™s initial discomfort gradually ...  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cda3f9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Lowercase and remove special characters\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8ce1a78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['question'] = df['question'].apply(preprocess)\n",
    "df['answer'] = df['answer'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c003686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into training and validation sets\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameters\n",
    "max_words = 10000\n",
    "max_len = 100\n",
    "\n",
    "# Tokenizer for questions and answers\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(pd.concat([df['question'], df['answer']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "11f2ea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding and padding sequences\n",
    "X_train = pad_sequences(tokenizer.texts_to_sequences(train_df['question']), maxlen=max_len, padding='post')\n",
    "y_train = pad_sequences(tokenizer.texts_to_sequences(train_df['answer']), maxlen=max_len, padding='post')\n",
    "\n",
    "X_val = pad_sequences(tokenizer.texts_to_sequences(val_df['question']), maxlen=max_len, padding='post')\n",
    "y_val = pad_sequences(tokenizer.texts_to_sequences(val_df['answer']), maxlen=max_len, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "70a6978d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 313\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "418a1daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand dimensions to fit LSTM requirements\n",
    "y_train = np.expand_dims(y_train, -1)\n",
    "y_val = np.expand_dims(y_val, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "04d84333",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zeeshan Ali\\Desktop\\NLP Practice\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_17\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_17\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">80,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_4              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">313</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">40,377</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_18 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │        \u001b[38;5;34m80,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_35 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m525,312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_36 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m197,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_37 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_4              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m313\u001b[0m)        │        \u001b[38;5;34m40,377\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">900,665</span> (3.44 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m900,665\u001b[0m (3.44 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">900,665</span> (3.44 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m900,665\u001b[0m (3.44 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LSTM Model\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, 256, input_length=max_len),  # Increased embedding size\n",
    "    LSTM(256, return_sequences=True, dropout=0.3, recurrent_dropout=0.3),  # First LSTM layer\n",
    "    LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.3),  # Second LSTM layer\n",
    "    LSTM(64, return_sequences=True, dropout=0.3),  # Third LSTM layer\n",
    "    TimeDistributed(Dense(128, activation='relu')),  # Fully connected layer with time distribution\n",
    "    Dropout(0.4),  # Dropout after dense layer\n",
    "    TimeDistributed(Dense(vocab_size, activation='softmax'))  # Final output layer\n",
    "])\n",
    "\n",
    "\n",
    "model.build(input_shape=(None, max_len-1)) \n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4e87ca92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 5.0000e-04 - loss: 5.7439 - val_accuracy: 0.7720 - val_loss: 5.6983\n",
      "Epoch 2/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step - accuracy: 0.2675 - loss: 5.6956 - val_accuracy: 0.7720 - val_loss: 5.5569\n",
      "Epoch 3/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - accuracy: 0.5975 - loss: 5.5718 - val_accuracy: 0.7720 - val_loss: 5.3080\n",
      "Epoch 4/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - accuracy: 0.7010 - loss: 5.3796 - val_accuracy: 0.7720 - val_loss: 5.0831\n",
      "Epoch 5/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - accuracy: 0.7445 - loss: 5.1541 - val_accuracy: 0.7720 - val_loss: 4.8885\n",
      "Epoch 6/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step - accuracy: 0.7705 - loss: 4.9467 - val_accuracy: 0.7720 - val_loss: 4.6789\n",
      "Epoch 7/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step - accuracy: 0.7785 - loss: 4.7409 - val_accuracy: 0.7720 - val_loss: 4.4450\n",
      "Epoch 8/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - accuracy: 0.7815 - loss: 4.5261 - val_accuracy: 0.7720 - val_loss: 4.1954\n",
      "Epoch 9/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.7840 - loss: 4.2915 - val_accuracy: 0.7720 - val_loss: 3.9271\n",
      "Epoch 10/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step - accuracy: 0.7835 - loss: 4.0399 - val_accuracy: 0.7720 - val_loss: 3.6434\n",
      "Epoch 11/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.7840 - loss: 3.7189 - val_accuracy: 0.7720 - val_loss: 3.3416\n",
      "Epoch 12/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.7840 - loss: 3.4267 - val_accuracy: 0.7720 - val_loss: 3.0343\n",
      "Epoch 13/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 0.7840 - loss: 3.1223 - val_accuracy: 0.7720 - val_loss: 2.7284\n",
      "Epoch 14/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.7840 - loss: 2.8405 - val_accuracy: 0.7720 - val_loss: 2.4337\n",
      "Epoch 15/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.7840 - loss: 2.5595 - val_accuracy: 0.7720 - val_loss: 2.1676\n",
      "Epoch 16/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - accuracy: 0.7840 - loss: 2.2550 - val_accuracy: 0.7720 - val_loss: 1.9479\n",
      "Epoch 17/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.7840 - loss: 2.0614 - val_accuracy: 0.7720 - val_loss: 1.7884\n",
      "Epoch 18/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - accuracy: 0.7840 - loss: 1.8662 - val_accuracy: 0.7720 - val_loss: 1.6921\n",
      "Epoch 19/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - accuracy: 0.7840 - loss: 1.7337 - val_accuracy: 0.7720 - val_loss: 1.6474\n",
      "Epoch 20/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - accuracy: 0.7840 - loss: 1.6571 - val_accuracy: 0.7720 - val_loss: 1.6372\n",
      "Epoch 21/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - accuracy: 0.7840 - loss: 1.5899 - val_accuracy: 0.7720 - val_loss: 1.6443\n",
      "Epoch 22/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 0.7845 - loss: 1.5350 - val_accuracy: 0.7720 - val_loss: 1.6581\n",
      "Epoch 23/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - accuracy: 0.7845 - loss: 1.5362 - val_accuracy: 0.7740 - val_loss: 1.6770\n",
      "Epoch 24/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.7850 - loss: 1.5143 - val_accuracy: 0.7720 - val_loss: 1.6958\n",
      "Epoch 25/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step - accuracy: 0.7855 - loss: 1.5133 - val_accuracy: 0.7720 - val_loss: 1.7103\n",
      "Epoch 26/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - accuracy: 0.7860 - loss: 1.5129 - val_accuracy: 0.7720 - val_loss: 1.7177\n",
      "Epoch 27/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.7840 - loss: 1.4970 - val_accuracy: 0.7720 - val_loss: 1.7148\n",
      "Epoch 28/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.7850 - loss: 1.4749 - val_accuracy: 0.7720 - val_loss: 1.6973\n",
      "Epoch 29/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.7850 - loss: 1.4423 - val_accuracy: 0.7720 - val_loss: 1.6615\n",
      "Epoch 30/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.7835 - loss: 1.4257 - val_accuracy: 0.7720 - val_loss: 1.6173\n",
      "Epoch 31/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - accuracy: 0.7810 - loss: 1.4264 - val_accuracy: 0.7720 - val_loss: 1.6084\n",
      "Epoch 32/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - accuracy: 0.7650 - loss: 1.4634 - val_accuracy: 0.7740 - val_loss: 1.6031\n",
      "Epoch 33/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.7750 - loss: 1.4232 - val_accuracy: 0.7720 - val_loss: 1.6152\n",
      "Epoch 34/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 0.7780 - loss: 1.4188 - val_accuracy: 0.7720 - val_loss: 1.6260\n",
      "Epoch 35/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - accuracy: 0.7785 - loss: 1.4033 - val_accuracy: 0.7720 - val_loss: 1.6331\n",
      "Epoch 36/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - accuracy: 0.7845 - loss: 1.3974 - val_accuracy: 0.7720 - val_loss: 1.6315\n",
      "Epoch 37/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.7825 - loss: 1.3730 - val_accuracy: 0.7740 - val_loss: 1.6215\n",
      "Epoch 38/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.7855 - loss: 1.3672 - val_accuracy: 0.7740 - val_loss: 1.6057\n",
      "Epoch 39/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.7850 - loss: 1.3543 - val_accuracy: 0.7740 - val_loss: 1.5865\n",
      "Epoch 40/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.7895 - loss: 1.3233 - val_accuracy: 0.7760 - val_loss: 1.5680\n",
      "Epoch 41/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - accuracy: 0.7845 - loss: 1.3240 - val_accuracy: 0.7760 - val_loss: 1.5535\n",
      "Epoch 42/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.7830 - loss: 1.3220 - val_accuracy: 0.7760 - val_loss: 1.5423\n",
      "Epoch 43/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - accuracy: 0.7880 - loss: 1.3006 - val_accuracy: 0.7760 - val_loss: 1.5358\n",
      "Epoch 44/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.7860 - loss: 1.3013 - val_accuracy: 0.7760 - val_loss: 1.5349\n",
      "Epoch 45/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.7840 - loss: 1.2985 - val_accuracy: 0.7760 - val_loss: 1.5382\n",
      "Epoch 46/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.7885 - loss: 1.2869 - val_accuracy: 0.7760 - val_loss: 1.5446\n",
      "Epoch 47/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.7885 - loss: 1.2832 - val_accuracy: 0.7760 - val_loss: 1.5536\n",
      "Epoch 48/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.7895 - loss: 1.2747 - val_accuracy: 0.7780 - val_loss: 1.5630\n",
      "Epoch 49/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.7895 - loss: 1.2623 - val_accuracy: 0.7780 - val_loss: 1.5715\n",
      "Epoch 50/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - accuracy: 0.7900 - loss: 1.2587 - val_accuracy: 0.7780 - val_loss: 1.5785\n",
      "Epoch 51/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.7880 - loss: 1.2362 - val_accuracy: 0.7780 - val_loss: 1.5820\n",
      "Epoch 52/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.7890 - loss: 1.2363 - val_accuracy: 0.7780 - val_loss: 1.5818\n",
      "Epoch 53/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.7880 - loss: 1.2261 - val_accuracy: 0.7780 - val_loss: 1.5808\n",
      "Epoch 54/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - accuracy: 0.7880 - loss: 1.2130 - val_accuracy: 0.7780 - val_loss: 1.5784\n",
      "Epoch 55/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.7905 - loss: 1.2182 - val_accuracy: 0.7780 - val_loss: 1.5757\n",
      "Epoch 56/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - accuracy: 0.7925 - loss: 1.2045 - val_accuracy: 0.7780 - val_loss: 1.5744\n",
      "Epoch 57/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.7925 - loss: 1.2058 - val_accuracy: 0.7780 - val_loss: 1.5750\n",
      "Epoch 58/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.7910 - loss: 1.2055 - val_accuracy: 0.7760 - val_loss: 1.5781\n",
      "Epoch 59/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.7880 - loss: 1.1871 - val_accuracy: 0.7780 - val_loss: 1.5827\n",
      "Epoch 60/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.7910 - loss: 1.1816 - val_accuracy: 0.7800 - val_loss: 1.5896\n",
      "Epoch 61/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.7915 - loss: 1.1654 - val_accuracy: 0.7800 - val_loss: 1.5981\n",
      "Epoch 62/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.7930 - loss: 1.1859 - val_accuracy: 0.7780 - val_loss: 1.6083\n",
      "Epoch 63/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.7905 - loss: 1.1614 - val_accuracy: 0.7780 - val_loss: 1.6190\n",
      "Epoch 64/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - accuracy: 0.7925 - loss: 1.1609 - val_accuracy: 0.7780 - val_loss: 1.6288\n",
      "Epoch 65/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - accuracy: 0.7935 - loss: 1.1599 - val_accuracy: 0.7780 - val_loss: 1.6378\n",
      "Epoch 66/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step - accuracy: 0.7940 - loss: 1.1547 - val_accuracy: 0.7780 - val_loss: 1.6455\n",
      "Epoch 67/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - accuracy: 0.7935 - loss: 1.1461 - val_accuracy: 0.7780 - val_loss: 1.6515\n",
      "Epoch 68/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.7925 - loss: 1.1397 - val_accuracy: 0.7800 - val_loss: 1.6566\n",
      "Epoch 69/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - accuracy: 0.7945 - loss: 1.1309 - val_accuracy: 0.7800 - val_loss: 1.6607\n",
      "Epoch 70/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - accuracy: 0.7975 - loss: 1.1400 - val_accuracy: 0.7800 - val_loss: 1.6643\n",
      "Epoch 71/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - accuracy: 0.7955 - loss: 1.1422 - val_accuracy: 0.7820 - val_loss: 1.6682\n",
      "Epoch 72/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - accuracy: 0.7920 - loss: 1.1313 - val_accuracy: 0.7820 - val_loss: 1.6737\n",
      "Epoch 73/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - accuracy: 0.7925 - loss: 1.1259 - val_accuracy: 0.7820 - val_loss: 1.6800\n",
      "Epoch 74/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step - accuracy: 0.7910 - loss: 1.1287 - val_accuracy: 0.7820 - val_loss: 1.6869\n",
      "Epoch 75/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - accuracy: 0.7930 - loss: 1.1191 - val_accuracy: 0.7820 - val_loss: 1.6925\n",
      "Epoch 76/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - accuracy: 0.7970 - loss: 1.1413 - val_accuracy: 0.7820 - val_loss: 1.6982\n",
      "Epoch 77/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - accuracy: 0.7960 - loss: 1.1162 - val_accuracy: 0.7840 - val_loss: 1.7026\n",
      "Epoch 78/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - accuracy: 0.7925 - loss: 1.1210 - val_accuracy: 0.7840 - val_loss: 1.7054\n",
      "Epoch 79/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - accuracy: 0.7980 - loss: 1.1089 - val_accuracy: 0.7840 - val_loss: 1.7060\n",
      "Epoch 80/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - accuracy: 0.7950 - loss: 1.1115 - val_accuracy: 0.7840 - val_loss: 1.7076\n",
      "Epoch 81/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - accuracy: 0.7970 - loss: 1.1205 - val_accuracy: 0.7840 - val_loss: 1.7123\n",
      "Epoch 82/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.7930 - loss: 1.1177 - val_accuracy: 0.7840 - val_loss: 1.7137\n",
      "Epoch 83/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - accuracy: 0.7945 - loss: 1.1013 - val_accuracy: 0.7840 - val_loss: 1.7144\n",
      "Epoch 84/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 0.7965 - loss: 1.1019 - val_accuracy: 0.7840 - val_loss: 1.7163\n",
      "Epoch 85/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.7970 - loss: 1.0906 - val_accuracy: 0.7840 - val_loss: 1.7259\n",
      "Epoch 86/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.7955 - loss: 1.1039 - val_accuracy: 0.7840 - val_loss: 1.7352\n",
      "Epoch 87/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - accuracy: 0.7990 - loss: 1.0906 - val_accuracy: 0.7840 - val_loss: 1.7384\n",
      "Epoch 88/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - accuracy: 0.7960 - loss: 1.0920 - val_accuracy: 0.7840 - val_loss: 1.7402\n",
      "Epoch 89/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - accuracy: 0.8005 - loss: 1.0932 - val_accuracy: 0.7840 - val_loss: 1.7463\n",
      "Epoch 90/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.7950 - loss: 1.0857 - val_accuracy: 0.7840 - val_loss: 1.7533\n",
      "Epoch 91/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - accuracy: 0.7970 - loss: 1.0835 - val_accuracy: 0.7840 - val_loss: 1.7687\n",
      "Epoch 92/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step - accuracy: 0.7965 - loss: 1.0843 - val_accuracy: 0.7840 - val_loss: 1.7747\n",
      "Epoch 93/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580ms/step - accuracy: 0.7990 - loss: 1.0725 - val_accuracy: 0.7860 - val_loss: 1.7771\n",
      "Epoch 94/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465ms/step - accuracy: 0.7970 - loss: 1.0812 - val_accuracy: 0.7860 - val_loss: 1.7734\n",
      "Epoch 95/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step - accuracy: 0.7980 - loss: 1.0819 - val_accuracy: 0.7860 - val_loss: 1.7722\n",
      "Epoch 96/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - accuracy: 0.7985 - loss: 1.0685 - val_accuracy: 0.7840 - val_loss: 1.7782\n",
      "Epoch 97/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - accuracy: 0.7990 - loss: 1.0571 - val_accuracy: 0.7840 - val_loss: 1.7834\n",
      "Epoch 98/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - accuracy: 0.7960 - loss: 1.0650 - val_accuracy: 0.7820 - val_loss: 1.7927\n",
      "Epoch 99/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.7985 - loss: 1.0631 - val_accuracy: 0.7820 - val_loss: 1.8036\n",
      "Epoch 100/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - accuracy: 0.7980 - loss: 1.0547 - val_accuracy: 0.7820 - val_loss: 1.8049\n",
      "Epoch 101/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - accuracy: 0.7995 - loss: 1.0551 - val_accuracy: 0.7840 - val_loss: 1.8049\n",
      "Epoch 102/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 0.7950 - loss: 1.0522 - val_accuracy: 0.7840 - val_loss: 1.8112\n",
      "Epoch 103/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - accuracy: 0.7960 - loss: 1.0454 - val_accuracy: 0.7840 - val_loss: 1.8135\n",
      "Epoch 104/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.8030 - loss: 1.0437 - val_accuracy: 0.7820 - val_loss: 1.8200\n",
      "Epoch 105/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - accuracy: 0.7995 - loss: 1.0478 - val_accuracy: 0.7820 - val_loss: 1.8375\n",
      "Epoch 106/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - accuracy: 0.7990 - loss: 1.0422 - val_accuracy: 0.7820 - val_loss: 1.8361\n",
      "Epoch 107/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.7965 - loss: 1.0471 - val_accuracy: 0.7820 - val_loss: 1.8338\n",
      "Epoch 108/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 0.7960 - loss: 1.0370 - val_accuracy: 0.7820 - val_loss: 1.8436\n",
      "Epoch 109/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.7980 - loss: 1.0418 - val_accuracy: 0.7820 - val_loss: 1.8516\n",
      "Epoch 110/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - accuracy: 0.7985 - loss: 1.0411 - val_accuracy: 0.7800 - val_loss: 1.8477\n",
      "Epoch 111/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.7995 - loss: 1.0303 - val_accuracy: 0.7800 - val_loss: 1.8531\n",
      "Epoch 112/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - accuracy: 0.7970 - loss: 1.0267 - val_accuracy: 0.7800 - val_loss: 1.8714\n",
      "Epoch 113/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - accuracy: 0.7960 - loss: 1.0365 - val_accuracy: 0.7800 - val_loss: 1.8808\n",
      "Epoch 114/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - accuracy: 0.7980 - loss: 1.0246 - val_accuracy: 0.7820 - val_loss: 1.8697\n",
      "Epoch 115/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.8010 - loss: 1.0261 - val_accuracy: 0.7820 - val_loss: 1.8630\n",
      "Epoch 116/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.8015 - loss: 1.0337 - val_accuracy: 0.7820 - val_loss: 1.8755\n",
      "Epoch 117/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.7970 - loss: 1.0222 - val_accuracy: 0.7820 - val_loss: 1.8845\n",
      "Epoch 118/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - accuracy: 0.7985 - loss: 1.0232 - val_accuracy: 0.7820 - val_loss: 1.8838\n",
      "Epoch 119/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - accuracy: 0.8000 - loss: 1.0240 - val_accuracy: 0.7820 - val_loss: 1.8860\n",
      "Epoch 120/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.7985 - loss: 1.0118 - val_accuracy: 0.7820 - val_loss: 1.8962\n",
      "Epoch 121/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.8030 - loss: 1.0108 - val_accuracy: 0.7820 - val_loss: 1.9090\n",
      "Epoch 122/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 0.8000 - loss: 1.0285 - val_accuracy: 0.7820 - val_loss: 1.9004\n",
      "Epoch 123/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450ms/step - accuracy: 0.8010 - loss: 1.0040 - val_accuracy: 0.7820 - val_loss: 1.9034\n",
      "Epoch 124/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - accuracy: 0.8040 - loss: 1.0067 - val_accuracy: 0.7820 - val_loss: 1.9171\n",
      "Epoch 125/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.7990 - loss: 1.0163 - val_accuracy: 0.7820 - val_loss: 1.9360\n",
      "Epoch 126/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.8010 - loss: 1.0159 - val_accuracy: 0.7820 - val_loss: 1.9239\n",
      "Epoch 127/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.8005 - loss: 1.0106 - val_accuracy: 0.7820 - val_loss: 1.9113\n",
      "Epoch 128/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8000 - loss: 1.0059 - val_accuracy: 0.7820 - val_loss: 1.9197\n",
      "Epoch 129/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.8020 - loss: 0.9968 - val_accuracy: 0.7820 - val_loss: 1.9403\n",
      "Epoch 130/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.8015 - loss: 0.9993 - val_accuracy: 0.7820 - val_loss: 1.9490\n",
      "Epoch 131/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8000 - loss: 1.0032 - val_accuracy: 0.7820 - val_loss: 1.9369\n",
      "Epoch 132/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.7995 - loss: 1.0001 - val_accuracy: 0.7820 - val_loss: 1.9277\n",
      "Epoch 133/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.7965 - loss: 0.9946 - val_accuracy: 0.7820 - val_loss: 1.9396\n",
      "Epoch 134/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8000 - loss: 1.0000 - val_accuracy: 0.7820 - val_loss: 1.9472\n",
      "Epoch 135/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.8020 - loss: 0.9953 - val_accuracy: 0.7820 - val_loss: 1.9510\n",
      "Epoch 136/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.7985 - loss: 1.0007 - val_accuracy: 0.7820 - val_loss: 1.9523\n",
      "Epoch 137/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - accuracy: 0.8000 - loss: 1.0009 - val_accuracy: 0.7820 - val_loss: 1.9475\n",
      "Epoch 138/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.8000 - loss: 0.9971 - val_accuracy: 0.7820 - val_loss: 1.9458\n",
      "Epoch 139/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.8010 - loss: 0.9912 - val_accuracy: 0.7820 - val_loss: 1.9489\n",
      "Epoch 140/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8000 - loss: 0.9855 - val_accuracy: 0.7820 - val_loss: 1.9586\n",
      "Epoch 141/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.8015 - loss: 0.9883 - val_accuracy: 0.7820 - val_loss: 1.9705\n",
      "Epoch 142/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - accuracy: 0.7995 - loss: 0.9868 - val_accuracy: 0.7820 - val_loss: 1.9817\n",
      "Epoch 143/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 0.8020 - loss: 0.9907 - val_accuracy: 0.7820 - val_loss: 1.9689\n",
      "Epoch 144/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - accuracy: 0.8005 - loss: 0.9811 - val_accuracy: 0.7820 - val_loss: 1.9564\n",
      "Epoch 145/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.7985 - loss: 0.9958 - val_accuracy: 0.7820 - val_loss: 1.9557\n",
      "Epoch 146/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.7990 - loss: 0.9828 - val_accuracy: 0.7820 - val_loss: 1.9719\n",
      "Epoch 147/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.8035 - loss: 0.9853 - val_accuracy: 0.7820 - val_loss: 1.9933\n",
      "Epoch 148/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - accuracy: 0.8005 - loss: 0.9817 - val_accuracy: 0.7820 - val_loss: 1.9997\n",
      "Epoch 149/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 0.7995 - loss: 0.9947 - val_accuracy: 0.7820 - val_loss: 1.9766\n",
      "Epoch 150/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.8010 - loss: 0.9821 - val_accuracy: 0.7820 - val_loss: 1.9723\n",
      "Epoch 151/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.7990 - loss: 0.9869 - val_accuracy: 0.7820 - val_loss: 1.9784\n",
      "Epoch 152/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - accuracy: 0.8005 - loss: 0.9760 - val_accuracy: 0.7820 - val_loss: 1.9956\n",
      "Epoch 153/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.8015 - loss: 0.9792 - val_accuracy: 0.7820 - val_loss: 2.0103\n",
      "Epoch 154/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 0.8000 - loss: 0.9627 - val_accuracy: 0.7820 - val_loss: 2.0055\n",
      "Epoch 155/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.7985 - loss: 0.9659 - val_accuracy: 0.7820 - val_loss: 1.9912\n",
      "Epoch 156/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.8015 - loss: 0.9642 - val_accuracy: 0.7820 - val_loss: 1.9802\n",
      "Epoch 157/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 0.8015 - loss: 0.9865 - val_accuracy: 0.7820 - val_loss: 1.9846\n",
      "Epoch 158/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.8020 - loss: 0.9718 - val_accuracy: 0.7820 - val_loss: 1.9985\n",
      "Epoch 159/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8030 - loss: 0.9669 - val_accuracy: 0.7820 - val_loss: 2.0175\n",
      "Epoch 160/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.7985 - loss: 0.9978 - val_accuracy: 0.7820 - val_loss: 2.0038\n",
      "Epoch 161/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 0.7990 - loss: 0.9684 - val_accuracy: 0.7820 - val_loss: 1.9884\n",
      "Epoch 162/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - accuracy: 0.8015 - loss: 0.9705 - val_accuracy: 0.7820 - val_loss: 1.9888\n",
      "Epoch 163/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.7995 - loss: 0.9620 - val_accuracy: 0.7820 - val_loss: 1.9926\n",
      "Epoch 164/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.8010 - loss: 0.9643 - val_accuracy: 0.7800 - val_loss: 2.0038\n",
      "Epoch 165/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.8000 - loss: 0.9589 - val_accuracy: 0.7800 - val_loss: 2.0253\n",
      "Epoch 166/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.8005 - loss: 0.9703 - val_accuracy: 0.7800 - val_loss: 2.0334\n",
      "Epoch 167/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.8015 - loss: 0.9660 - val_accuracy: 0.7800 - val_loss: 2.0204\n",
      "Epoch 168/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - accuracy: 0.8020 - loss: 0.9568 - val_accuracy: 0.7800 - val_loss: 2.0124\n",
      "Epoch 169/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.8005 - loss: 0.9600 - val_accuracy: 0.7800 - val_loss: 2.0111\n",
      "Epoch 170/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.8040 - loss: 0.9556 - val_accuracy: 0.7800 - val_loss: 2.0163\n",
      "Epoch 171/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.8030 - loss: 0.9554 - val_accuracy: 0.7800 - val_loss: 2.0276\n",
      "Epoch 172/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.8025 - loss: 0.9567 - val_accuracy: 0.7800 - val_loss: 2.0305\n",
      "Epoch 173/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8020 - loss: 0.9509 - val_accuracy: 0.7800 - val_loss: 2.0201\n",
      "Epoch 174/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8055 - loss: 0.9533 - val_accuracy: 0.7800 - val_loss: 2.0121\n",
      "Epoch 175/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.8010 - loss: 0.9588 - val_accuracy: 0.7800 - val_loss: 2.0081\n",
      "Epoch 176/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.8005 - loss: 0.9572 - val_accuracy: 0.7800 - val_loss: 2.0148\n",
      "Epoch 177/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439ms/step - accuracy: 0.8050 - loss: 0.9452 - val_accuracy: 0.7800 - val_loss: 2.0322\n",
      "Epoch 178/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.8035 - loss: 0.9456 - val_accuracy: 0.7800 - val_loss: 2.0446\n",
      "Epoch 179/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 0.8005 - loss: 0.9551 - val_accuracy: 0.7800 - val_loss: 2.0410\n",
      "Epoch 180/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.7995 - loss: 0.9439 - val_accuracy: 0.7800 - val_loss: 2.0215\n",
      "Epoch 181/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.8040 - loss: 0.9475 - val_accuracy: 0.7820 - val_loss: 2.0188\n",
      "Epoch 182/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.8020 - loss: 0.9500 - val_accuracy: 0.7820 - val_loss: 2.0218\n",
      "Epoch 183/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.8005 - loss: 0.9373 - val_accuracy: 0.7820 - val_loss: 2.0329\n",
      "Epoch 184/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8040 - loss: 0.9400 - val_accuracy: 0.7800 - val_loss: 2.0492\n",
      "Epoch 185/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 0.8025 - loss: 0.9341 - val_accuracy: 0.7800 - val_loss: 2.0582\n",
      "Epoch 186/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8060 - loss: 0.9390 - val_accuracy: 0.7800 - val_loss: 2.0582\n",
      "Epoch 187/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8055 - loss: 0.9408 - val_accuracy: 0.7820 - val_loss: 2.0423\n",
      "Epoch 188/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8030 - loss: 0.9313 - val_accuracy: 0.7820 - val_loss: 2.0377\n",
      "Epoch 189/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.8020 - loss: 0.9318 - val_accuracy: 0.7820 - val_loss: 2.0408\n",
      "Epoch 190/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8010 - loss: 0.9310 - val_accuracy: 0.7820 - val_loss: 2.0496\n",
      "Epoch 191/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.8025 - loss: 0.9359 - val_accuracy: 0.7800 - val_loss: 2.0595\n",
      "Epoch 192/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - accuracy: 0.8000 - loss: 0.9293 - val_accuracy: 0.7800 - val_loss: 2.0703\n",
      "Epoch 193/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.8020 - loss: 0.9427 - val_accuracy: 0.7800 - val_loss: 2.0622\n",
      "Epoch 194/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.8020 - loss: 0.9274 - val_accuracy: 0.7800 - val_loss: 2.0600\n",
      "Epoch 195/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - accuracy: 0.8030 - loss: 0.9281 - val_accuracy: 0.7820 - val_loss: 2.0583\n",
      "Epoch 196/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8055 - loss: 0.9290 - val_accuracy: 0.7800 - val_loss: 2.0612\n",
      "Epoch 197/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8045 - loss: 0.9326 - val_accuracy: 0.7800 - val_loss: 2.0659\n",
      "Epoch 198/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.8035 - loss: 0.9260 - val_accuracy: 0.7800 - val_loss: 2.0701\n",
      "Epoch 199/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 0.8025 - loss: 0.9213 - val_accuracy: 0.7780 - val_loss: 2.0758\n",
      "Epoch 200/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.8060 - loss: 0.9217 - val_accuracy: 0.7780 - val_loss: 2.0727\n",
      "Epoch 201/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.7975 - loss: 0.9418 - val_accuracy: 0.7800 - val_loss: 2.0631\n",
      "Epoch 202/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.8020 - loss: 0.9269 - val_accuracy: 0.7800 - val_loss: 2.0586\n",
      "Epoch 203/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.8060 - loss: 0.9195 - val_accuracy: 0.7780 - val_loss: 2.0614\n",
      "Epoch 204/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8035 - loss: 0.9208 - val_accuracy: 0.7800 - val_loss: 2.0803\n",
      "Epoch 205/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - accuracy: 0.8020 - loss: 0.9257 - val_accuracy: 0.7800 - val_loss: 2.0994\n",
      "Epoch 206/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.8020 - loss: 0.9186 - val_accuracy: 0.7800 - val_loss: 2.1009\n",
      "Epoch 207/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.8035 - loss: 0.9164 - val_accuracy: 0.7800 - val_loss: 2.0790\n",
      "Epoch 208/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.8035 - loss: 0.9121 - val_accuracy: 0.7800 - val_loss: 2.0696\n",
      "Epoch 209/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - accuracy: 0.8040 - loss: 0.9171 - val_accuracy: 0.7800 - val_loss: 2.0673\n",
      "Epoch 210/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.8025 - loss: 0.9197 - val_accuracy: 0.7800 - val_loss: 2.0754\n",
      "Epoch 211/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8025 - loss: 0.9198 - val_accuracy: 0.7780 - val_loss: 2.0954\n",
      "Epoch 212/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 0.8020 - loss: 0.9205 - val_accuracy: 0.7780 - val_loss: 2.1058\n",
      "Epoch 213/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.8050 - loss: 0.9115 - val_accuracy: 0.7780 - val_loss: 2.0978\n",
      "Epoch 214/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - accuracy: 0.8065 - loss: 0.9034 - val_accuracy: 0.7800 - val_loss: 2.0881\n",
      "Epoch 215/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - accuracy: 0.8055 - loss: 0.8987 - val_accuracy: 0.7800 - val_loss: 2.0782\n",
      "Epoch 216/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - accuracy: 0.8025 - loss: 0.9226 - val_accuracy: 0.7800 - val_loss: 2.0787\n",
      "Epoch 217/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.8065 - loss: 0.9088 - val_accuracy: 0.7820 - val_loss: 2.0894\n",
      "Epoch 218/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8020 - loss: 0.9088 - val_accuracy: 0.7800 - val_loss: 2.0997\n",
      "Epoch 219/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.8045 - loss: 0.9008 - val_accuracy: 0.7800 - val_loss: 2.0981\n",
      "Epoch 220/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - accuracy: 0.8030 - loss: 0.9061 - val_accuracy: 0.7820 - val_loss: 2.0904\n",
      "Epoch 221/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8060 - loss: 0.8988 - val_accuracy: 0.7820 - val_loss: 2.0807\n",
      "Epoch 222/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - accuracy: 0.8065 - loss: 0.8956 - val_accuracy: 0.7820 - val_loss: 2.0811\n",
      "Epoch 223/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - accuracy: 0.8050 - loss: 0.9074 - val_accuracy: 0.7820 - val_loss: 2.0918\n",
      "Epoch 224/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580ms/step - accuracy: 0.8045 - loss: 0.8952 - val_accuracy: 0.7800 - val_loss: 2.1082\n",
      "Epoch 225/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step - accuracy: 0.8015 - loss: 0.9079 - val_accuracy: 0.7800 - val_loss: 2.1201\n",
      "Epoch 226/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - accuracy: 0.8010 - loss: 0.8996 - val_accuracy: 0.7820 - val_loss: 2.1116\n",
      "Epoch 227/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.8015 - loss: 0.8906 - val_accuracy: 0.7820 - val_loss: 2.1033\n",
      "Epoch 228/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8045 - loss: 0.8907 - val_accuracy: 0.7820 - val_loss: 2.0994\n",
      "Epoch 229/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8025 - loss: 0.8799 - val_accuracy: 0.7820 - val_loss: 2.1050\n",
      "Epoch 230/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8050 - loss: 0.8901 - val_accuracy: 0.7820 - val_loss: 2.1143\n",
      "Epoch 231/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.8035 - loss: 0.8910 - val_accuracy: 0.7820 - val_loss: 2.1239\n",
      "Epoch 232/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.8035 - loss: 0.8901 - val_accuracy: 0.7800 - val_loss: 2.1310\n",
      "Epoch 233/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.8030 - loss: 0.8791 - val_accuracy: 0.7800 - val_loss: 2.1368\n",
      "Epoch 234/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.8040 - loss: 0.8875 - val_accuracy: 0.7800 - val_loss: 2.1345\n",
      "Epoch 235/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - accuracy: 0.8025 - loss: 0.8825 - val_accuracy: 0.7800 - val_loss: 2.1301\n",
      "Epoch 236/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8090 - loss: 0.8763 - val_accuracy: 0.7820 - val_loss: 2.1247\n",
      "Epoch 237/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.8065 - loss: 0.8859 - val_accuracy: 0.7820 - val_loss: 2.1273\n",
      "Epoch 238/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 0.8010 - loss: 0.8952 - val_accuracy: 0.7820 - val_loss: 2.1382\n",
      "Epoch 239/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.8040 - loss: 0.8848 - val_accuracy: 0.7820 - val_loss: 2.1515\n",
      "Epoch 240/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 0.8045 - loss: 0.8914 - val_accuracy: 0.7800 - val_loss: 2.1509\n",
      "Epoch 241/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8015 - loss: 0.8863 - val_accuracy: 0.7800 - val_loss: 2.1504\n",
      "Epoch 242/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8060 - loss: 0.8706 - val_accuracy: 0.7820 - val_loss: 2.1464\n",
      "Epoch 243/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 0.8070 - loss: 0.8823 - val_accuracy: 0.7840 - val_loss: 2.1447\n",
      "Epoch 244/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.8015 - loss: 0.8860 - val_accuracy: 0.7820 - val_loss: 2.1507\n",
      "Epoch 245/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.8065 - loss: 0.8783 - val_accuracy: 0.7820 - val_loss: 2.1557\n",
      "Epoch 246/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 0.8035 - loss: 0.8708 - val_accuracy: 0.7820 - val_loss: 2.1509\n",
      "Epoch 247/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.8060 - loss: 0.8706 - val_accuracy: 0.7820 - val_loss: 2.1483\n",
      "Epoch 248/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - accuracy: 0.8040 - loss: 0.8706 - val_accuracy: 0.7840 - val_loss: 2.1476\n",
      "Epoch 249/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.8035 - loss: 0.8725 - val_accuracy: 0.7820 - val_loss: 2.1559\n",
      "Epoch 250/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.8025 - loss: 0.8725 - val_accuracy: 0.7840 - val_loss: 2.1585\n",
      "Epoch 251/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8050 - loss: 0.8711 - val_accuracy: 0.7840 - val_loss: 2.1564\n",
      "Epoch 252/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8035 - loss: 0.8644 - val_accuracy: 0.7840 - val_loss: 2.1561\n",
      "Epoch 253/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.8020 - loss: 0.8578 - val_accuracy: 0.7840 - val_loss: 2.1591\n",
      "Epoch 254/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 0.8040 - loss: 0.8652 - val_accuracy: 0.7860 - val_loss: 2.1650\n",
      "Epoch 255/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.8010 - loss: 0.8683 - val_accuracy: 0.7860 - val_loss: 2.1708\n",
      "Epoch 256/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - accuracy: 0.8070 - loss: 0.8654 - val_accuracy: 0.7860 - val_loss: 2.1701\n",
      "Epoch 257/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 0.8020 - loss: 0.8630 - val_accuracy: 0.7860 - val_loss: 2.1699\n",
      "Epoch 258/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.8025 - loss: 0.8618 - val_accuracy: 0.7860 - val_loss: 2.1735\n",
      "Epoch 259/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.8050 - loss: 0.8639 - val_accuracy: 0.7840 - val_loss: 2.1714\n",
      "Epoch 260/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8040 - loss: 0.8570 - val_accuracy: 0.7840 - val_loss: 2.1766\n",
      "Epoch 261/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 0.8045 - loss: 0.8523 - val_accuracy: 0.7840 - val_loss: 2.1831\n",
      "Epoch 262/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.8045 - loss: 0.8527 - val_accuracy: 0.7840 - val_loss: 2.1903\n",
      "Epoch 263/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.8050 - loss: 0.8646 - val_accuracy: 0.7840 - val_loss: 2.1812\n",
      "Epoch 264/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.8075 - loss: 0.8459 - val_accuracy: 0.7820 - val_loss: 2.1743\n",
      "Epoch 265/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - accuracy: 0.8085 - loss: 0.8546 - val_accuracy: 0.7860 - val_loss: 2.1794\n",
      "Epoch 266/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.8040 - loss: 0.8485 - val_accuracy: 0.7840 - val_loss: 2.1871\n",
      "Epoch 267/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8020 - loss: 0.8486 - val_accuracy: 0.7840 - val_loss: 2.1979\n",
      "Epoch 268/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.8040 - loss: 0.8424 - val_accuracy: 0.7820 - val_loss: 2.2072\n",
      "Epoch 269/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.8015 - loss: 0.8621 - val_accuracy: 0.7840 - val_loss: 2.1986\n",
      "Epoch 270/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8065 - loss: 0.8485 - val_accuracy: 0.7820 - val_loss: 2.1865\n",
      "Epoch 271/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8045 - loss: 0.8489 - val_accuracy: 0.7820 - val_loss: 2.1802\n",
      "Epoch 272/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - accuracy: 0.8055 - loss: 0.8491 - val_accuracy: 0.7820 - val_loss: 2.1862\n",
      "Epoch 273/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.8035 - loss: 0.8547 - val_accuracy: 0.7840 - val_loss: 2.2021\n",
      "Epoch 274/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - accuracy: 0.8075 - loss: 0.8415 - val_accuracy: 0.7840 - val_loss: 2.2125\n",
      "Epoch 275/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.8050 - loss: 0.8404 - val_accuracy: 0.7840 - val_loss: 2.2200\n",
      "Epoch 276/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.8010 - loss: 0.8486 - val_accuracy: 0.7840 - val_loss: 2.2133\n",
      "Epoch 277/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.8025 - loss: 0.8542 - val_accuracy: 0.7840 - val_loss: 2.2011\n",
      "Epoch 278/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.8055 - loss: 0.8337 - val_accuracy: 0.7860 - val_loss: 2.1927\n",
      "Epoch 279/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.8045 - loss: 0.8507 - val_accuracy: 0.7860 - val_loss: 2.1985\n",
      "Epoch 280/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8050 - loss: 0.8398 - val_accuracy: 0.7840 - val_loss: 2.2164\n",
      "Epoch 281/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8070 - loss: 0.8414 - val_accuracy: 0.7840 - val_loss: 2.2341\n",
      "Epoch 282/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 0.8045 - loss: 0.8470 - val_accuracy: 0.7840 - val_loss: 2.2240\n",
      "Epoch 283/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 0.8045 - loss: 0.8453 - val_accuracy: 0.7820 - val_loss: 2.2036\n",
      "Epoch 284/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.8035 - loss: 0.8420 - val_accuracy: 0.7800 - val_loss: 2.1998\n",
      "Epoch 285/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - accuracy: 0.8035 - loss: 0.8619 - val_accuracy: 0.7840 - val_loss: 2.2086\n",
      "Epoch 286/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - accuracy: 0.8085 - loss: 0.8369 - val_accuracy: 0.7840 - val_loss: 2.2317\n",
      "Epoch 287/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - accuracy: 0.8065 - loss: 0.8246 - val_accuracy: 0.7820 - val_loss: 2.2530\n",
      "Epoch 288/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.8020 - loss: 0.8542 - val_accuracy: 0.7860 - val_loss: 2.2427\n",
      "Epoch 289/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - accuracy: 0.8045 - loss: 0.8434 - val_accuracy: 0.7880 - val_loss: 2.2206\n",
      "Epoch 290/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - accuracy: 0.8010 - loss: 0.8264 - val_accuracy: 0.7880 - val_loss: 2.2118\n",
      "Epoch 291/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - accuracy: 0.8045 - loss: 0.8354 - val_accuracy: 0.7860 - val_loss: 2.2118\n",
      "Epoch 292/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - accuracy: 0.8050 - loss: 0.8374 - val_accuracy: 0.7860 - val_loss: 2.2266\n",
      "Epoch 293/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.8030 - loss: 0.8369 - val_accuracy: 0.7860 - val_loss: 2.2556\n",
      "Epoch 294/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step - accuracy: 0.8040 - loss: 0.8288 - val_accuracy: 0.7860 - val_loss: 2.2619\n",
      "Epoch 295/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - accuracy: 0.8070 - loss: 0.8298 - val_accuracy: 0.7860 - val_loss: 2.2515\n",
      "Epoch 296/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - accuracy: 0.8020 - loss: 0.8252 - val_accuracy: 0.7860 - val_loss: 2.2343\n",
      "Epoch 297/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.8070 - loss: 0.8262 - val_accuracy: 0.7860 - val_loss: 2.2212\n",
      "Epoch 298/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - accuracy: 0.8070 - loss: 0.8274 - val_accuracy: 0.7880 - val_loss: 2.2224\n",
      "Epoch 299/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8075 - loss: 0.8392 - val_accuracy: 0.7880 - val_loss: 2.2339\n",
      "Epoch 300/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.8055 - loss: 0.8153 - val_accuracy: 0.7860 - val_loss: 2.2520\n",
      "Epoch 301/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - accuracy: 0.8070 - loss: 0.8237 - val_accuracy: 0.7860 - val_loss: 2.2610\n",
      "Epoch 302/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.8055 - loss: 0.8206 - val_accuracy: 0.7860 - val_loss: 2.2537\n",
      "Epoch 303/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - accuracy: 0.8025 - loss: 0.8259 - val_accuracy: 0.7860 - val_loss: 2.2416\n",
      "Epoch 304/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.8070 - loss: 0.8195 - val_accuracy: 0.7860 - val_loss: 2.2392\n",
      "Epoch 305/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 0.8075 - loss: 0.8143 - val_accuracy: 0.7860 - val_loss: 2.2452\n",
      "Epoch 306/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.8040 - loss: 0.8167 - val_accuracy: 0.7860 - val_loss: 2.2574\n",
      "Epoch 307/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - accuracy: 0.8055 - loss: 0.8180 - val_accuracy: 0.7860 - val_loss: 2.2750\n",
      "Epoch 308/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - accuracy: 0.8025 - loss: 0.8228 - val_accuracy: 0.7860 - val_loss: 2.2819\n",
      "Epoch 309/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.8020 - loss: 0.8223 - val_accuracy: 0.7860 - val_loss: 2.2745\n",
      "Epoch 310/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.8050 - loss: 0.8061 - val_accuracy: 0.7860 - val_loss: 2.2656\n",
      "Epoch 311/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.8065 - loss: 0.8090 - val_accuracy: 0.7860 - val_loss: 2.2612\n",
      "Epoch 312/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8070 - loss: 0.8096 - val_accuracy: 0.7860 - val_loss: 2.2600\n",
      "Epoch 313/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.8050 - loss: 0.8192 - val_accuracy: 0.7860 - val_loss: 2.2720\n",
      "Epoch 314/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.8075 - loss: 0.8130 - val_accuracy: 0.7860 - val_loss: 2.2841\n",
      "Epoch 315/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.8075 - loss: 0.8048 - val_accuracy: 0.7860 - val_loss: 2.2930\n",
      "Epoch 316/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.8090 - loss: 0.8044 - val_accuracy: 0.7860 - val_loss: 2.2881\n",
      "Epoch 317/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - accuracy: 0.8085 - loss: 0.8012 - val_accuracy: 0.7860 - val_loss: 2.2762\n",
      "Epoch 318/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - accuracy: 0.8090 - loss: 0.7972 - val_accuracy: 0.7860 - val_loss: 2.2705\n",
      "Epoch 319/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8055 - loss: 0.8122 - val_accuracy: 0.7860 - val_loss: 2.2716\n",
      "Epoch 320/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - accuracy: 0.8075 - loss: 0.7994 - val_accuracy: 0.7860 - val_loss: 2.2835\n",
      "Epoch 321/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.8040 - loss: 0.7997 - val_accuracy: 0.7860 - val_loss: 2.3033\n",
      "Epoch 322/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.8050 - loss: 0.7990 - val_accuracy: 0.7860 - val_loss: 2.3160\n",
      "Epoch 323/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - accuracy: 0.8100 - loss: 0.7929 - val_accuracy: 0.7840 - val_loss: 2.3196\n",
      "Epoch 324/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - accuracy: 0.8080 - loss: 0.8034 - val_accuracy: 0.7860 - val_loss: 2.3095\n",
      "Epoch 325/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.8085 - loss: 0.8023 - val_accuracy: 0.7860 - val_loss: 2.2956\n",
      "Epoch 326/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - accuracy: 0.8060 - loss: 0.8014 - val_accuracy: 0.7860 - val_loss: 2.2918\n",
      "Epoch 327/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - accuracy: 0.8110 - loss: 0.7959 - val_accuracy: 0.7860 - val_loss: 2.2945\n",
      "Epoch 328/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.8055 - loss: 0.7963 - val_accuracy: 0.7860 - val_loss: 2.2997\n",
      "Epoch 329/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.8060 - loss: 0.7973 - val_accuracy: 0.7860 - val_loss: 2.3070\n",
      "Epoch 330/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - accuracy: 0.8080 - loss: 0.7880 - val_accuracy: 0.7860 - val_loss: 2.3126\n",
      "Epoch 331/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8060 - loss: 0.7986 - val_accuracy: 0.7860 - val_loss: 2.3116\n",
      "Epoch 332/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.8110 - loss: 0.7898 - val_accuracy: 0.7860 - val_loss: 2.3145\n",
      "Epoch 333/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - accuracy: 0.8045 - loss: 0.7909 - val_accuracy: 0.7860 - val_loss: 2.3171\n",
      "Epoch 334/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - accuracy: 0.8090 - loss: 0.7841 - val_accuracy: 0.7860 - val_loss: 2.3181\n",
      "Epoch 335/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - accuracy: 0.8050 - loss: 0.7875 - val_accuracy: 0.7880 - val_loss: 2.3246\n",
      "Epoch 336/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - accuracy: 0.8115 - loss: 0.7878 - val_accuracy: 0.7880 - val_loss: 2.3316\n",
      "Epoch 337/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.8070 - loss: 0.7842 - val_accuracy: 0.7880 - val_loss: 2.3311\n",
      "Epoch 338/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - accuracy: 0.8050 - loss: 0.7794 - val_accuracy: 0.7880 - val_loss: 2.3317\n",
      "Epoch 339/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - accuracy: 0.8110 - loss: 0.7932 - val_accuracy: 0.7860 - val_loss: 2.3389\n",
      "Epoch 340/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - accuracy: 0.8090 - loss: 0.7874 - val_accuracy: 0.7860 - val_loss: 2.3368\n",
      "Epoch 341/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - accuracy: 0.8030 - loss: 0.7824 - val_accuracy: 0.7860 - val_loss: 2.3357\n",
      "Epoch 342/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.8095 - loss: 0.7856 - val_accuracy: 0.7860 - val_loss: 2.3376\n",
      "Epoch 343/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - accuracy: 0.8060 - loss: 0.7924 - val_accuracy: 0.7860 - val_loss: 2.3436\n",
      "Epoch 344/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.8060 - loss: 0.7877 - val_accuracy: 0.7860 - val_loss: 2.3551\n",
      "Epoch 345/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.8070 - loss: 0.7826 - val_accuracy: 0.7860 - val_loss: 2.3600\n",
      "Epoch 346/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - accuracy: 0.8090 - loss: 0.7938 - val_accuracy: 0.7880 - val_loss: 2.3519\n",
      "Epoch 347/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.8085 - loss: 0.7785 - val_accuracy: 0.7880 - val_loss: 2.3406\n",
      "Epoch 348/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - accuracy: 0.8060 - loss: 0.7763 - val_accuracy: 0.7880 - val_loss: 2.3398\n",
      "Epoch 349/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 0.8070 - loss: 0.7824 - val_accuracy: 0.7880 - val_loss: 2.3492\n",
      "Epoch 350/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - accuracy: 0.8070 - loss: 0.7758 - val_accuracy: 0.7860 - val_loss: 2.3650\n",
      "Epoch 351/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.8060 - loss: 0.7770 - val_accuracy: 0.7860 - val_loss: 2.3770\n",
      "Epoch 352/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.8110 - loss: 0.7713 - val_accuracy: 0.7860 - val_loss: 2.3760\n",
      "Epoch 353/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.8070 - loss: 0.7868 - val_accuracy: 0.7860 - val_loss: 2.3554\n",
      "Epoch 354/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 0.8065 - loss: 0.7727 - val_accuracy: 0.7860 - val_loss: 2.3392\n",
      "Epoch 355/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8055 - loss: 0.7778 - val_accuracy: 0.7860 - val_loss: 2.3362\n",
      "Epoch 356/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8070 - loss: 0.7885 - val_accuracy: 0.7860 - val_loss: 2.3480\n",
      "Epoch 357/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.8080 - loss: 0.7706 - val_accuracy: 0.7860 - val_loss: 2.3730\n",
      "Epoch 358/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 0.8065 - loss: 0.7742 - val_accuracy: 0.7860 - val_loss: 2.3842\n",
      "Epoch 359/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - accuracy: 0.8035 - loss: 0.7744 - val_accuracy: 0.7860 - val_loss: 2.3786\n",
      "Epoch 360/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - accuracy: 0.8080 - loss: 0.7853 - val_accuracy: 0.7860 - val_loss: 2.3552\n",
      "Epoch 361/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - accuracy: 0.8125 - loss: 0.7521 - val_accuracy: 0.7840 - val_loss: 2.3434\n",
      "Epoch 362/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - accuracy: 0.8070 - loss: 0.7807 - val_accuracy: 0.7820 - val_loss: 2.3481\n",
      "Epoch 363/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.8045 - loss: 0.7815 - val_accuracy: 0.7860 - val_loss: 2.3694\n",
      "Epoch 364/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.8130 - loss: 0.7637 - val_accuracy: 0.7860 - val_loss: 2.3917\n",
      "Epoch 365/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.8095 - loss: 0.7733 - val_accuracy: 0.7860 - val_loss: 2.3969\n",
      "Epoch 366/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8080 - loss: 0.7735 - val_accuracy: 0.7860 - val_loss: 2.3870\n",
      "Epoch 367/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.8110 - loss: 0.7715 - val_accuracy: 0.7860 - val_loss: 2.3676\n",
      "Epoch 368/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.8115 - loss: 0.7626 - val_accuracy: 0.7840 - val_loss: 2.3555\n",
      "Epoch 369/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.8075 - loss: 0.7845 - val_accuracy: 0.7840 - val_loss: 2.3585\n",
      "Epoch 370/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.8090 - loss: 0.7639 - val_accuracy: 0.7860 - val_loss: 2.3725\n",
      "Epoch 371/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 0.8090 - loss: 0.7569 - val_accuracy: 0.7860 - val_loss: 2.3943\n",
      "Epoch 372/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.8105 - loss: 0.7530 - val_accuracy: 0.7840 - val_loss: 2.4096\n",
      "Epoch 373/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - accuracy: 0.8080 - loss: 0.7691 - val_accuracy: 0.7860 - val_loss: 2.4031\n",
      "Epoch 374/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - accuracy: 0.8085 - loss: 0.7670 - val_accuracy: 0.7860 - val_loss: 2.3878\n",
      "Epoch 375/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.8075 - loss: 0.7514 - val_accuracy: 0.7820 - val_loss: 2.3784\n",
      "Epoch 376/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8045 - loss: 0.7745 - val_accuracy: 0.7820 - val_loss: 2.3795\n",
      "Epoch 377/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - accuracy: 0.8080 - loss: 0.7730 - val_accuracy: 0.7860 - val_loss: 2.3892\n",
      "Epoch 378/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8075 - loss: 0.7572 - val_accuracy: 0.7860 - val_loss: 2.4028\n",
      "Epoch 379/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.8060 - loss: 0.7507 - val_accuracy: 0.7860 - val_loss: 2.4108\n",
      "Epoch 380/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.8085 - loss: 0.7540 - val_accuracy: 0.7860 - val_loss: 2.4075\n",
      "Epoch 381/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.8065 - loss: 0.7683 - val_accuracy: 0.7860 - val_loss: 2.3957\n",
      "Epoch 382/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.8130 - loss: 0.7493 - val_accuracy: 0.7840 - val_loss: 2.3855\n",
      "Epoch 383/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.8070 - loss: 0.7472 - val_accuracy: 0.7840 - val_loss: 2.3800\n",
      "Epoch 384/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.8120 - loss: 0.7489 - val_accuracy: 0.7840 - val_loss: 2.3842\n",
      "Epoch 385/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - accuracy: 0.8095 - loss: 0.7431 - val_accuracy: 0.7840 - val_loss: 2.3975\n",
      "Epoch 386/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 0.8145 - loss: 0.7372 - val_accuracy: 0.7840 - val_loss: 2.4077\n",
      "Epoch 387/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - accuracy: 0.8100 - loss: 0.7379 - val_accuracy: 0.7840 - val_loss: 2.4190\n",
      "Epoch 388/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.8040 - loss: 0.7544 - val_accuracy: 0.7860 - val_loss: 2.4173\n",
      "Epoch 389/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - accuracy: 0.8085 - loss: 0.7515 - val_accuracy: 0.7840 - val_loss: 2.4055\n",
      "Epoch 390/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.8115 - loss: 0.7352 - val_accuracy: 0.7860 - val_loss: 2.3975\n",
      "Epoch 391/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.8080 - loss: 0.7455 - val_accuracy: 0.7840 - val_loss: 2.3963\n",
      "Epoch 392/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - accuracy: 0.8120 - loss: 0.7415 - val_accuracy: 0.7840 - val_loss: 2.4003\n",
      "Epoch 393/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.8120 - loss: 0.7364 - val_accuracy: 0.7840 - val_loss: 2.4062\n",
      "Epoch 394/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 0.8110 - loss: 0.7379 - val_accuracy: 0.7840 - val_loss: 2.4103\n",
      "Epoch 395/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8140 - loss: 0.7301 - val_accuracy: 0.7840 - val_loss: 2.4117\n",
      "Epoch 396/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.8130 - loss: 0.7267 - val_accuracy: 0.7840 - val_loss: 2.4119\n",
      "Epoch 397/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.8090 - loss: 0.7355 - val_accuracy: 0.7840 - val_loss: 2.4133\n",
      "Epoch 398/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - accuracy: 0.8125 - loss: 0.7175 - val_accuracy: 0.7840 - val_loss: 2.4168\n",
      "Epoch 399/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8130 - loss: 0.7278 - val_accuracy: 0.7840 - val_loss: 2.4223\n",
      "Epoch 400/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8100 - loss: 0.7214 - val_accuracy: 0.7840 - val_loss: 2.4290\n",
      "Epoch 401/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8125 - loss: 0.7272 - val_accuracy: 0.7840 - val_loss: 2.4316\n",
      "Epoch 402/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.8155 - loss: 0.7197 - val_accuracy: 0.7840 - val_loss: 2.4284\n",
      "Epoch 403/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step - accuracy: 0.8100 - loss: 0.7328 - val_accuracy: 0.7840 - val_loss: 2.4304\n",
      "Epoch 404/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524ms/step - accuracy: 0.8120 - loss: 0.7312 - val_accuracy: 0.7840 - val_loss: 2.4330\n",
      "Epoch 405/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523ms/step - accuracy: 0.8155 - loss: 0.7108 - val_accuracy: 0.7840 - val_loss: 2.4396\n",
      "Epoch 406/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step - accuracy: 0.8115 - loss: 0.7264 - val_accuracy: 0.7840 - val_loss: 2.4451\n",
      "Epoch 407/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - accuracy: 0.8110 - loss: 0.7195 - val_accuracy: 0.7840 - val_loss: 2.4485\n",
      "Epoch 408/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - accuracy: 0.8090 - loss: 0.7253 - val_accuracy: 0.7840 - val_loss: 2.4473\n",
      "Epoch 409/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - accuracy: 0.8130 - loss: 0.7186 - val_accuracy: 0.7840 - val_loss: 2.4435\n",
      "Epoch 410/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - accuracy: 0.8145 - loss: 0.7236 - val_accuracy: 0.7840 - val_loss: 2.4386\n",
      "Epoch 411/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - accuracy: 0.8110 - loss: 0.7245 - val_accuracy: 0.7820 - val_loss: 2.4380\n",
      "Epoch 412/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - accuracy: 0.8090 - loss: 0.7205 - val_accuracy: 0.7820 - val_loss: 2.4412\n",
      "Epoch 413/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - accuracy: 0.8105 - loss: 0.7235 - val_accuracy: 0.7820 - val_loss: 2.4452\n",
      "Epoch 414/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - accuracy: 0.8100 - loss: 0.7205 - val_accuracy: 0.7820 - val_loss: 2.4539\n",
      "Epoch 415/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - accuracy: 0.8165 - loss: 0.7105 - val_accuracy: 0.7820 - val_loss: 2.4643\n",
      "Epoch 416/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - accuracy: 0.8135 - loss: 0.7232 - val_accuracy: 0.7820 - val_loss: 2.4597\n",
      "Epoch 417/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.8145 - loss: 0.7160 - val_accuracy: 0.7820 - val_loss: 2.4557\n",
      "Epoch 418/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8160 - loss: 0.7101 - val_accuracy: 0.7820 - val_loss: 2.4574\n",
      "Epoch 419/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.8135 - loss: 0.7039 - val_accuracy: 0.7820 - val_loss: 2.4573\n",
      "Epoch 420/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8080 - loss: 0.7088 - val_accuracy: 0.7820 - val_loss: 2.4652\n",
      "Epoch 421/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.8145 - loss: 0.7076 - val_accuracy: 0.7820 - val_loss: 2.4671\n",
      "Epoch 422/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.8140 - loss: 0.7197 - val_accuracy: 0.7820 - val_loss: 2.4663\n",
      "Epoch 423/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.8155 - loss: 0.7120 - val_accuracy: 0.7820 - val_loss: 2.4706\n",
      "Epoch 424/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.8125 - loss: 0.7179 - val_accuracy: 0.7820 - val_loss: 2.4791\n",
      "Epoch 425/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.8165 - loss: 0.7028 - val_accuracy: 0.7820 - val_loss: 2.4897\n",
      "Epoch 426/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 0.8155 - loss: 0.7049 - val_accuracy: 0.7840 - val_loss: 2.4948\n",
      "Epoch 427/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - accuracy: 0.8120 - loss: 0.7155 - val_accuracy: 0.7840 - val_loss: 2.4847\n",
      "Epoch 428/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.8120 - loss: 0.7105 - val_accuracy: 0.7820 - val_loss: 2.4759\n",
      "Epoch 429/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - accuracy: 0.8125 - loss: 0.7087 - val_accuracy: 0.7840 - val_loss: 2.4756\n",
      "Epoch 430/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 0.8090 - loss: 0.7067 - val_accuracy: 0.7840 - val_loss: 2.4816\n",
      "Epoch 431/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8120 - loss: 0.7079 - val_accuracy: 0.7840 - val_loss: 2.4928\n",
      "Epoch 432/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - accuracy: 0.8110 - loss: 0.7124 - val_accuracy: 0.7820 - val_loss: 2.4941\n",
      "Epoch 433/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.8160 - loss: 0.7036 - val_accuracy: 0.7820 - val_loss: 2.4836\n",
      "Epoch 434/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.8135 - loss: 0.7049 - val_accuracy: 0.7800 - val_loss: 2.4782\n",
      "Epoch 435/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.8180 - loss: 0.6876 - val_accuracy: 0.7780 - val_loss: 2.4784\n",
      "Epoch 436/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8140 - loss: 0.7086 - val_accuracy: 0.7820 - val_loss: 2.4879\n",
      "Epoch 437/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.8160 - loss: 0.7020 - val_accuracy: 0.7820 - val_loss: 2.5059\n",
      "Epoch 438/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.8200 - loss: 0.6973 - val_accuracy: 0.7820 - val_loss: 2.5189\n",
      "Epoch 439/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - accuracy: 0.8130 - loss: 0.6996 - val_accuracy: 0.7820 - val_loss: 2.5235\n",
      "Epoch 440/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.8185 - loss: 0.6957 - val_accuracy: 0.7820 - val_loss: 2.5083\n",
      "Epoch 441/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.8095 - loss: 0.6965 - val_accuracy: 0.7780 - val_loss: 2.4917\n",
      "Epoch 442/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8120 - loss: 0.7110 - val_accuracy: 0.7780 - val_loss: 2.4926\n",
      "Epoch 443/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.8170 - loss: 0.7001 - val_accuracy: 0.7820 - val_loss: 2.5049\n",
      "Epoch 444/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - accuracy: 0.8160 - loss: 0.6995 - val_accuracy: 0.7820 - val_loss: 2.5275\n",
      "Epoch 445/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.8125 - loss: 0.6848 - val_accuracy: 0.7820 - val_loss: 2.5338\n",
      "Epoch 446/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.8120 - loss: 0.7062 - val_accuracy: 0.7820 - val_loss: 2.5228\n",
      "Epoch 447/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8085 - loss: 0.6831 - val_accuracy: 0.7800 - val_loss: 2.5041\n",
      "Epoch 448/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.8150 - loss: 0.6940 - val_accuracy: 0.7780 - val_loss: 2.4985\n",
      "Epoch 449/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.8170 - loss: 0.6939 - val_accuracy: 0.7780 - val_loss: 2.5017\n",
      "Epoch 450/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.8140 - loss: 0.6920 - val_accuracy: 0.7820 - val_loss: 2.5168\n",
      "Epoch 451/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - accuracy: 0.8170 - loss: 0.6846 - val_accuracy: 0.7820 - val_loss: 2.5365\n",
      "Epoch 452/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - accuracy: 0.8185 - loss: 0.6954 - val_accuracy: 0.7820 - val_loss: 2.5451\n",
      "Epoch 453/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8105 - loss: 0.7005 - val_accuracy: 0.7820 - val_loss: 2.5390\n",
      "Epoch 454/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 0.8165 - loss: 0.6761 - val_accuracy: 0.7820 - val_loss: 2.5290\n",
      "Epoch 455/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - accuracy: 0.8195 - loss: 0.6779 - val_accuracy: 0.7780 - val_loss: 2.5276\n",
      "Epoch 456/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8175 - loss: 0.6913 - val_accuracy: 0.7780 - val_loss: 2.5308\n",
      "Epoch 457/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 0.8185 - loss: 0.6798 - val_accuracy: 0.7820 - val_loss: 2.5372\n",
      "Epoch 458/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - accuracy: 0.8185 - loss: 0.6722 - val_accuracy: 0.7820 - val_loss: 2.5435\n",
      "Epoch 459/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.8170 - loss: 0.6843 - val_accuracy: 0.7820 - val_loss: 2.5365\n",
      "Epoch 460/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.8170 - loss: 0.6781 - val_accuracy: 0.7820 - val_loss: 2.5295\n",
      "Epoch 461/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 0.8180 - loss: 0.6750 - val_accuracy: 0.7800 - val_loss: 2.5243\n",
      "Epoch 462/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 0.8185 - loss: 0.6827 - val_accuracy: 0.7820 - val_loss: 2.5238\n",
      "Epoch 463/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8170 - loss: 0.6812 - val_accuracy: 0.7820 - val_loss: 2.5269\n",
      "Epoch 464/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - accuracy: 0.8130 - loss: 0.6780 - val_accuracy: 0.7820 - val_loss: 2.5334\n",
      "Epoch 465/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.8130 - loss: 0.6814 - val_accuracy: 0.7840 - val_loss: 2.5424\n",
      "Epoch 466/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8190 - loss: 0.6679 - val_accuracy: 0.7840 - val_loss: 2.5482\n",
      "Epoch 467/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - accuracy: 0.8135 - loss: 0.6686 - val_accuracy: 0.7840 - val_loss: 2.5515\n",
      "Epoch 468/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step - accuracy: 0.8145 - loss: 0.6862 - val_accuracy: 0.7840 - val_loss: 2.5476\n",
      "Epoch 469/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.8225 - loss: 0.6694 - val_accuracy: 0.7840 - val_loss: 2.5470\n",
      "Epoch 470/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step - accuracy: 0.8130 - loss: 0.6666 - val_accuracy: 0.7840 - val_loss: 2.5469\n",
      "Epoch 471/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 0.8210 - loss: 0.6675 - val_accuracy: 0.7840 - val_loss: 2.5489\n",
      "Epoch 472/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.8190 - loss: 0.6697 - val_accuracy: 0.7840 - val_loss: 2.5535\n",
      "Epoch 473/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - accuracy: 0.8145 - loss: 0.6673 - val_accuracy: 0.7840 - val_loss: 2.5643\n",
      "Epoch 474/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - accuracy: 0.8220 - loss: 0.6648 - val_accuracy: 0.7840 - val_loss: 2.5694\n",
      "Epoch 475/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step - accuracy: 0.8255 - loss: 0.6596 - val_accuracy: 0.7840 - val_loss: 2.5719\n",
      "Epoch 476/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.8210 - loss: 0.6462 - val_accuracy: 0.7840 - val_loss: 2.5720\n",
      "Epoch 477/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - accuracy: 0.8175 - loss: 0.6610 - val_accuracy: 0.7840 - val_loss: 2.5768\n",
      "Epoch 478/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8155 - loss: 0.6728 - val_accuracy: 0.7840 - val_loss: 2.5749\n",
      "Epoch 479/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.8185 - loss: 0.6606 - val_accuracy: 0.7840 - val_loss: 2.5710\n",
      "Epoch 480/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 0.8250 - loss: 0.6589 - val_accuracy: 0.7840 - val_loss: 2.5738\n",
      "Epoch 481/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.8230 - loss: 0.6678 - val_accuracy: 0.7840 - val_loss: 2.5836\n",
      "Epoch 482/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 0.8180 - loss: 0.6758 - val_accuracy: 0.7840 - val_loss: 2.5816\n",
      "Epoch 483/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.8205 - loss: 0.6631 - val_accuracy: 0.7840 - val_loss: 2.5795\n",
      "Epoch 484/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.8230 - loss: 0.6508 - val_accuracy: 0.7800 - val_loss: 2.5783\n",
      "Epoch 485/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.8250 - loss: 0.6626 - val_accuracy: 0.7840 - val_loss: 2.5837\n",
      "Epoch 486/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.8200 - loss: 0.6517 - val_accuracy: 0.7840 - val_loss: 2.5929\n",
      "Epoch 487/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step - accuracy: 0.8175 - loss: 0.6556 - val_accuracy: 0.7840 - val_loss: 2.5992\n",
      "Epoch 488/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439ms/step - accuracy: 0.8205 - loss: 0.6420 - val_accuracy: 0.7840 - val_loss: 2.5974\n",
      "Epoch 489/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - accuracy: 0.8170 - loss: 0.6710 - val_accuracy: 0.7840 - val_loss: 2.5868\n",
      "Epoch 490/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.8190 - loss: 0.6557 - val_accuracy: 0.7840 - val_loss: 2.5720\n",
      "Epoch 491/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.8180 - loss: 0.6504 - val_accuracy: 0.7820 - val_loss: 2.5703\n",
      "Epoch 492/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 0.8200 - loss: 0.6521 - val_accuracy: 0.7820 - val_loss: 2.5806\n",
      "Epoch 493/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.8225 - loss: 0.6449 - val_accuracy: 0.7840 - val_loss: 2.5907\n",
      "Epoch 494/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - accuracy: 0.8200 - loss: 0.6460 - val_accuracy: 0.7840 - val_loss: 2.5971\n",
      "Epoch 495/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - accuracy: 0.8235 - loss: 0.6542 - val_accuracy: 0.7840 - val_loss: 2.5972\n",
      "Epoch 496/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - accuracy: 0.8220 - loss: 0.6388 - val_accuracy: 0.7840 - val_loss: 2.5925\n",
      "Epoch 497/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - accuracy: 0.8275 - loss: 0.6492 - val_accuracy: 0.7820 - val_loss: 2.5874\n",
      "Epoch 498/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.8295 - loss: 0.6459 - val_accuracy: 0.7820 - val_loss: 2.5820\n",
      "Epoch 499/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - accuracy: 0.8225 - loss: 0.6436 - val_accuracy: 0.7840 - val_loss: 2.5830\n",
      "Epoch 500/500\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step - accuracy: 0.8235 - loss: 0.6362 - val_accuracy: 0.7840 - val_loss: 2.5940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=500, batch_size=32)\n",
    "\n",
    "# Saving the model\n",
    "model.save(\"qna_lstm_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3ed09baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Answer: <No Prediction>\n"
     ]
    }
   ],
   "source": [
    "def preprocess_question(question, tokenizer, max_len):\n",
    "    seq = tokenizer.texts_to_sequences([question])  # Convert text to sequence\n",
    "    padded_seq = pad_sequences(seq, maxlen=max_len, padding='post')  # Pad sequence\n",
    "    return padded_seq\n",
    "\n",
    "# def predict_answer(question, tokenizer, max_len, model, index_to_word):\n",
    "#     # Preprocess the question\n",
    "#     input_seq = preprocess_question(question, tokenizer, max_len)\n",
    "    \n",
    "#     # Predict\n",
    "#     predicted_seq = model.predict(input_seq)  # Shape: (1, max_len, vocab_size)\n",
    "#     # Convert predicted tokens to words\n",
    "#     predicted_words = [\n",
    "#         index_to_word.get(np.argmax(word_probs), \"<UNK>\") for word_probs in predicted_seq[0]\n",
    "#     ]\n",
    "#     # Join words to form the answer\n",
    "#     predicted_answer = ' '.join(predicted_words)\n",
    "    \n",
    "#     return predicted_answer\n",
    "\n",
    "\n",
    "\n",
    "# question = \"Who is Queequeg?\"\n",
    "# predicted_answer = predict_answer(question, tokenizer, max_len, model, index_to_word)\n",
    "# print(\"Predicted Answer:\", predicted_answer)\n",
    "\n",
    "index_to_word = {index: word for word, index in tokenizer.word_index.items()}\n",
    "\n",
    "def predict_answer(question, tokenizer, max_len, model, index_to_word):\n",
    "    # Preprocess the question\n",
    "    input_seq = preprocess_question(question, tokenizer, max_len)\n",
    "    answer = []\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        # Predict the next word\n",
    "        predicted_probs = model.predict(input_seq, verbose=0)  # Shape: (1, max_len, vocab_size)\n",
    "        \n",
    "        # Get the last time step prediction (the final word in the sequence)\n",
    "        predicted_token = np.argmax(predicted_probs[0, -1, :])\n",
    "        \n",
    "        # If the predicted token is padding or unknown, continue generating more words\n",
    "        if predicted_token == 0:\n",
    "            continue\n",
    "        \n",
    "        # Convert token to word and add to answer\n",
    "        predicted_word = index_to_word.get(predicted_token, \"<UNK>\")\n",
    "        answer.append(predicted_word)\n",
    "        \n",
    "        # Update the input sequence by shifting left and appending the predicted token\n",
    "        input_seq = np.roll(input_seq, -1)  # Shift left\n",
    "        input_seq[0, -1] = predicted_token  # Add the new token at the end\n",
    "\n",
    "    return ' '.join(answer) if answer else \"<No Prediction>\"\n",
    "\n",
    "# Example usage\n",
    "question = \"Who is Queequeg?\"\n",
    "predicted_answer = predict_answer(question, tokenizer, max_len, model, index_to_word)\n",
    "print(\"Predicted Answer:\", predicted_answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b8a7b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new\n",
    "df=pd.DataFrame(qna_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71f6d4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Lowercase and remove special characters\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b881ce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Questions'] = df['Questions'].apply(preprocess)\n",
    "df['Answers'] = df['Answers'].apply(preprocess)\n",
    "\n",
    "df= df[['Questions', 'Answers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dc962e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = df[\"Questions\"].tolist()\n",
    "answers = df[\"Answers\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0ae8b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(questions + answers)\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a18cc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zeeshan Ali\\Desktop\\NLP Practice\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "question_sequences = tokenizer.texts_to_sequences(questions)\n",
    "answer_sequences = tokenizer.texts_to_sequences(answers)\n",
    "\n",
    "max_sequence_length = max(max(len(seq) for seq in question_sequences), max(len(seq) for seq in answer_sequences))\n",
    "\n",
    "padded_questions = pad_sequences(question_sequences, maxlen=max_sequence_length)\n",
    "padded_answers = pad_sequences(answer_sequences, maxlen=max_sequence_length)\n",
    "\n",
    "answer_one_hot = to_categorical(padded_answers, num_classes=vocab_size)\n",
    "\n",
    "# 2. LSTM Model Architecture\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length=max_sequence_length))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(max_sequence_length * vocab_size, activation='relu'))\n",
    "model.add(tf.keras.layers.Reshape((max_sequence_length,vocab_size)))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 3. Training\n",
    "model.fit(padded_questions, answer_one_hot, epochs=10, validation_split=0.2)\n",
    "\n",
    "# 4. Inference\n",
    "def answer_question(question):\n",
    "    question_seq = tokenizer.texts_to_sequences([question])\n",
    "    padded_question = pad_sequences(question_seq, maxlen=max_sequence_length)\n",
    "    prediction = model.predict(padded_question)\n",
    "    predicted_seq = tf.argmax(prediction[0], axis=-1).numpy()\n",
    "    answer_words = [tokenizer.index_word.get(idx, '') for idx in predicted_seq]\n",
    "    return ' '.join(answer_words)\n",
    "\n",
    "# Example usage\n",
    "question = \"What is the purpose of Section 23 in the document?\"\n",
    "answer = answer_question(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bba972bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into training and validation sets\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameters\n",
    "max_words = 10000\n",
    "max_len = 100\n",
    "\n",
    "# Tokenizer for questions and answers\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(pd.concat([df['Questions'], df['Answers']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "86cb3d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding and padding sequences\n",
    "X_train = pad_sequences(tokenizer.texts_to_sequences(train_df['Questions']), maxlen=max_len, padding='post')\n",
    "y_train = pad_sequences(tokenizer.texts_to_sequences(train_df['Answers']), maxlen=max_len, padding='post')\n",
    "X_val = pad_sequences(tokenizer.texts_to_sequences(val_df['Questions']), maxlen=max_len, padding='post')\n",
    "y_val = pad_sequences(tokenizer.texts_to_sequences(val_df['Answers']), maxlen=max_len, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "36e028e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 3493\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "30133161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand dimensions to fit LSTM requirements\n",
    "y_train = np.expand_dims(y_train, -1)\n",
    "y_val = np.expand_dims(y_val, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8aa44a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,788,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">328,192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_8              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_9              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_10             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3493</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">450,597</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │     \u001b[38;5;34m1,788,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │     \u001b[38;5;34m1,574,912\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m328,192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_11 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_8              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_9              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_10             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m3493\u001b[0m)       │       \u001b[38;5;34m450,597\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,342,437</span> (16.57 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,342,437\u001b[0m (16.57 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,341,157</span> (16.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,341,157\u001b[0m (16.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> (5.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,280\u001b[0m (5.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LSTM Model\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, 512, input_length=max_len),  # Increased embedding size\n",
    "    Bidirectional(LSTM(256, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)),\n",
    "    BatchNormalization(),\n",
    "    LSTM(128, return_sequences=True, dropout=0.4, recurrent_dropout=0.4),\n",
    "    LayerNormalization(),\n",
    "    LSTM(128, return_sequences=True, dropout=0.3),\n",
    "    BatchNormalization(),\n",
    "    TimeDistributed(Dense(256, activation='relu')),\n",
    "    Dropout(0.5),\n",
    "    TimeDistributed(Dense(128, activation='relu')),\n",
    "    Dropout(0.4),\n",
    "    TimeDistributed(Dense(vocab_size, activation='softmax'))\n",
    "])\n",
    "\n",
    "# Compile the model with a lower learning rate for better convergence\n",
    "# Gradient Clipping\n",
    "optimizer = Adam(learning_rate=0.001, clipvalue=1.0)\n",
    "\n",
    "# Learning Rate Scheduler\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model.build(input_shape=(None, max_len-1)) \n",
    "\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b27238f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 1s/step - accuracy: 0.4091 - loss: 6.0595 - val_accuracy: 0.6315 - val_loss: 2.9431 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.6122 - loss: 2.9523 - val_accuracy: 0.6315 - val_loss: 3.2079 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.6304 - loss: 2.7257 - val_accuracy: 0.6347 - val_loss: 2.8405 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.6291 - loss: 2.6857 - val_accuracy: 0.6378 - val_loss: 2.6902 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.6410 - loss: 2.6011 - val_accuracy: 0.6421 - val_loss: 2.6709 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.6413 - loss: 2.5991 - val_accuracy: 0.6462 - val_loss: 2.6968 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.6454 - loss: 2.5409 - val_accuracy: 0.6476 - val_loss: 2.6370 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.6476 - loss: 2.5164 - val_accuracy: 0.6483 - val_loss: 2.6679 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.6399 - loss: 2.5579 - val_accuracy: 0.6481 - val_loss: 2.6805 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6327 - loss: 2.5796\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.6329 - loss: 2.5781 - val_accuracy: 0.6471 - val_loss: 2.6789 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.6383 - loss: 2.5445 - val_accuracy: 0.6468 - val_loss: 2.6697 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.6459 - loss: 2.4700 - val_accuracy: 0.6445 - val_loss: 2.6874 - learning_rate: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    callbacks=[lr_scheduler, early_stopping]\n",
    ")\n",
    "\n",
    "# Saving the model\n",
    "model.save(\"qna_lstm_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a00f112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAHqCAYAAADVi/1VAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAArV1JREFUeJzs3Qd4VGXaxvE7vZFA6FWKIAgKKjawrYp97X1VrPjZdV1d17LWXVF37bp2xbKubRVde6+oIIgiIoIgRToBQhLS813Pe+ZMJiEJSUgy7f+7rrNn5syZmTOTrJzc53mfN6GqqqpKAAAAAAAAQBtKbMs3AwAAAAAAAAyhFAAAAAAAANocoRQAAAAAAADaHKEUAAAAAAAA2hyhFAAAAAAAANocoRQAAAAAAADaHKEUAAAAAAAA2hyhFAAAAAAAANocoRQAAAAAAADaHKEUgIiWkJCg66+/vsnP+/XXX91zJ0yY0CrHBQAAEKs4/wLQVgilAGySnVjYCYYtn3/++UaPV1VVqU+fPu7x3//+94pWb775pvsMPXv2VGVlZbgPBwAAxLFYPv/6+OOP3XG/9NJL4T4UAGFGKAWg0dLT0/Xss89utP2TTz7R4sWLlZaWpmj273//W/369dPSpUv14YcfhvtwAAAAYv78C0B8I5QC0GgHH3ywXnzxRZWXl9fYbidKI0eOVPfu3RWtCgsL9eqrr+rSSy/V9ttv7wKqSD5WAAAQH2L5/AsACKUANNqJJ56o1atX67333gtuKy0tdaXXf/jDH+oNUP70pz+58nK7kjd48GD985//dCXnoUpKSvTHP/5RXbp0UXZ2tg477DB39a8uv/32m8444wx169bNveawYcP0+OOPb9Zne+WVV7RhwwYde+yxOuGEE/Tyyy+ruLh4o/1sm/VY2GqrrdyVyx49euioo47SL7/8EtzHhv7dfffd2nbbbd0+9pkOPPBAffPNN5vst1C7h4Pdtm0//vij+45zc3O1++67u8e+//57nXbaaRowYIB7Hzspte/FfkZ1fWdnnnmmG5po31n//v117rnnup/fvHnz3HvceeedGz1v0qRJ7rH//Oc/m/HtAgCA5orl869NsXMUOzfr2LGjMjMzteuuu+qNN97YaL97773XHY/tY+dKO+64Y43qsvXr1+uSSy5xFfF27F27dtV+++2nadOmterxA9i05EbsAwCO/UM+atQoF1AcdNBBbttbb72ldevWuSDnnnvuqbG/nfjYyc1HH33kApHttttO77zzji6//HJ3YhMagpx11ll65pln3MnV6NGj3fC5Qw45ZKNjWL58uTshsaDkggsucCdRdgz2+vn5+e6EozmsMmrvvfd2wY59lr/85S/63//+506EfBUVFa5nwwcffOD2ufjii91Jjp0k/vDDD9pyyy3dfnYsFjjZd2Sfy65sfvbZZ/rqq6/cSVJz2HEMGjRIN998c/CE0t7XTtZOP/10d9wzZ87Uww8/7Nb2XvYdmSVLlmjnnXfW2rVrdfbZZ2vIkCHu+7eT2aKiIhdq7bbbbu47sBPT2t+LnaQefvjhzTpuAACweWL5/Ksh9p52THauctFFF6lTp0568skn3Wezc5gjjzzS7ffII4+4x4855hh3bmYXEO3C3ddffx0M7c455xz3HDv2oUOHupDP+nTNmjVLO+ywQ4sfO4AmqAKATXjiiScsBamaMmVK1X333VeVnZ1dVVRU5B479thjq/bee293u2/fvlWHHHJI8HkTJ050z/vb3/5W4/WOOeaYqoSEhKq5c+e6+9OnT3f7nXfeeTX2+8Mf/uC2X3fddcFtZ555ZlWPHj2qVq1aVWPfE044oap9+/bB45o/f757rh37pixfvrwqOTm56pFHHgluGz16dNXhhx9eY7/HH3/cveYdd9yx0WtUVla69Ycffuj2ueiii+rdp6Fjq/157bZtO/HEEzfa1/+sof7zn/+4/T/99NPgtrFjx1YlJia6n199x/TQQw+5582aNSv4WGlpaVXnzp2rTj311I2eBwAAWlcsn3999NFHbr8XX3yx3n0uueQSt89nn30W3LZ+/fqq/v37V/Xr16+qoqLCbbPztWHDhjX4fnaM559/foP7AAgPhu8BaJLjjjvODXN7/fXXXZWQresrHbfZ7JKSktzVq1BWTm75i11h8/cztferfdXNnvPf//5Xhx56qLu9atWq4HLAAQe4K4bNKcN+7rnnlJiYqKOPPrpGqbwd35o1a4Lb7L07d+6sCy+8cKPX8KuSbB+7fd1119W7T3PYFb7aMjIygrftqqB9D3YV0/jfgw0lnDhxovvO6qrS8o/Jfq42BDC0l5ZdVbXXPPnkk5t93AAAYPPF4vnXptjxWaW337bAtGvXzlV9WysEa21gOnTo4IYcTpkypd7Xsn2scsqqxwFEFkIpAE1i5dpjxoxx4/St75INabNy6bosWLDA9TCy4V+htt566+Dj/tpCIX/4m8/6H4RauXKlG4JmQ9TsOEIXG8JmVqxY0eTPZGXrdtJjpdxz5851izU7t34N1ljUZ32j7JiSk+sf+Wz72Ge23gctyXpA1ZaXl+fK1K23gwVU9j34+9kJov+dWVn9Ntts0+Dr28manWyG9l+wgKpXr17aZ599WvSzAACAponF869NseOrfSx1fY4rrrjChVV2LmetDs4//3x98cUXNZ5z2223uVYL1mPL9rOendYCAUD40VMKQJPZlblx48Zp2bJlrreBBRptwap+jFXunHrqqXXuM3z48Ca95pw5c4JX1uxEpjYLZuyKXEuqr2LKTjDrE1oVFXrV1BqRW48I6xdhJ2T2HVlTdf+7aoqxY8e6EM5e05q0v/baazrvvPPcCSsAAAivWDr/akkWUs2ePdtVj7399tuuqutf//qXrr32Wt1www3Bc6Y99tjDTWzz7rvv6h//+IduvfVWF/D5fboAhAehFIAms8aS//d//+eaaT///PP17te3b1+9//77rsw89GrdTz/9FHzcX9sJj1+J5LMTjFD+zDAW3tjVwpZgoVNKSoqefvppV+oeyhpgWvPQhQsXaosttnBXEq30u6yszD2nLraPDXuzKqb6qqVsVhhjVx1D+Vf8GsOGFVrDdTvZspOu0JCt9neWk5Pjrg5uioVZtr99J7vssotrLHrKKac0+pgAAEDriaXzr8aw46t9LHV9DpOVlaXjjz/eLVbpbjMj//3vf9eVV17p2hMYmzHZLrbZYpVd1uDc9iGUAsKLy98Amswqch544AFX+mxDvupz8MEHuxOY++67r8Z2m/XFqoX8kwB/XXv2mLvuuqvGfQuNrO+TXQGrK2Sx8vKmsgDGrpzZSYyVwYcuVoFkbLYbY+9t/RNqfx7jz4hn+9ht/8pcXftYSGS9qT799NMaj9tVvcbyA7TaUzvX/s6syumII45wMwl+88039R6TsWGJ1kvrhRdecLMHWrVUOK98AgCA2Dz/agz7HJMnT9aXX34Z3FZYWOiGEdqMhDaLnrH2C6FSU1PdY3aOYxcS7bvw2xr4unbt6oY4lpSUtMqxA2g8KqUANEt95duh7IRp77331tVXX+0aUo4YMcKVTL/66quuiabfw8CGnlkYYqGMnTTY9L9WBWS9nWq75ZZb3BTHVsljJex20mFVSdZg064K2u3Gsqonew+bHrgu1k/JrqJZcGX9Cmx421NPPaVLL73UnSRZmGUnR/a+dtXt8MMPd5/XqovsBM+qlvyhdJ999pl7zH8vm4LZPoutrQG5BVQ///xzo4/dgq0999zT9UiwEy47Vvtu58+fv9G+N998s3tsr732ckMRrcx96dKlbqieVYOFlv/bZ7Rjt+/YytoBAEDkiIXzr1AWdPmVT7U/51/+8hd3YdDCM2vGbhXoTz75pDvXsef57QX2339/de/eXbvttpvrszlr1iwXyB1yyCGuwssq03v37u0uONp3YeGeHbO1b7j99tubddwAWlCYZv0DEKVTEjek9pTE/tS9f/zjH6t69uxZlZKSUjVo0KCqf/zjH1WVlZU19tuwYUPVRRddVNWpU6eqrKysqkMPPbRq0aJFG01JbJYvX+6m9e3Tp497ze7du1ftu+++VQ8//HBwn8ZMSXzhhRe6fX755Zd697n++uvdPt999527b1MeX3311W46Yv+9bYrl0NcoLy93n3HIkCFVqampVV26dKk66KCDqqZOnRrcx17Hple2KYptiufjjjuuasWKFRt9Xrtt21auXLnRsS1evLjqyCOPrOrQoYN7HZseesmSJXV+ZwsWLKgaO3asO5a0tLSqAQMGuO+wpKRko9e1aZUTExPd6wMAgPCI1fMv89FHH7n96ls+++wzt5+dX9l5lp3rpKenV+28885Vr7/+eo3Xeuihh6r23HNP9xnsHGfLLbesuvzyy6vWrVvnHrdzHbs/YsQId85ln9Nu/+tf/2rwGAG0jQT7n5YMuQAA0c1mHrSrkXa1FAAAAABaCz2lAABB1ndq+vTpbhgfAAAAALQmKqUAAK5x6dSpU11vBWvmPm/evOBsNQAAAADQGqiUAgDopZde0umnn+6apltTUQIpAAAAAK2NSikAAAAAAAC0OSqlAAAAAAAA0OYIpQAAAAAAANDmktv+LSNfZWWllixZouzsbCUkJIT7cAAAQASxzgfr169Xz549lZgYv9f3OF8CAACbe75EKFUHO8Hq06dPuA8DAABEsEWLFql3796KV5wvAQCAzT1fIpSqg13x87+8nJyccB8OAACIIPn5+S6M8c8X4hXnSwAAYHPPlwil6uCXoNsJFidZAACgLvE+ZI3zJQAAsLnnS/HbCAEAAAAAAABhQygFAAAAAACANkcoBQAAAAAAgDZHTykAAAAAAGJUZWWlSktLw30YiDEpKSlKSkra7NchlAIAAAAAIAZZGDV//nwXTAEtrUOHDurevftmTf5CKAUAAAAAQIypqqrS0qVLXTVLnz59lJhI9x603O9WUVGRVqxY4e736NGj2a9FKAUAAAAAQIwpLy93wUHPnj2VmZkZ7sNBjMnIyHBrC6a6du3a7KF8RKUAAAAAAMSYiooKt05NTQ33oSBGZQbCzrKysma/BqEUAAAAAAAxanP6/QCt/bsV9lDq/vvvV79+/ZSenq5ddtlFkydPbnD/tWvX6vzzz3djFtPS0rTVVlvpzTffDD5+/fXXuy8mdBkyZEgbfBIAAAAAAABERSj1/PPP69JLL9V1112nadOmacSIETrggAOCzbLqmjlgv/3206+//qqXXnpJs2fP1iOPPKJevXrV2G/YsGGuoZu/fP755230iQAAAAAAQCSxQpi77rqr0ft//PHHrsDFimLQusLa6PyOO+7QuHHjdPrpp7v7Dz74oN544w09/vjj+stf/rLR/rY9Ly9PkyZNUkpKSvCXq7bk5GQ3LSEAAAAAAIiN4WBW0GKjo5pqypQpysrKavT+o0ePdgUu7du3V2v6+OOPtffee2vNmjXq0KGD4lHYKqWs6mnq1KkaM2ZM9cEkJrr7X375ZZ3Pee211zRq1Cg3fK9bt27aZpttdPPNNwcbuPnmzJnjZhgYMGCATjrpJC1cuLDBYykpKVF+fn6NBQAAAAAAtJ3QEU9W2ZSTk1Nj22WXXRbct6qqys0w2BhdunRp0gyE1hzeCl3oxxXDodSqVatcmGThUii7v2zZsjqfM2/ePDdsz55nfaT++te/6vbbb9ff/va34D7Wl2rChAl6++239cADD2j+/PnaY489tH79+nqPZfz48S4B9Zc+ffq04CcFAAAAAACbYkGQv9jf5hYK+fd/+uknZWdn66233tLIkSNdj2lr1fPLL7/o8MMPd1lCu3bttNNOO+n9999vcPieve6jjz6qI4880oVVgwYNckUw9Q3fs4zBKpneeecdbb311u59DjzwQBeU+Swgu+iii9x+nTp10hVXXKFTTz1VRxxxRLO/jzVr1mjs2LHKzc11x3nQQQe5IhzfggULdOihh7rHrRLMWhn5PbftuVakY4FcRkaG+4xPPPGEIk3YG503RWVlpbp27aqHH37Y/RIef/zxuvrqq92wP5/9kI499lgNHz7c9aeyH4j9Ir3wwgv1vu6VV16pdevWBZdFixa10ScCgAhUVSUVrpIWTZFmvS7NeV9a8KW09Dtp1Vwpf6lUvE6qaNyVKQBoqnUbyvTej8v19g/VJ/sAgM1jlUVFpeVhWey9W4q1+rnllls0a9Ys93d/QUGBDj74YH3wwQf69ttvXVhkQc2mRkzdcMMNOu644/T999+751uAY+2C6lNUVKR//vOfevrpp/Xpp5+61w+t3Lr11lv173//2wU/X3zxhRuBNXHixM36rKeddpq++eYbF5jZiDL7Hu1Yy8rK3OM2isxGftnxzJgxwx2DBWbGinh+/PFHF+LZd2VFO507d1akCVtPKfsykpKStHz58hrb7X59/aBsxj3rJWXP81lKaZVVNhzQSuxqs5TSZuibO3duvcdiCastABoIKNb8KuUvliprDpdtFVYmm5BY9yL/sQb2SdjEPvYaVRXeZ6ksl6oqvdv+NrcutyS81rZatxt6zN67XTcpu7uU3cNb0rK97ZHAPlv+b9Ka+VLePClvfuB2YCmtv7q0hqQ0KTVTSsmSUrOadzs1W8rMlTI7R9Z3BCBsFuUVadxT36hrdpoO3KZHuA8HAGLChrIKDb32nbC89483HqDM1JaJH2688UY3AZqvY8eObtI030033aRXXnnFBTkXXHBBg4HPiSee6G5bW6B77rlHkydPdqFWXSwIsoKYLbfc0t2317Zj8d17772u4MWqr8x9990XrFpqjjlz5rjPYAGX9bgyFnrZyC4Lu6wYx4Kxo48+Wttuu6173FoY+eyx7bffXjvuuGO9/bjjOpSyAMmqnSzN9MvZrBLK7tf3i7Pbbrvp2WefdftZ/ynz888/u7CqrkDKWGpq5XynnHJKK36aOFRaKE151KuY2OgP9MrAH/S1t4X+sV97mx8OVGwcBLggIUlKTAqsE6XE5I23uXVyHdsC22tvC33MlqTUwBJyuyW3R/If2mXF0tqFXvBU11JWGO4jjA0WxOQEAiq3dJdyegaCK3/dXUpuoZC8vMT7uW4UOs2T1i6QKkobeHKClNPLO157nbIi7//3pbYu8P6/aSpKpA22rGmZY05MkTI7BZaO3jqrc8i2kO3+kpKhmGP//bPvtHBlyLLK++9kt2FSjxFSRm64jxJoNZ3aeed1a4pK3VVhenoAAHx+yBL6N781P7dJ02w4nQ2j27BhwyYrpazKymdD36x/1YoVK+rd34bP+YGUsRzC399GXFmBzc477xx83IppLPOw/KI5Zs2a5SZxsxZFPhsWOHjwYPeYseGC5557rt59913Xn9sCKv9z2Xa7P23aNO2///4ud/HDrUgS1tn3Lr30UjfG0n6p7IdnYzwLCwuDs/HZ2MlevXq5nk/+l2pp48UXX6wLL7zQJYeWaNoPwmflc1aq17dvXy1ZssR157dfBj8BRQsoKZD+fay0cFK4jySKJEgZHRr4w7rzxtvT27dckGXVTgUr6g+d1i/Z9PFbQNGhj5TkzXzZqux43VJZ/6JN7bOJx4PBZHLdYeUmA9BNhJ0WKhSu8ILb9cukknVeuLd6rrc0xH7+DQZXPaSsLt77lqyvDpr80Mlfr1vsfU8NBUC5faXc/lJHWwZU3+7QV0pJr//nY4GWC6kKQwKrZt62z1CU530/lWVSwTJvaUrYV1dYlRVy2wKclEwpOd0LsWxxt21bWuuHxvadWZjnh0u1w6bat4tWB37PG2A/Iwunem7nrXts5wV4QAzIzfRCqbKKKhWUlCs7vQ3+7QGAGJeRkuQqlsL13i2l9ix6lgG89957bmjdwIEDXf+kY445xo2maoiNwgplF0AaCpDq2r8lhyU2x1lnneXaFlkgZ8GUZSfWd9vyEmttZD2nrFrLvp99993XDfez7ymShDWUsp5QK1eu1LXXXuuG4G233XauQbnf/NySTb8iyliZmjUW++Mf/+jSPwusLKCyBmK+xYsXuwBq9erVrqHX7rvvrq+++srdRgsHUmk50o6ne3/YBiuUEuv4w76uP/ZD9m3oj35buxAhtBqrsnHDrPx9gxVYDTzfeuPYH8P2h3ZF6Dpw2z22qe22lFdvr6HKq3qwZVOBhM++l4zQSpFaf3AH/wgPBFo27MnCj/qCp/INDb+fDaHK7RcIKfoFlv7e2sKolqreiVcWwNjPZ/3SQFAVuiyT8pd4a6s8skDCluU/NPz7kdpOKvaaL9bL9nFBU7+aoZOt2/f2/n/WVBbg2O+DLfY72FLKNlR/drfk1bxvgU3t7fb/NQuz1tnS8NWwBj5QSEjlB1aBtQVzwduhjwX2DX3MXqdoVf1BU3lx0w/N/htgAaRbOnv/PVz2vff/aat2s2VWdVNO5fQOBFQhYZUFmUCUSU9JUmZqkopKK7SmsIxQCgBagIUoLTWELpLY8DYbiucPm7PKqV9//bVNj8GasluOMWXKFO25555um03QZlVKlnM0x9Zbb+2qvr7++utghZPlHLNnz9bQoUNr5CTnnHOOW2z44COPPOJCKWM5iBUC2WITwF1++eWEUrXZUL36hutZx/vaRo0a5UKm+jz33HMtenwIYdUMLpD6UkprL53yitR7ZLiPKjJZYu7CrkBYVV7qBVI1/uCub8nzKirs+VZpY8vKFjgmCwEthAgGThY2Bapk7LaFCwyPaD3WP6nTlt7S0O+N/Z74YZVfZWWVbKGBlv1O2O+HH0hZMFm70smtB3hBRrT8XC3Ysd9RWxrDvi9XZeUHVX5oVUewZd+rVWXZUFULh+y2fYfeCwUeK5I2kd1uNqvqsp9JaNAUvF3rvoXNNgy4LvZ5ls2Qlkz3GtAvne4F3tb3zZbZb1Tva73NrIoqNKyyysdo+b1AXFdLFZVuUF5Rqbbo1PhpvAEA8cVmlXv55ZfdiCkL3qzBd3OHzG0OC4KsUsmqtYYMGeJ6TNkMeI0Zgj5jxgw3s6DPnmN9smxWwXHjxumhhx5yj1uTdyvOse3mkksucRVR1kfb3uujjz5yYZax4h8bPmgz8lkz9Ndffz34WCQJeyiFKGF/+D1zjLToKy+QGvuK1ItAql72Hx4b5uaGugXKS7O9CsBGsT+cN+SFVIbUUTVSe7Hwy342VhGTW8fSvo2G3mHzfm9c9VtHr29Qfawiz4IpmwHPwoX0HMXt92Wf3RYL4prKqhytOssPqcoCa3d/QwOP+eFWYB9/sSqmjUKm0LCpsxdOtgQbjth/T2/xFed71XXBoMpmS5wtFSyX5rzjLT4LvPwhf35YZf+dIKhCBOmYlarf1m5QXmFJuA8FABDB7rjjDp1xxhmumsgmVLORVDbzXVuz97URYNaGyFoInX322W5oXehEbfXZM1Bd5bPnWJWUzeRno8N+//vfu+GItp8Nx/OHElo1lg3JsxFj1hPLmrTfeeed7jHru22VU1Y1ZkMarVIqEot4EqrCPQgyAtkvsJXfWbMy+8HGPQKpyGf/N7Y/lmOx4TOAzRs2unymF1D5YdXKWSFVYiGsj52FU312kUaeLrXv1eqHZ6cgFZVVKq+sUmVVYF1Zc11Rx2MV/hJ4fkXtbRXeetcBndQ+o+XDeM4T2uZ7GPv4ZH3680r989gROmZkIysoAQBBxcXFmj9/vvr376/09Hp6haLVWLWWVSYdd9xxbkbAePsdy2/keQKVUmiYXXn/twVSX3t/sJwyUeq1Q7iPCrVZdQOBFBA2Fq5YNpyYGGGVRlaZ1Wdnb/FZldeKQFDlh1UrfvQq7+Z/6paqz+9U0eCjtHrEOcrPHqjisgo3jXRxWaW3Lq1QcXmFNpRWb3f7hGwvLq90+3mPV69t35LyikDY1Lof//ULd1f7Xu1b903QajpmeoHimsKGG9UCABAJrKm4NRvfa6+93HA5m6TNAps//OEP4T60iEYohYYDqWeOlhZP9gKpsa9KPbcP91EBQIuESBaSFJbYUu5m97KGytW3bV2hIrtfWu62F5VUuMcK3X1vX3uO21ZS7ip4rDFzu7Rkb0n31llpycoOrP1t/uIeS9/4tr1OY/oP+CzksWMqKC7X+pIyt7bjCi7FtW9LBSXDVFAyWAXFR6k4aYO6lS/QwPI5OizxC43Wj8qa9YJb3q/YXg+VH6opVYO9Zu5txPK9pMQEb0kIrN2SqKREKTkx0c2L4dYJ/v0EJScmuHVqQqVrlo3o1THLm2DDekoBABDpbJK2CRMmuNkA7Vxzm2220fvvvx+RfZwiCaEU6mZXzF0gNUVK7yCNnUggBWCz2D/OfoizvrhM+RaOFHsBUKkNt6qsdNO/l9tSWRlc+9vc4zZ8qyKwrbLSVdt4j3uPVYQ+J/gaVSotrwyESYFAqbTcVTa1NPt8tqxYv3k9cCyPape6cZCVkpTgjn99IAjzQ6bSis1v5rlIvfWNeuu5ir01onyuzk15XfsnTtGYpG/d8mPSEL2adYxmZO2mtNRkZaQmKT05SempSW6a5/SUxMDaW/zbGamJG21LTU5USiA8Sg5dJ3hrC5+aEsrV6BP2y4fSjBeleR9L7adv9veC8OmYRaUUACB62Cx4NhMgmoZQCnUHUk8fJf32TSCQsgqp5k1jCSA2WKhjQZIXKPlL9X1b5xeXebdrPRa6b2sP12qOrNQkF/54S5KyAmGQC4TSbFr6mrf9qqbaz0tJSnTVVH6lkgVf9tldBVOwesm77QdLBcXe7dCqJgvaLDCzx21RE/p01lWptdH9+rYHbtvnT085WEmJF0urf5Em3StNf1ZDK37S0Py/SSmDpB0vlEacICV7lSxhZbPrWM9DC6JmTvQmifDNfV8adkQ4jw6bITcr1a3zCKUAAIhZhFKoiUAKaHWhQ6384WChw6usAsYLM0KDDf/x6lDDKoxMQmBIlV9YYiu/ysT9b13bE6oHYoXuW12cYpUq9vd+lQtGLJRqKVYF067WsDWrALJQx6pkkkPWVk2TnOQN2bJ9bIiW3Q99PMmeW2u7re317L381/aCJC9AckPkbElJatk+UO02v5rMei7V/l3wb9vPocawwJCgKSs12X3eFtVpS+nQu6S9r5K+flCa8qi0eo70v4ukj/4u7XqutOMZ3hDvtmSpnc00aEHUjP9K+YurH8vqKm1ztLTtsfRAjHIdMwmlAACIdYRSqLZhrfSMBVJTvenGLZCymZgAbMTCGqsMWlVQqtUFJe6PplWFpcqz+4Xe/RoBUyB4sjCpJYZahYtVB1kAkp2eEgyW3JKW4gUkgcesh1Lofds3J3DfhnA1a2hWHLDvxYbF2dIlOwKqkHztukr7Xivt/kdp2lPSl/dL+b9J718vfXq7tOPpXkCV07N1jyNvvvTDS9KMl6SVP1VvT8uRtj5M2vYYqd8eUlL8nd789ttvbirqt956S0VFRRo4cKCbRnrHHXes9zkff/yxLr30Us2cOdMNObjmmmt02mmnKeIqpegpBQBAzIq/szbUH0g9faS0ZFogkHpN6jE83EcFtBmrULGKoNUFpcorLAmETdW3LWSysMm2rbbwqbDUDbPaHBbOVFe9hAy7Cm2KnRqogqmjObY9f+PPIVWpKuR29eervh3cO3jbVtW3q7e73kZp1cFSi1fiILqkZUujzpd2Gif98F/pi7ullbOkSfdIXz0gDT9e2u0iqYs1RW8hBSukma94VVHW59CXlCZtdYBXETVofyklfqe6XrNmjXbbbTftvffeLpTq0qWL5syZo9zc3HqfY7MBHXLIITrnnHP073//Wx988IHOOuss9ejRQwcccIAiQcdAKEVPKQAAYhehFGoFUh2lU1+Tum8b7qMCNptNP28BklUyWZi0MrB2962yKVDh5IVPpc2qYLJwqHO7NHXKSnV/QHVql6bO7VKVm5laY3haaN8evx+RDTMDolJyqrTdiV4INfc9L5xa8IU0/RlvGXywtNvF0ha7Nn/2159er25YXhX4/2ZCotR/Ly+I2vr3bT9sMELdeuutrtLJKqN8/fv3b/A5Dz74oNvn9ttvd/dtZqDPP/9cd955Z8SFUms3lLmLAITiAADEHkKpeLdhTSCQ+pZAClE0ZK66ksluW8hkQ+fc2g+dCkq9JtFNZGFRx3ap6pTlhUt+0GShU6fAdttmQVRuVorSkplyHnEsMdGrVrJl0RTpi7ukn96QZr/pLX12kXa7RNrqQG/fhpQVewGXBVGz35YqQmYw7LWjF0QNO1LK7tbqHyvavPbaay5IOvbYY/XJJ5+oV69eOu+88zRu3Lh6n/Pll19qzJgxNbbZa1xyySX1PqekpMQtvvz8JnThb4YOGd7se1a5uW5DWTCkAgAAsYNQKt4DqaeOkJZOlzI7eUP2um8T7qNCBLMmy+WVtlS5gCh0XeEvVSG3A4vbr6pK5RWBda3nhW6z97D+IX7A5IVO1VVNtl9TWJNrC5IsUHIVTS5Y8m774VInP3zKSnO9fAA0Q5+dpBP+La2a4w3n++45adHX0nMnSp0He8P6LFgKnbGvskL69TMviPrxf1LJuurHOm8lbXuctO3RUscBYflI0WLevHl64IEHXH+oq666SlOmTNFFF12k1NRUnXrqqXU+Z9myZerWrWbAZ/ctaNqwYYMyMjI2es748eN1ww03qK1YNWn7jBQXSNl//wmlAACN9bvf/U7bbbed7rrrLne/X79+7sJLQxdfrLfnK6+8oiOO2LyZe1vqdeIFoVS8qh1Info/qduwcB8VwjjMbUV+iZavL/bW+cXu9spa2/KLm1551BqsYbYfJlUHTV5lk3e/+jHbl6baQBvqPEg67F5p76u9PlPfPC6tmi29er704d+8huhWQfXjq15fqoLl1c/N6VU9c55V7fL/3UaprKx0Dc1vvvlmd3/77bfXDz/84Ibo1RdKNceVV17pgi+fBVg2bLA1WRDlh1IAgNh36KGHqqysTG+//fZGj3322Wfac8899d1332n48Kb1P7YLNllZWS14pNL111+viRMnavr06TW2L126tMG+ji1hwoQJLmBbu3atoh2hVDwqypOetkDqOwKpOAqbLFTyb/th0/L8Eq3YzLDJWnwkJya6kTlubfeTbJ2g5MQE1wOkxpJQx7bA9uQk7zk245Lfp8nv0RRa0cSQOSAKZHeX9rtB2uNP0tQJ0lf/ktYvld67tuZ+NrnG0CO8IGqLUZse5oeNWHPyoUOH1thmPaL++9//1vuc7t27a/nykEBQcvdzcnLqrJIyaWlpbmlLuZkpmm8z8BFKAUBcOPPMM3X00Udr8eLF6t27d43H/FllmxpIGZsEpK3Yv7FoPEKpeAyknjpcWva9lNk5EEjVPJFF27JZ0UrKK91iQ9dKyisC67q31bWPLRZArVrf/LApPSVR3XLS1TU7TV0D62611hYMpaUk1giXqEIC0KD0HG/o3i7nSDNekCbdJ61b5PWZsiBqy328xuloNpt5b/bs2TW2/fzzz+rbt2+9zxk1apTefPPNGtvee+89tz2SBGfgKyKUAoB48Pvf/94FSFYJdM011wS3FxQU6MUXX9Q//vEPrV69WhdccIE+/fRTNwPtlltu6Yavn3jiifW+bu3hezZLrQVgkydP1oABA3T33Xdv9JwrrrjCDcOzgMyCppNOOknXXnutUlJS3PH5Q9r9v4csNDvttNM2Gr43Y8YMXXzxxa6fY2Zmpgvd7rjjDrVr1849bs+xiqfdd9/dTUBSWlqqE044wQ09tPdqjoULF+rCCy90s+smJibqwAMP1L333hscum/VZvZdfPPNN+54Bw0apIceesiFfgsWLHDfr02AYsdi35197wcffLBaA6FU3AVSh0nLZhBItbCyikrX88gqkVast6U4eHulVSYVlKq4tKKOcKmyWTO+NUXtsKlbdrq65ljQlKau2elu3SU7nWFuAFqXBU/bn+wtaFF//OMfNXr0aDd877jjjnMn2A8//LBbQofe/fbbb3rqqafc/XPOOUf33Xef/vznP+uMM87Qhx9+qBdeeEFvvPGGIonNZGqolAKAFmAzR5QVhee9UzIbNSw/OTlZY8eOdaHP1VdfHfz7xAKpiooKFzxZQDVy5EgXGlmFr/3bdcopp7hwauedd27UsPejjjrKBTRff/211q1bV2evqezsbHccPXv2dMGSTSBi2+zfzuOPP94Nlbdhhu+//77bv337jWcFLiwsdBOJ2EUfG0K4YsUKnXXWWS70sdf2ffTRR67y2dZz5851r289sRqatKShz3f44Ye70MsmQCkvL9f555/vXvPjjz92+1jAZsP9rSdlUlKSG4LoB2C2r4VRFvrZkMcff/wxGKC1BkKpeAyksrp4gVTXrcN9VBHPqo9W1gqZat72QqfVhaXuv/EtIS05UanJiW6Imt2uvh/YlpKo1KTE6nVgmz1ulUwucAoETxZCZacRNgFALNtpp53cFVkLnm688Ub179/fXV21E87Q/hZ21dRn+9hJvAVadnXYhkg8+uij7sQ5kthsqGYNoRQAbD4LpG7uGZ73vmqJlNq4nk52scQqcyxQsYblfhWSVRhZ8GPLZZddFtzfKoLeeecdd3GlMaGUhUg//fSTe44FTsYu7Bx00EE19gut1LJqIXvP5557zoVSNtTdghoL0Roarvfss8+quLjYXRTye1rZRSHrnXXrrbcGK5esB5Vtt4BoyJAhOuSQQ1yVU3NCKXuehWjz588P9n609x82bJgLxuy8wc4JLr/8cvdexiqlfPaYfdfbbrutu2+VZK2JUCoeFK72huwt9wOp16Wu3i9fPCuvqNT8VYX6eXmBlq7bEAifaoZO1ly1sWwom/U+8quSrPrIq05KU5d2acpKS64RLvm3Q7fZTHEESACA5gx3sKU+oVdjfXai/+233yqSdfQrpRi+BwBxw4ISqwB+/PHH3b9VVjlkTc7twouxiikLkSyEsipgq+opKSlxQ+MaY9asWS6s8QMpU9fw9eeff1733HOPfvnlF1edZRVHVpnVFPZeI0aMqNFk3YbdWzWTDb3vFgilLDCyQMpnVVMWLDWH//lCJyOx3pMdOnRwj1koZROXWMXW008/rTFjxujYY491lWbGZvA999xz9e6777rHLKBqTh+vxiKUiotA6jBp+Q9SVtdAhdSQuOvZtLKgRD8tXa/Zy9Zr1rJ8d3vuygI3hG5TrBqpS3b1cDdXgWRhU3a6uoTctr4XFkwBAICWYRNfGCqlAKCFhtBZxVK43rsJrN+TVUDdf//9rkrKApO99trLPWZVVFbla1XBVs1jgY8Nv7NwqqVY/yerOLa+UVZFbNVZViVlPZ9aQ0qt3lFWqGDBVWuxmQP/8Ic/uKrpt956S9ddd537fEceeaQLq+wz22MWTI0fP959bvt5tAZCqXgKpE57XeoyWLE+3G7O8oJg8DR7ube24XV1yUpN0qBu2eqdm7FR4OTfbp+RQvUSAADhrJQilAKAzWd/0zRyCF24WY9Eaw5uw99s6JlV7vh/k33xxReuZ9LJJ3t9Ki28sQk+as9EWx+boXbRokVuaLtVJJmvvvqqxj6TJk1yE4ZYXyufNQAPlZqa6qq2NvVeVq1svaX8aik7fms+Pnhw6/xt7n8+W/xqKesLZc3UQ7+jrbbayi02lN96dVn4Z6GUsedZ/0lbrD3AI488QiiFJipcJT15mLRiZkwGUpWVVfpt7QbNWpqvn5ZVV0D9uqpQlXX0drL/fvXvlKUhPbI1pHuOBnfP1tbdc1wYlUh1EwAAEV0pxfA9AIgv1q/JGnNbIJKfn+9mqPNZ/6OXXnrJBUfWi8lmslu+fHmjQykbkmZhzKmnnuqqruz1Q8Mn/z2st5JVD9lwN6sasv6NoazPlPVtsibh1pvRmqCnpaXV2MeqrawKyd7LqpNWrlzpwh1rzO4P3WsuC8TsvUPZ+9vnswoye2+rJrNhh+edd56rNLPZ9TZs2OD6SR1zzDGux6TNLmi9pmyYnrGqM+uvZd+RzW5ozdct6GothFKxprRImvOO9PGt0spZUrtuXg+pLlspWllfJwudfrLqJ1svzXf3C0vrTqVtGN2Q7l745NY9sjWoa7YyUqvH6AIAgMhn/6abNYWN7/EIAIgNNoTvscce08EHH1yj/5M1IJ83b54bYmZ9pM4++2wdccQRbha9xrAqJQuY7PWtMbqFS9Y76sADDwzuc9hhh7kKIpslz/pVWePxv/71ry5Y8lmI8/LLL2vvvfd2VUhWaRQanhk7PmuoblVfFm7ZfXueBWmbq6CgwM2gF8qGOVoPrldffdWFX3vuuaf7vPbZ7r33XreP9a5avXq1m+XQwrzOnTu72QhtqKIfdtkMfBZWWQ8te+6dd96p1pJQZQ13UIMlpTZm1H6pm9rILCzKS6S5H0g//Fea/ZZUVuhtj8JAypqM//DbOv3wW75bz1yS7yqi6uv1NLBru0D1UyCE6pHtmooz3A4A0Fqi7jwhir8HuzA14oZ33e3ZfzvQTQoCAGgcm/XNKnmsGiY9PT3ch4M4+x3Lb+R5ApVS0aqiTJr3iTTzZWnW61JJSCrcfgtpm6OkncdJ7XsrElkWuiy/WDMWr9MPS7wAyhab8a4uvTpkuODJht0N6ZGjrbtnq1/nLKUkJbb5sQMAgLaRk57sJhGpqKzS2qIydcshlAIAIJYQSkWTygppwRdeRdSPr0kb8qofy+4hDTtS2uZoqddIr4lSBAVQi9ds8IKnJes047d8zfxtXZ3Nx62905Zd2mmbXu01rGeOW2/dI8c1GwcAAPHFKp9zM1O1qqDENTvvlsOVfgAAYgmhVKSzaSAXT5Z+eFn6caJUsLz6sczO0rAjpGFHSVuMssGxioQG5AvyioIBlD8Uz8rva7Mrn4O6egHUNj1ztG1vL4DKTOXXEgAAeDpmpQRDKQAAEFv46z8SWZuvJd96FVEzJ0r5i6sfS+8gbX2oVxHVbw8pKXw/Qiuln7+qwIVOMwLD735ckq/1JeUb7ZuSlOCG3m3Ts72G9WqvbXu1d8Px0lMowwcAAPWzSilDKAUAQOwhlIqkIGr5TK9HlIVRa36tfiw1WxpyiNcnasDeUrJ3chYuxWUVeuzz+Xr403l1VkClJie6iierftomEEAN6taO5qQAAKD5M/AVEUoBABBrCKXCbeXPgSDqZWnV7OrtyRnS4AO9iqiB+0kp6RExNG/i9N/0z3dma8m6YrctIyVJQy186pkTrICyGfFoQA4AAFpCbiCUolIKAJrf4xdoDZXWbmgzEUqFg1VBWQhly/IZ1duTUqVB+3sNy7c6UEprp0gxae4q/f3NWZq5JN/d79k+XZcfOFiHDu+pZAIoAADQSjr5lVKEUgDQJCkpKW7CiJUrV6pLly7uNtBSQWdpaan73UpMTFRqavNHcxFKtbVvnpBev6T6fmKytOU+XrPyIQdL6e0VSeYsX6/xb/2kD39a4e5npyXrvL0H6vTd+tEPCgAAtF1PqaKNWwYAAOqXlJSk3r17a/Hixfr115D2MEALyczM1BZbbOGCqeYilGpr1pw8IdFb29A8a1qe2VGRZsX6Yt353hw9P2WhKquk5MQEnbxrX124z0B1apcW7sMDAADx1lOKSikAaLJ27dpp0KBBKisj2EfLh57JycmbXYFHKNXWOg+ULpsrZXVSJCoqLdejn83Xg5/8oqLSCrftgGHddMWBQzSgS+QMJwQAAPHVU2o1oRQANDs8sAWIRIRS4RCBgVRFZZX+O3Wxbn9vtpbnl7htI/p00DWHbK2d+kVeJRcAAIgPHQPD96iUAgAg9hBKQZ/+vFI3vzlLPy1b7+73zs1wlVG/H96DZngAACCscrNS3DqvqNQ1VuXcBACA2EEoFcdmLc13YdRnc1a5+znpybpo30E6ZVRfpSVT3gkAAMKvU5bXy7K0vNK1FshK4/QVAIBYwb/qcWjZumLd8d5svTh1saqqpJSkBI0d1c81Me8QKJEHAACIBBmpSUpPSVRxWaXyCksJpQAAiCH8qx5HCkrK9fAnv+jhz+a5EztzyPAe+vMBg9W3U1a4Dw8AAKDevlJL1hVrTVGp+nTMDPfhAACAFkIoFQfKKyr1/DeLdOd7c7SqwGtiPrJvrq46eGu3BgAAiPQZ+CyUYgY+AABiC6FUDLNmoB/NXqGb3/xJc1cUuG39OmXqLwcN0QHDutMoFAAARIWOWczABwBALCKUilE//LbONTGf9Mtqdz83M8U1MT9pl75KTU4M9+EBAAA0Wm6g56X1lAIAALGDUCpGA6nD7/9CFZVVLoA6fbd+Ou93A9U+w5tSGQAAICorpYoIpQAAiCWEUjFo1tJ8F0gN6tpOT5y+k3rn0hAUAABEfyiVV1gW7kMBAAAtiHFcMci/irhtr/YEUgAAICYanRt6SgEAEFsIpWKQfxXRP4EDAACIZh3pKQUAQEwilIpB/lVEv9QdAAAgmuVmeX0x8+gpBQBATCGUikH+CVuHTBqbAwCAGGp0TqUUAAAxhVAqliulAqXuAAAA0cw/p7G+mZWVVeE+HAAA0EIIpWK4UoqeUgAAIBb45zSWR+UXMwMfAACxglAqBtFTCgAAxJKUpERlpye72zQ7BwAgdhBKxZiKyiqt2xCYfY/hewAAINb6StHsHACAmEEoFWPyN5S50nZDo3MAABAr/IttqwsIpQAAiBWEUjHaTyonPdmVugMAAMQCKqUAAIg9pBYxhn5SAAAgliul8gppdA4AQKwglIoxfvPPDvSTAgAAMaRjlteWgEopAABiB6FUjPFP1KiUAgAAsaRjVppbM/seAACxg1Aqxvgl7cy8BwAAYrJSilAKAICYQSgVs5VSzLwHAEC8uP7665WQkFBjGTJkSL37T5gwYaP909PTFRWz7xFKAQAQM5LDfQBoWf7Vw1yG7wEAEFeGDRum999/P3g/Obnh07ycnBzNnj07eN+CqUjG7HsAAMQeQqlYrZRi+B4AAHHFQqju3bs3en8LoZqyf7j5F9zoKQUAQOxg+F6M8U/UqJQCACC+zJkzRz179tSAAQN00kknaeHChQ3uX1BQoL59+6pPnz46/PDDNXPmzAb3LykpUX5+fo2lLfkX3NYXl6usorJN3xsAALQOQqkYs6bIa3TO7HsAAMSPXXbZxfWJevvtt/XAAw9o/vz52mOPPbR+/fo69x88eLAef/xxvfrqq3rmmWdUWVmp0aNHa/HixfW+x/jx49W+ffvgYmFWW2qfkaLEwAhDhvABABAbCKVitVKK4XsAAMSNgw46SMcee6yGDx+uAw44QG+++abWrl2rF154oc79R40apbFjx2q77bbTXnvtpZdfflldunTRQw89VO97XHnllVq3bl1wWbRokdpSYmJC8PxmTWC2YQAAEN3oKRVDyisqtW6Dd5KWm8nsewAAxKsOHTpoq6220ty5cxu1f0pKirbffvsG909LS3NLOFl7Apt9b3VhiaTssB4LAADYfFRKxZC1gUDKJs+xEncAABCfrF/UL7/8oh49ejRq/4qKCs2YMaPR+4eL31eKSikAAGIDoVQMWRMYumeBVHISP1oAAOLFZZddpk8++US//vqrJk2apCOPPFJJSUk68cQT3eM2VM+G3/luvPFGvfvuu5o3b56mTZumk08+WQsWLNBZZ52lSJab5V10y6OnFAAAMYHhezHYT8q/iggAAOKDNSi3AGr16tWuN9Tuu++ur776yt02NhNfYmL1Bas1a9Zo3LhxWrZsmXJzczVy5EgXZg0dOlSRzJ/Ixb8QBwAAolvYy2nuv/9+9evXT+np6W7mmMmTJze4vzXtPP/88115ufU1sH4J1sxzc14z1mbes34LAAAgfjz33HNasmSJSkpKXEBl97fccsvg4x9//LGbnc935513usoo29+CqTfeeMP1lIp0fqNz/0IcAACIbmENpZ5//nldeumluu6661zp+IgRI9yMMStWrKhz/9LSUu23336uNP2ll17S7Nmz9cgjj6hXr17Nfs1Y4k+PzMx7AAAgFgUrpRi+BwBATAhrKHXHHXe40vHTTz/dlYs/+OCDyszM1OOPP17n/rY9Ly9PEydO1G677eaqoWwaYwuemvuaMTl8L9BvAQAAIBZDKSqlAACIDWELpazqaerUqRozZkz1wSQmuvtffvllnc957bXXNGrUKDd8r1u3btpmm2108803uxljmvuascTvr8DwPQAAEIv8cxxCKQAAYkPYGp2vWrXKhUkWLoWy+z/99FOdz7EZYj788EOddNJJro/U3Llzdd5556msrMwN12vOaxrrp2CLLz8/X9HIn4mGRucAACAW+ec4NDoHACA2hL3ReVNUVlaqa9euevjhh90sMccff7yuvvpqN0Rvc4wfP17t27cPLn369FFUV0oRSgEAgFgevkdPKQAAYkLYQqnOnTsrKSlJy5cvr7Hd7nfv3r3O59iMezbbnj3Pt/XWW7tZY2zoXnNe01x55ZVat25dcFm0aJGiUR6z7wEAgBjmn+MUl1VqQ6nXvgEAAESvsIVSqamprtrpgw8+qFEJZfetb1RdrLm5Ddmz/Xw///yzC6vs9ZrzmiYtLU05OTk1lmiulKLROQAAiEVZqUlKTfZOX6mWAgAg+oV1+N6ll16qRx55RE8++aRmzZqlc889V4WFhW7mPDN27FhXxeSzx232vYsvvtiFUW+88YZrdG6Nzxv7mrGM4XsAACCWJSQk0FcKAIAYErZG58Z6Qq1cuVLXXnutG4K33Xbb6e233w42Kl+4cKGbPc9nvZ7eeecd/fGPf9Tw4cPVq1cvF1BdccUVjX7NWFVWUan1JeU1+i0AAADE4hC+ZfnFWk0oBQBA1AtrKGUuuOACt9Tl448/3mibDcP76quvmv2asWpNoIQ9MUHKSWf4HgAAiE1+mwIqpQAAiH5RNfse6remMNDkPDNViZZMAQAAxCC/TUEeoRQAAFGPUCpG+CdmzLwHAABimd+mwK8SBwAA0YtQKkb4J2a5mQzdAwAAsYtKKQAAYgehVKxVSjHzHgAAiGGd2lEpBQBArCCUihF+s09m3gMAALGMSikAAGIHoVSMyPOH7xFKAQCAGOZfgCOUAgAg+hFKxVqlFMP3AABAXFRKeTMPAwCA6EUoFSPWFHknZlRKAQCAeJl9r6qqKtyHAwAANgOhVIzwm312zGL2PQAAELtyA+c6FZVVyi8uD/fhAACAzUAoFSOYfQ8AAMSDtOQktUtLrtG+AAAARCdCqRjB7HsAACDeqqX8iV4AAEB0IpSKAcVlFSosrXC3O1ApBQAAYpw/sUteAaEUAADRjFAqBqwNNDlPSkxQTrpXzg4AABCr/IldqJQCACC6EUrFWD+phISEcB8OAABAm1RK0VMKAIDoRigVA5h5DwAAxBMqpQAAiA2EUjEUSjHzHgAAiAf+xC5USgEAEN0IpWIAM+8BAIB44p/z5BV6fTUBAEB0IpSKAf4JmV/KDgAAEMv86vC8wpJwHwoAANgMhFKx1FOK4XsAACCehu8FZiAGAADRiVAqhmbf65BJo3MAABD7/Mld/HMgAAAQnQilYmr2PSqlAABA/AzfW7ehTOUVleE+HAAA0EyEUjHAv0pITykAABAPOmSmKiHBu712A0P4AACIVoRSsTT7Hj2lAABAHEhKTFCHjJQa50EAACD6EErFgDyG7wEAgDjjV4jTVwoAgOhFKBXlNpRWqLjM66XA8D0AABAv/ApxQikAAKIXoVSMNDlPTUpUVmpSuA8HAACgbSulAudCAAAg+hBKxUyT8xQl+B0/AQAA4qRSip5SAABEL0KpGKmU8qdGBgAAiK+eUsy+BwBAtCKUipVKKUIpAADi1vXXX+8qpkOXIUOGNPicF1980e2Tnp6ubbfdVm+++aaiSadAKOVfoAMAANGHUCrK+SXrzLwHAEB8GzZsmJYuXRpcPv/883r3nTRpkk488USdeeaZ+vbbb3XEEUe45YcfflC0YPY9AACiH6FUlMsrKgv2lAIAAPErOTlZ3bt3Dy6dO3eud9+7775bBx54oC6//HJtvfXWuummm7TDDjvovvvuU7ToGDj3IZQCACB6EUrFSqUUw/cAAIhrc+bMUc+ePTVgwACddNJJWrhwYb37fvnllxozZkyNbQcccIDbHi381gWEUgAARK/kcB8ANo8/DbJfwg4AAOLPLrvsogkTJmjw4MFu6N4NN9ygPfbYww3Hy87O3mj/ZcuWqVu3bjW22X3bXp+SkhK3+PLz8xVOfusCekoBABC9CKWi3NrAiRg9pQAAiF8HHXRQ8Pbw4cNdSNW3b1+98MILrm9USxg/frwLuyKFf0GuqLRCxWUVSk9JCvchAQCAJmL4XpTzp0Fm9j0AAODr0KGDttpqK82dO7fOx63n1PLly2tss/u2vT5XXnml1q1bF1wWLVqkcMpOS1ZKUoK7TbUUAADRiVAqyjH7HgAAqK2goEC//PKLevToUefjo0aN0gcffFBj23vvvee21yctLU05OTk1lnBKSEigrxQAAFGOUCqKVVVVBXtKdchk9j0AAOLVZZddpk8++US//vqrJk2apCOPPFJJSUk68cQT3eNjx451lU6+iy++WG+//bZuv/12/fTTT7r++uv1zTff6IILLlA0CfaVClSOAwCA6EJPqShmPRRKyyvdbSqlAACIX4sXL3YB1OrVq9WlSxftvvvu+uqrr9xtYzPxJSZWX4scPXq0nn32WV1zzTW66qqrNGjQIE2cOFHbbLONoolfKbW6sLoBOwAAiB6EUlHML1VPS05UBs09AQCIW88991yDj3/88ccbbTv22GPdEs2qK6UYvgcAQDRi+F4U85t62gmZ9VUAAACIJ7lZXvuCvCKG7wEAEI0IpWKgUoqZ9wAAQDzqGDgHolIKAIDoRCgVI5VSAAAA8cY/B/InfgEAANGFUCqK+TPN5BJKAQCAOOSfA1EpBQBAdCKUioVKqUyvnwIAAEBcVkoRSgEAEJUIpWKhpxSVUgAAIA75fTUJpQAAiE6EUjFQKUWjcwAAEM+VUnZOVFVVFe7DAQAATUQoFcWolAIAAPHMvzBXVlGlgpLycB8OAABoIkKpGGh07k+HDAAAEE8yUpOUkZJU47wIAABED0KpKOZPf5ybRaNzAAAQ583OA+dFAAAgehBKRSnrm+BPf+yfjAEAAMTvDHwl4T4UAADQRIRSUWp9SbnKK72GnjQ6BwAA8crvrZnH8D0AAKIOoVSUWhs48cpMTVJ6oJcCAABAvOmY6bUx8CvIAQBA9CCUivZ+UlRJAQCAOBaslKKnFAAAUYdQKkr5VwNpcg4AAOKZPwsxlVIAAEQfQqkoleeHUlRKAQCAONaxnd9TilAKAIBoQygVpdYEStSZeQ8AAMSzYKUUw/cAAIg6hFJRikopAACA6p5Sq6mUAgAg6hBKRSkqpQAAAKrPhegpBQBA9CGUivZKKUIpAAAQx/yq8bUbylRRWRXuwwEAAE1AKBWl1hSV1eijAAAAEI86ZHozEVdVSes2eOdHAAAgOhBKRSm/RD03yzsRAwAAiEcpSYnKSU92t5mBDwCA6EIoFaXoKQUAAODp1C7NrZmBDwCA6EIoFYUqK6uCw/eYfQ8AAMS73MAQvtUFhFIAAEQTQqkotL64PNjI0++jAAAAoHifgY9KKQAAogqhVBTKC5xwtUtLVlpyUrgPBwAAIKz8ynF6SgEAEF0IpaKQf8JFk3MAAICQSilCKQAAogqhVBTyT7g60k8KAABAuYFQyq8mBwAA0SEiQqn7779f/fr1U3p6unbZZRdNnjy53n0nTJighISEGos9L9Rpp5220T4HHnigYoV/wuWfgAEAAMQzKqUAAIhOyeE+gOeff16XXnqpHnzwQRdI3XXXXTrggAM0e/Zsde3atc7n5OTkuMd9FjrVZiHUE088EbyfluZNFRwL1gZCKSqlAAAAqs+J6CkFAEB0CXul1B133KFx48bp9NNP19ChQ104lZmZqccff7ze51gI1b179+DSrVu3jfaxECp0n9zcXMWKvMIyt6ZSCgAAgOF7AABEq7CGUqWlpZo6darGjBlTfUCJie7+l19+We/zCgoK1LdvX/Xp00eHH364Zs6cudE+H3/8sau0Gjx4sM4991ytXr1ascIvTc/NpNE5AABA9fA978IdAACIDmENpVatWqWKioqNKp3s/rJly+p8joVMVkX16quv6plnnlFlZaVGjx6txYsX1xi699RTT+mDDz7Qrbfeqk8++UQHHXSQe6+6lJSUKD8/v8YSyegpBQAAsPHwvYKScpWU132+BwAAYqCnlDUkP+OMM1wz8S222EJtbdSoUW7xWSC19dZb66GHHtJNN93ktp1wwgnBx7fddlsNHz5cW265paue2nfffTd6zfHjx+uGG25QtGD2PQAAgGrZ6clKSkxQRWWV1haVqVtOUrgPCQAAtEal1CWXXKKXX35ZAwYM0H777afnnnvOVRo1R+fOnZWUlKTly5fX2G73rQ9UY6SkpGj77bfX3Llz693HjtXeq759rrzySq1bty64LFq0SJGMSikAAIBqiYkJwbYGNDsHACDGQ6np06dr8uTJrkLpwgsvVI8ePXTBBRdo2rRpTXqt1NRUjRw50g2z89lwPLsfWg3VEBuSN2PGDHcM9bGhfdZTqr59rCm6zegXukRFpRShFAAAQK2+UoRSAADEfE+pHXbYQffcc4+WLFmi6667To8++qh22mknbbfddq7nU1VVVaNe59JLL9UjjzyiJ598UrNmzXJNyQsLC91sfGbs2LGuksl344036t1339W8efNcCHbyySdrwYIFOuuss4JN0C+//HJ99dVX+vXXX13AZc3QBw4cqAMOOEDRzpWlbwjMvsfwPQAAgBrnRasJpQAAiN2eUr6ysjK98soreuKJJ/Tee+9p11131Zlnnumqkq666iq9//77evbZZzf5Oscff7xWrlypa6+91jU3t1Dr7bffDjY/X7hwoZuRz7dmzRqNGzfO7Zubm+sqrSZNmqShQ4e6x2044Pfff+9CrrVr16pnz57af//9Xb8pq4iKdus2lMnP+zow+x4AAEDNSqlAmwMAABCDoZRVJ1kQ9Z///MeFRVbJdOedd2rIkCHBfY488khXNdVYNvTPlrpYc/JQ9l621CcjI0PvvPOOYpV/opWTnqyUpLBOnggAABAx/F6b9JQCACB6NDnVsLBpzpw5euCBB/Tbb7/pn//8Z41AyvTv37/GDHhoOfSTAgAADbnllluUkJDg+oDWZ8KECW6f0CU9PV3RzJ+VmJ5SAADEcKWU9XLq27dvg/tkZWW5aiq0PP/qXwf6SQEAgFqmTJmihx56SMOHD9/kvjaxy+zZs4P3LZiKiUqpIq/3JgAAiMFKqRUrVujrr7/eaLtt++abb1rquLCJ4XtUSgEAgFA22ctJJ53kJpCxvpubYiFU9+7dg4vfzzNadWL2PQAAYj+UOv/887Vo0aKNtttQPnsMrSuvkJn3AADAxuw87JBDDtGYMWMaHWJZ9XufPn3cTMUzZ85ULFRKMfseAAAxPHzvxx9/1A477LDR9u233949hraqlGLmPQAA4HnuuefcZDQ2fK8xBg8erMcff9wN81u3bp3rETp69GgXTPXu3bvO55SUlLjFl5+fr0hCTykAAOKgUiotLU3Lly/faPvSpUuVnNzkjAvN7CnlXw0EAADxzSrYL774Yv373/9udLPyUaNGuRmUt9tuO+211156+eWX1aVLF9ePqj7jx49X+/btg4tVWEWS3MAFu7yiUlVVVYX7cAAAQGuEUvvvv7+uvPJKd1XNt3btWl111VXab7/9mvpyaO7sewzfAwAAkqZOnep6flolu10gtOWTTz7RPffc425XVFRs8jVSUlJc1fvcuXPr3cc///OXuto5hJPfb7O0vFJFpZv+zAAAIPyaXNpk5d177rmn60FgJy9m+vTprjnm008/3RrHiBB29c9QKQUAAMy+++6rGTNm1Nh2+umna8iQIbriiiuUlJS0ydew4Mpe4+CDD26wWt6WSJWRkqS05ESVlFe6yvKsNCr4AQCIdE3+17pXr176/vvvXYn4d999p4yMDHfic+KJJ7qrbGhdawPTHDP7HgAAMNnZ2dpmm21qbMvKylKnTp2C222onp3D2RA8c+ONN2rXXXfVwIEDXcX7P/7xDy1YsEBnnXWWopXNJmjnR0vXFbsenH06Zob7kAAAwCY06xKSneicffbZzXkqWqqnFMP3AABAIy1cuFCJidVdG9asWaNx48Zp2bJlys3N1ciRIzVp0iQNHTpU0cwPpfzzJQAAENmaXddsM+3ZCU5pac1/9A877LCWOC7UobyiUus2eJVSuZlUpQEAgLp9/PHHDd6/88473RJr/EpyQikAAGI0lJo3b56OPPJI13fAyqT92U3stmlMM000z9pAIGVfdfsMQikAAIBQfiU5oRQAADE6+55NOdy/f383y0tmZqZmzpypTz/9VDvuuONGV+HQOjPvWSCVnNTkHx0AAIgwNoPd4sWLg/cnT56sSy65RA8//HBYjyvaK6WspxQAAIh8TU42vvzyS9ccs3Pnzq43gS277767a5x50UUXtc5RosZVv470kwIAICb84Q9/0EcffeRuW3+n/fbbzwVTV199tTvfQnMrpbzqcgAAEGOhlA3Ps1lejAVTS5Yscbf79u2r2bNnt/wRIsi/6pfLzHsAAMSEH374QTvvvLO7/cILL7jZ8qzhuM1yPGHChHAfXtTpmJVSo7ocAADEWE8pO1n67rvv3BC+XXbZRbfddptSU1NdmfmAAQNa5yhR46ofM+8BABAbysrKlJaW5m6///77wQljhgwZoqVLl4b56KJPxyzvu8xj+B4AALFZKXXNNdeosrLS3bay8vnz52uPPfbQm2++qXvuuac1jhG1KqX8q4AAACC6DRs2TA8++KA+++wzvffeezrwwAPddqtE79SpU7gPL+rkBs6RaHQOAECMVkodcMABwdsDBw7UTz/9pLy8POXm5gZn4EPr8EvRGb4HAEBsuPXWW92sxv/4xz906qmnasSIEW77a6+9FhzWh2Y0OieUAgAg9kIpKzHPyMjQ9OnT3TA+X8eOHVvj2FCLX4rO8D0AAGLD7373O61atUr5+fnuAp/v7LPPdrMco2n8yWCsuryyskqJiVwwBQAgZobvpaSkaIsttnDNztH2/Kt+zL4HAEBs2LBhg0pKSoKB1IIFC3TXXXe5yWO6du0a7sOLOh0C50iVVVJ+MTPwAQAQcz2lbIriq666yg3ZQ9vKKwo0Omf4HgAAMeHwww/XU0895W6vXbvWTSJz++2364gjjtADDzwQ7sOLOqnJicpO8wYC0FcKAIAYDKXuu+8+ffrpp+rZs6cGDx6sHXbYocaCNqiUotE5AAAxYdq0aW7CGPPSSy+pW7durlrKgiomkGke/+KdP0EMAACIoUbnduUOYW50zvA9AABiQlFRkbKzs93td999V0cddZQSExO16667unAKzWt2vjCvSKsLCKUAAIi5UOq6665rnSNBg0rLK7W+pLzGzDIAACC62UzGEydOdDPwvfPOO/rjH//otq9YsUI5OTnhPrzonoGPSikAAGJv+B7CY23gxMomkclJZ/geAACx4Nprr9Vll12mfv36aeedd9aoUaOCVVPbb799uA8vKvkV5XmFNDoHACDmKqWspDwhof7pdZmZr3Ws8ZucZ6YyvTEAADHimGOO0e67766lS5dqxIgRwe377ruvq55C0/m9N6mUAgAgBkOpV155pcb9srIyffvtt3ryySd1ww03tOSxIYQ/gwwz7wEAEFu6d+/ulsWLF7v7vXv3dlVTaB7/XInZ9wAAiMFQyqYurusq37Bhw/T888/rzDPPbKljQwj/al9uJkP3AACIFZWVlfrb3/6m22+/XQUFBW6bNT7/05/+pKuvvtpVqKNpOgaG7/kTxAAAgBgKpepjs8ScffbZLfVyqK9Sipn3AACIGRY8PfbYY7rlllu02267uW2ff/65rr/+ehUXF+vvf/97uA8xahud5zF8DwCA+AilNmzYoHvuuUe9evVqiZdDHfyrfcy8BwBA7LD2B48++qgOO+yw4Lbhw4e7c6rzzjuPUGpzQikqpQAAiL1QKjc3t0aj86qqKq1fv16ZmZl65plnWvr4EOBf7aOnFAAAsSMvL09DhgzZaLtts8fQdPSUAgAghkOpO++8s0YoZb0OunTpol122cUFVmjlSimG7wEAEDNsxr377rvPVZyHsm1WMYWm88+V1heXq6yiUilJ9OUCACBmQqnTTjutdY4EDcorKnNrKqUAAIgdt912mw455BC9//77GjVqlNv25ZdfatGiRXrzzTfDfXhRKScjRYkJUmWVN1FM1+z0cB8SAACoR5MvHT3xxBN68cUXN9pu26wvAlq7pxSz7wEAECv22msv/fzzzzryyCO1du1atxx11FGaOXOmnn766XAfXlRKSkxQh+AMfN5FPQAAECOh1Pjx49W5c+eNtnft2lU333xzSx0XarErfYbZ9wAAiC09e/Z0Dc3/+9//uuVvf/ub1qxZ42blQ/PkZnoX8egrBQBAjIVSCxcuVP/+/Tfa3rdvX/cYWrdSilAKAACgYZ2y0tyaUAoAgBgLpawi6vvvv99o+3fffadOnTq11HEhRHFZhQpLK9xtekoBAAA0LDfQ7sCfvRgAAMRIKHXiiSfqoosu0kcffaSKigq3fPjhh7r44ot1wgkntM5Rxrm1gSbn1iMhJ73JvekBAADiSsfARTy/0hwAAESmJiccN910k3799Vftu+++Sk72nl5ZWamxY8fSU6qV5IUM3UtISAj34QAAgM1kzcwbYg3P0Xx+uwOG7wEAEGOhVGpqqp5//nnXhHP69OnKyMjQtttu63pKoXWbnDPzHgAAsaF9+/abfNwu+GEzK6UYvgcAQERr9liwQYMGuQVtWykFAACi3xNPPBHuQ4hpVEoBABCjodTRRx+tnXfeWVdccUWN7bfddpumTJmiF198sSWPDzUqpQilAAAANqVjO7+nVIlUUiBtyJM2rKm5FOVJxeukQftL/fcI9yEDABCXmhxKffrpp7r++us32n7QQQfp9ttvb6njQl2VUoRSAAAgHlVVSSXrawVLoUHT2hph06j1qzQlbaU65BVK48sbfu2pT0qX/iiltWurTwMAAJobShUUFLi+UrWlpKQoPz+/qS+HJsy+15HhewAAIB6s/Fl67YKaIVTlJsKlEOm2hM4Nk5QqZXSUMnJrLr98KK1fIs14QdrxjFb5KAAAoAVDKWtqbo3Or7322hrbn3vuOQ0dOrSpL4cmVEp1yKTROQAAiBOLvt54W1KalOmHS7busHHQlNlRG5JzdNQTs7S2qp0+vOYIZWRlS3XNYPzlv6R3rpQmPyKNPL3ufQAAQOSEUn/961/dNMa//PKL9tlnH7ftgw8+0LPPPquXXnqpNY4x7tFTCgAAxJX2vaXjng6GTMHAKSWjUU9Pr6rSL4nFKq2oVF55inrVFzZt9wfpw5ukFT9KC76Q+u3esp8DAAA0KFFNdOihh2rixImaO3euzjvvPP3pT3/Sb7/9pg8//FADBw5s6suhEegpBQAA4kpqpjT0MK8BebdhUk7PRgdSJiEhQblZXoX5moZm4LNKq+HHebetWgoAAER2KGUOOeQQffHFFyosLNS8efN03HHH6bLLLtOIESNa/ggRPJmipxQAAEDj5AbOm/yLe/XaaZy3nvU/KX9JGxwZAADYrFDKn4Xv1FNPVc+ePd2sezaU76uvvmruy6EBeQzfAwAAaJJO7RoZSnXfRuq7m1RVIX3zRNscHAAAaHpPqWXLlmnChAl67LHH3Ex7ViFVUlLihvPR5Lx1bCitUHFZpbvN8D0AAIAWrpQyO4/zekpNfULa8zIpOa31DxAAADS+Usp6SQ0ePFjff/+97rrrLi1ZskT33ntv6x4dglVSqUmJykpNCvfhAACACHfLLbe4nkqXXHJJg/u9+OKLGjJkiNLT093sym+++aZiiV9h7k8Y06Ahv5eye0iFK6UfX2v9gwMAAE0Lpd566y2deeaZuuGGG1xPqaQkApK27CdlzTrtBBMAAKA+U6ZM0UMPPaThw4c3uN+kSZN04oknunO7b7/9VkcccYRbfvjhB8VlpVRSirTjGd7tyQ+38pEBAIAmh1Kff/651q9fr5EjR2qXXXbRfffdp1WrVjX26Wgm/+qef2IFAABQl4KCAp100kl65JFHlJub2+C+d999tw488EBdfvnl2nrrrXXTTTdphx12cOd3cVkpZXY4VUpMkRZPlpZ827oHBwAAmhZK7brrru4kZ+nSpfq///s/Pffcc67JeWVlpd577z0XWKHl+Vf3CKUAAEBDzj//fFfNPmbMmE3u++WXX2603wEHHOC218f6iFpP0dAlkvm9OBtVKWWyu0nDjvBuT360FY8MAAA0e/a9rKwsnXHGGa5yasaMGfrTn/7kehd07dpVhx12WFNfDo0cvsfMewAAoD52sXDatGkaP358oyev6datW41tdt+218deu3379sGlT58+imSdmhpKmZ3P9tY/vCQV5bXSkQEAgGaHUqGs8fltt92mxYsX6z//+c/mvBTqkVdUFuwpBQAAUNuiRYt08cUX69///rdrWt5arrzySq1bty642PtGR08p71yqUXrvJHUfLpUXS98+3XoHBwAANj+U8lnTc2uO+dprzFbSapVSDN8DAAB1mDp1qlasWOF6QiUnJ7vlk08+0T333ONuV1RUbPSc7t27a/ny5TW22X3bXp+0tDTl5OTUWKKlp1RVVVXjnmSTyvjVUlMelSo3/u4AAECEhVJoPXl+o3OG7wEAgDrsu+++rqXC9OnTg8uOO+7omp7b7bpmTB41apQ++OCDGtusR6htjxUdMr0q84rKKuUXlzf+idseI2XkSmsXSnPebb0DBAAASg73AaBh9JQCAAANyc7O1jbbbLNRD9BOnToFt48dO1a9evUK9pyy4X577bWXbr/9dtcc3XpSffPNN3r44YcVK9JTkpSVmqTC0gp3PtU+o5GtEFIypO1PkSbdI01+WBp8UGsfKgAAcYtKqQjH7HsAAGBzLVy40M2g7Bs9erSeffZZF0KNGDFCL730kiZOnLhRuBXtgjPwBSrPG22nM20sn/TLh9KqOa1zcAAAgEqpSLc20OicSikAANBYH3/8cYP3zbHHHuuWWGbnT4vXbAhWnjdabj9pqwOln9/yeksddGtrHSIAAHGNSqkIZk05/St7fl8EAAAANI5/UW91U0Mps/M4bz39WamkoIWPDAAAGEKpCFZUWqHS8kp3m0opAACApvFnL25ypZQZsLfUaaBUki99/3zLHxwAACCUioZ+UmnJicpI2XjmHAAAALRCTymTmCjtdJZ3e/IjVsLewkcHAAAIpSLYmsAJlFVJJSQkhPtwAAAAoopfad6sSikz4kQpJUtaOUv69fOWPTgAAEAoFcmYeQ8AAKD5/HOovEJv4pgmy+ggjTjeuz354RY8MgAAYAiloqRSCgAAAE3TMSulxjlVs+wUaHj+0xvSusUtdGQAAMAQSkUw/6qe3w8BAAAAjdcxK61G9XmzdBsq9dtDqqqQvnmi5Q4OAABERih1//33q1+/fkpPT9cuu+yiyZMn17vvhAkTXH+l0MWeF6qqqkrXXnutevTooYyMDI0ZM0Zz5sxRtPH7H3TM9K7yAQAAoOmVUpsVSpmdA9VSUydI5SUtcGQAACAiQqnnn39el156qa677jpNmzZNI0aM0AEHHKAVK1bU+5ycnBwtXbo0uCxYsKDG47fddpvuuecePfjgg/r666+VlZXlXrO4uFjRxC8170BPKQAAgGb3lFq3oUzlFZXNf6HBh0g5vaSiVdKPr7bcAQIAEOfCHkrdcccdGjdunE4//XQNHTrUBUmZmZl6/PHH632OVUd17949uHTr1q1GldRdd92la665RocffriGDx+up556SkuWLNHEiRMVTegpBQAA0HztM1LkT2C8dkMzm52bpGRpx9O92zQ8BwAgNkKp0tJSTZ061Q2vCx5QYqK7/+WXX9b7vIKCAvXt21d9+vRxwdPMmTODj82fP1/Lli2r8Zrt27d3wwLre82SkhLl5+fXWCJq9j1CKQAAgCZLTkp0wVRoW4Rm2+FUKTFFWjxF+m1ayxwgAABxLqyh1KpVq1RRUVGj0snYfQuW6jJ48GBXRfXqq6/qmWeeUWVlpUaPHq3Fi73ZUPznNeU1x48f74Irf7GwKxKsCTQ678jwPQAAgGbxz6M2u69Uu67SsCO921MebYEjAwAAYR++11SjRo3S2LFjtd1222mvvfbSyy+/rC5duuihhx5q9mteeeWVWrduXXBZtGiRIkFeYPhebqBJJwAAAJrGrzjf7FDK7Hy2t57xklS4evNfDwCAOBfWUKpz585KSkrS8uXLa2y3+9YrqjFSUlK0/fbba+7cue6+/7ymvGZaWpprnh66hJv1xgrOvsfwPQAAgGbxz6P8i32bpfeOUo/tpIoS6dunNv/1AACIc2ENpVJTUzVy5Eh98MEHwW02HM/uW0VUY9jwvxkzZqhHjx7ufv/+/V34FPqa1iPKZuFr7GtGgvUl5SqvrKoxcwwAAACaN3xvs3tKGeua7ldLTXlMqqzY/NcEACCOhX343qWXXqpHHnlETz75pGbNmqVzzz1XhYWFbjY+Y0P1bHid78Ybb9S7776refPmadq0aTr55JO1YMECnXXWWcGZ+S655BL97W9/02uvveYCK3uNnj176ogjjlC08E+cMlOTlJ6SFO7DAQAAiPLhe5sx+16obY6SMjpK6xZJP7/dMq8JAECcSg73ARx//PFauXKlrr32WteI3HpFvf3228FG5QsXLnQz8vnWrFmjcePGuX1zc3NdpdWkSZM0dOjQ4D5//vOfXbB19tlna+3atdp9993da6anpytaBGfeo0oKAACg2ToGenOuaYnheyYlQ9phrPTFXdLkR6Qhh7TM6wIAEIcSqqx5EWqw4X42C581PQ9Xf6mPflqh0ydM0Ta9cvT6hXuE5RgAAEBknidEgmj5Hl78ZpEuf+l77bVVFz15xs4t86JrFkj3bCdVVUrnT5G6bNUyrwsAQJydJ4R9+B7qRqUUAABAyzU6b7FKKZPbV9rqQO/2lEdb7nUBAIgzhFIRyj9xYuY9AACA5vPPpVYXtGAoZXYe562nPyuVrG/Z1wYAIE4QSkUoKqUAAAAitFLK9P+d1GmQVLpe+u65ln1tAADiBKFUhKJSCgAAoOVm3ysqrVBxWUXLvbBNxONXS1nDc9q0AgDQZIRSkV4pRSgFAADQbNlpyUpOTGidaqkRJ0qp7aRVs6X5n7bsawMAEAcIpSLUmsIyt+7I8D0AAIBmS0hICF7k8y/6tZj0HGnECd7tyQ+37GsDABAHCKUiVF7gSl5uVkq4DwUAACCq+Rf5/It+LWqnwBC+2W9Kaxe1/OsDABDDCKUi1BoanQMAALQI/yLf6sKSln/xrkOk/ntKVZXS1Cda/vUBAIhhhFIRqLKySms3BIbv0VMKAABgs3TKSqtx0a/VqqWmTpDKilvnPQAAiEGEUhFofXG5Kiq9GVw6ZDJ8DwAAoCUqpfKKWmH4nhl8sJTTSypaLf04sXXeAwCAGEQoFcH9pNqlJSstOSnchwMAABAjPaVaqVIqKVna8QzvNg3PAQBoNEKpCOTPDEOTcwAAgM0XnH0vcOGvVexwqpSUKv02VVo8tfXeBwCAGEIoFYH8q3j+VT0AAAA0n9+js9UqpUy7LtKwo7zbUx5pvfcBACCGEEpFIP8qnn9VDwAAAM3nz2bsV6O3mp3P9tY/vCwVrmrd9wIAIAYQSkUgKqUAAABavlKq1UOp3iOlnjtIFSXStKda970AAIgBhFIRiEopAACAVhi+V1SqqipvhuNWr5b65nGporx13wsAgChHKBWB1hZ60xXnZtLoHAAAoKWG75VVVKmgpJWDomFHSpmdpHWLpJ/fbt33AgAgyhFKRSAqpQAAAFpORmqSMlKS3O01gYt/rSYlXdphrHd78sOt+14AAEQ5QqkIRE8pAACAVuorFbj416p2PENKSJTmfyKtnN367wcAQJQilIpAVEoBAAC0rNyslBoX/1pVhy2kwQd7tyc/0vrvBwBAlCKUiuRKKUIpAACAFu0rtbotQimz8zhv/d1/pOL8tnlPAACiDKFUhKmorNLaDX6jc0IpAACwaQ888ICGDx+unJwct4waNUpvvfVWvftPmDBBCQkJNZb09HTFsk7+DHxtFUr130vqvJVUWiB9/3zbvCcAAFGGUCrCrNtQJn+m4g7MvgcAABqhd+/euuWWWzR16lR988032meffXT44Ydr5syZ9T7HwqulS5cGlwULFiiW5bZlTymTkCDtfLZ3+4u7pQ1r2+Z9AQCIIoRSESYvcPUuJz1ZKUn8eAAAwKYdeuihOvjggzVo0CBttdVW+vvf/6527drpq6++qvc5Vh3VvXv34NKtWzfFMn8CmTarlDIjTpQ69JXWLZJev0TBK48AAMAh9YgwawJX7+gnBQAAmqOiokLPPfecCgsL3TC++hQUFKhv377q06fPJquqTElJifLz82ssUVkp1ZahVFo76ZgnpMRkaeYr0rSn2u69AQCIAoRSEca/eteBflIAAKAJZsyY4aqj0tLSdM455+iVV17R0KFD69x38ODBevzxx/Xqq6/qmWeeUWVlpUaPHq3FixfX+/rjx49X+/btg4uFWdHEv+DnXwBsM71HSvv81bv91hXSip/a9v0BAIhghFIRhkopAADQHBY0TZ8+XV9//bXOPfdcnXrqqfrxxx/r3NcqqMaOHavttttOe+21l15++WV16dJFDz30UL2vf+WVV2rdunXBZdGiRYombT77XqjRF0lb7iOVb5BeOkMq29D2xwAAQAQilIoweYXMvAcAAJouNTVVAwcO1MiRI11V04gRI3T33Xc36rkpKSnafvvtNXfu3Hr3sQosf3Y/f4kmndqFoaeULzFROuJBKauLtGKm9G6gcgoAgDhHKBWxlVLMvAcAAJrPhuRZH6jG9qGy4X89evRQrPIv+K3dUKaKyjA0HM/uJh35oHd7yiPSrNfb/hgAAIgwhFIRxm++6TfjBAAA2BQbWvfpp5/q119/deGS3f/444910kknucdtqJ5t891444169913NW/ePE2bNk0nn3yyFixYoLPOOkuxqkOmd8HPJsBbt8GrTG9zA8dIoy/0br96vrSu/h5eAADEg+RwHwBq8kvK/WmLAQAANmXFihUueFq6dKlrQj58+HC988472m+//dzjCxcuVKINIQtYs2aNxo0bp2XLlik3N9cN+Zs0aVK9jdFjQUpSonLSk5VfXO4uAoatf+c+10q/fiEtmSb9d5x06v+kJE7JAQDxiX8BI0xeYPgelVIAAKCxHnvssQYft6qpUHfeeadb4o0FURZKtfkMfKGSU6VjHpMe3FNaOEn69B/S3tVVbAAAxBOG70VqpRShFAAAQIvyL/r57RLCpuMA6feBUPDT26RfPw/v8QAAECaEUpHaUyrQ9wAAAAAto1OkhFJm+LHSdidJVZXeML6ivHAfEQAAbY5QKoKUV1S6kvLQGWIAAADQMvzzq4gIpcxBt0mdBknrl0ivXuB1YQcAII4QSkUQm6LYJCRI7TOolAIAAGhJfnsEv11C2KW18/pLJaVKs9+Qpjwa7iMCAKBNEUpFEP8EyQKp5CR+NAAAAK3SUyqcjc5r6zFC2u9G7/Y7V0vLZoT7iAAAaDMkHxHELyXvyNA9AACAFuefY0VMpZRvl3OkrQ6UKkqkl86QSgvDfUQAALQJQqkI4k9P7F/FAwAAQGtUSnktEyKG9W44/F9Sdg9p1c/SW1eE+4gAAGgThFIRJK/QO0GiyTkAAEDL65jl9ezMKyxRxMnqJB31sCVU0rdPSz/8N9xHBABAqyOUisBKKf+ECQAAAC2nY1aaW68JXAiMOP33lPa8zLv9v0ukNb+G+4gAAGhVhFIR2FOK4XsAAACt11OqoKRcJeUVikh7/UXqs6tUki+9dKZUEaEBGgAALYBQKoL4TTcZvgcAANDystOTlZSY4G6vjbS+Ur6kZOnoR6T09tJv30gf/T3cRwQAQKshlIrE4XuEUgAAAC0uMTFBuZl+X6kIm4EvVIctpMPu9W5/fpf0y0fhPiIAAFoFoVQE8WeCYfgeAABA6/Ar0v0K9Yg19HBp5OmSqqRX/k8qWBnuIwIAoMURSkUQ/+SIRucAAACtw7/4tzrSQylz4Hipy9ZSwXJp4jlSZWW4jwgAgBZFKBVB6CkFAADQujoFQim/bUJES8mQjn1CSk6X5r4vfXV/uI8IAIAWRSgVIUrLK7W+pNzd7sjwPQAAgFatlIronlKhum7tVUyZ92+QfpsW7iMCAKDFEEpFiLWBq3U2IUxOOsP3AAAAWkPHaOkpFcp6S219mFRZJv33TKlkfbiPCACAFkEoFSHyiqqH7tnMMAAAAGjFSqnABDNRISFBOuweqX0fKW+e9Mafwn1EAAC0CEKpCOGXkHcITFMMAACAludPKBNVlVImI1c6+jEpIUn6/nlp+n/CfUQAAGw2QqkIsTZwtY5+UgAAAK3Hn1AmanpKhdpiF+l3V3q3rVpq1dxwHxEAAJuFUCpC+CdGzLwHAADQevwLgFEZSpk9LpX67SGVFUovnS6Vl4T7iAAAaDZCqQjhl5BTKQUAANAGoVRRqaqqqhR1EpOkox6WMjpKy76X3r8+3EcEAECzEUpFWqNzQikAAIBWD6VKyytVVFqhqJTTUzriAe/2V/+Sfn4n3EcEAECzEEpFWqUUw/cAAABaTUZKktKSE6N7CJ8ZfKC0y7ne7YnnSvlLw31EAAA0GaFUhPCnJaZSCgAAoPUkJCQEq6XWBCrVo9Z+N0jdh0tFq6Vnj5Xy5oX7iAAAaBJCqYjrKeVNUwwAAIDWEdUz8IVKTpOOeSLQX2qG9NBe0sxXwn1UAAA0GqFUhGD2PQAAgLYR9TPwheo8UDrnc6nPrlJJvvTiadIbf5LKisN9ZAAAbBKhVITwy8cJpQAAAFpXTIVSpn0v6bQ3pN0v9e5PeVR6bIy0+pdwHxkAAA0ilIoAxWUVwdlf6CkFAADQumKmp1SopGRpzHXSSf+VMjtVD+eb8VK4jwwAgHoRSkWAtYEm50mJCcpJTw734QAAAMRJTynvHCymDBrjDefru5tUul7675nS/y6RyjaE+8gAANgIoVSE9ZOyGWEAAADQevyJZfyJZmJOTk9p7GvSnpfbfIPS1CekR8dIq+aE+8gAAKiBUCoC+KXjzLwHAADQ+vx2CXmxNHyvruF8+1wjnfKylNVFWv6DN5zv+xfCfWQAAAQRSkUAZt4DAABoOx0D51wxWykVast9vOF8/faQygqll8dJr10olRaF+8gAACCUiqxKKUIpAACANquUiodQymR3l8a+Ku31F28437SnpEf3lVbODveRAQDiHKFUJFVKEUoBAAC0uk4hs+9VVlYpLiQmSXtf6YVTWV2lFT9KD/9Omv6fcB8ZACCORUQodf/996tfv35KT0/XLrvsosmTJzfqec8995xrDH7EEUfU2H7aaae57aHLgQceqEjll47nZtJTCgAAoLV1CAzfszwqvzgGZ+BryIC9vOF8/feSyoqkiedIE8+TSgvDfWQAgDgU9lDq+eef16WXXqrrrrtO06ZN04gRI3TAAQdoxYoVDT7v119/1WWXXaY99tijzscthFq6dGlw+c9/IvcqUF6RdzJETykAAIDWl5qcqOy05Pgawhcqu5t0yivS3ldLCYnS9H9Lj+wjrZgV7iMDAMSZsIdSd9xxh8aNG6fTTz9dQ4cO1YMPPqjMzEw9/vjj9T6noqJCJ510km644QYNGDCgzn3S0tLUvXv34JKbm6tItZaeUgAAAG3Kb5vg9/aMOzacb68/S6f+T2rXXVr5k/Tw3tK3z0hVcTKkEQAQ36FUaWmppk6dqjFjxlQfUGKiu//ll1/W+7wbb7xRXbt21ZlnnlnvPh9//LHbZ/DgwTr33HO1evXqevctKSlRfn5+jaUt0VMKAAAgXM3O42z4Xm39dveG89ksfeUbpFfPl145RyopCPeRAQDiQFhDqVWrVrmqp27dutXYbveXLVtW53M+//xzPfbYY3rkkUfqfV0buvfUU0/pgw8+0K233qpPPvlEBx10kHuvuowfP17t27cPLn369FE4ekr50xMDAAA0xQMPPKDhw4crJyfHLaNGjdJbb73V4HNefPFFDRkyxPX03HbbbfXmm28qnnQM9PLMKywJ96GEX7su0kn/lfb5qzec7/vnpEf2lpbPDPeRAQBiXNiH7zXF+vXrdcopp7hAqnPnzvXud8IJJ+iwww5zJ1jWBP3111/XlClTXPVUXa688kqtW7cuuCxatEhtKY/hewAAYDP07t1bt9xyi6tA/+abb7TPPvvo8MMP18yZdYcKkyZN0oknnuiqzr/99lt3vmTLDz/8oHjRMSvNreO+UsqXmCjteZl02htSdk9p1c9en6mpTzKcDwAQm6GUBUtJSUlavnx5je123/pA1fbLL7+4BueHHnqokpOT3WIVUa+99pq7bY/XxfpO2XvNnTu33v5T/pVFf2krG0orVFxW6W4zfA8AADSHnRsdfPDBGjRokLbaaiv9/e9/V7t27fTVV1/Vuf/dd9/tKssvv/xybb311rrpppu0ww476L777lO86JiVEt89perTd7Q3nG/gflJ5sfS/i6SXx0kl68N9ZACAGBTWUCo1NVUjR450w+x8lZWV7r6VnddmJeYzZszQ9OnTg4tVRO29997udn3D7hYvXux6SvXo0UORxq+SSk1KVFZqUrgPBwAARDlrV/Dcc8+psLCwzvMpY707Q3t6Gpv9uKGenuHuwdl6PaUIpTaS1Un6wwvSmOulhCRpxovSw7+TZk6U1v1G5RQAoMV4c+GG0aWXXqpTTz1VO+64o3beeWfddddd7iTKZuMzY8eOVa9evVzfJ+t5sM0229R4focOHdza315QUOBm5Tv66KNdtZVVT/35z3/WwIED3clWpPH7SeVmpSghISHchwMAAKKUXbizEKq4uNhVSb3yyituZuO6WO/OpvT0NHYuZudYscLv5emfi6GO4Xy7/1HaYpT00hnS6rnSi6d6j9lsfb1GSr128JaeO0gZ3jk5AABRFUodf/zxWrlypa699lp3IrTddtvp7bffDp4oLVy40M3I11g2HPD777/Xk08+qbVr16pnz57af//9XVm6DdOLNMGZ92hyDgAANoPNOGyV49Yf86WXXnIX/Wyyl/qCqaayHpx2MdFnlVJtPTlMq1RKMXyvYVvs6g3n++Q2acHn0vIfpYJl0uw3vMXXaWAgqAos3baRUtLDeeQAgCgQ9lDKXHDBBW6pS33NyX0TJkyocT8jI0PvvPOOooXfx4BQCgAAbG5bBKsMN9YewSZ5sd5RDz300Eb7WjV5Y3t6+uziXiRe4Gsuf4KZucsL9PW81dplQKdwH1LkyuwoHXSLd7u0SFo2Q/ptavWyZr5XSWXL9897+yWmSN2G1QyqOg+SEmlXAQCIsFAqnvkl48y8BwAAWpL16bQ+UHWxYX7Ww/OSSy4Jbnvvvffq7UEVi4b3bq+turXTz8sLdMIjX+m8322pS8ZspZSkqJqcuu2lZkpb7OItvqI86bdpXkC1ZJq0+BupaJW0dLq3fPNY4LnZUs/tAsP+AkFVTi+JFhYAELcIpcIsr6gs2FMKAACguUPrDjroIG2xxRZav369nn32WVdt7lePh/boNBdffLH22msv3X777TrkkENcY/RvvvlGDz/8sOJFWnKSXj5vN934v5l64ZvFuv+jX/TZnFW6+4Tt1b9zVrgPL/oqqQaN8RZjjdDXLQqpppomLZkula6Xfv3MW3ztunnhlPWlsrCq724M+wOAOEIoFSmVUgzfAwAAzbRixQoXPC1dulTt27fX8OHDXSC133771dmjc/To0S64uuaaa3TVVVdp0KBBmjhx4kYTysS6dmnJuu2YEfrd4K668uUZ+n7xOh1892e67tChOn6nPkxC01z2vXXYwluGHeltq6yQVs6uOexv+UypYLk0+01vMbn9pENulwbWnB0SABCbEqqqmNO1NmvcaSd01ig0JyenVd/r/Gen6Y3vl7qTn9N369+q7wUAAKLrPCGSxdr3sHTdBv3phe806ZfV7v4Bw7rplqOGBxuioxWE9qeyYX/zPpEKV3iPbXOMdOB4qV3XcB8lAKAVzxMYNB9m9JQCAAAIvx7tM/TMmbvoqoOHKCUpQe/MXK4D7vpUn81ZGe5Di/3+VKPOk45+VLpomrTLuVJCovTDS9J9O0pTJ1iDtHAfKQCglRBKhVleIJRi9j0AAIDwSkxM0Nl7bqlXzttNW3bJ0or1JTrlscn62+s/qqS8ItyHF/vSsr1Z/s76QOoxQipeJ/3vYmnCwdKKn8J9dACAVkAoFWZrigilAAAAIsk2vdrr9Qv30Mm7buHuP/r5fB1+3xf6efn6cB9afLCG52d9KB1ws5SSJS38Unpwd+nDv0llG8J9dACAFkQoFUbWzmtNIbPvAQAARJqM1CT97Yht9ejYHdUpK1U/LVuvQ+/9XE9O+tWdw6GVJSVLo86Xzv9a2uogqbJM+vQf0gOjpXkfh/voAAAthFAqjIpKK1Ra4Y2Rp6cUAABA5BkztJveumQP7bVVF5WUV+q612bqjAlTtHJ9SbgPLT506COd+B/puKel7B5S3jzpqcOll/9PKlwV7qMDAGwmQqkI6CeVlpyojJSkcB8OAAAA6tA1O10TTt9JNxw2TKnJifpo9kodeNen+vCn5eE+tPiQkCANPUw6f7K089m2Qfr+Oa8R+rfP2PCDcB8hAKCZCKUioJ+UVUkl2D+2AAAAiEh2rnbq6H763wW7a0j3bK0uLNUZE77RXyf+oA2lNEFvE+k50sH/8Bqhd9tW2rBGevV8acLvpZU/h/voAADNQCgVRsy8BwAAEF0Gd8/WxPN305m793f3n/5qgQ6973PNXLIu3IcWP3qPlM7+SNrvJiklU1rwufTgbtJH46Wy4nAfHQCgCQilIqRSCgAAANEhPSVJf/39UD11xs7qmp2muSsKdMT9X+jhT39RZSVDydpEUoq020XSeV9JA/eTKkqlT27xwqn5n4X76AAAjUQoFUZ5wZn3CKUAAACizZ5bddHbl+yp/Yd2U1lFlW5+8yed8vjXWraOap02k9tXOulF6dgJUrtu0uq50pO/lyaeJxXlhfvoAACbQCgVRmsCw/c6ZqaE+1AAAADQDFbx/tApIzX+qG3dxDVfzF2tA+76VG/NWBruQ4sf1pt12JFeI/Qdz/QaoU//t9cIffp/aIQOABEsOdwHEM/yAsP3OtBTCkAUqqioUFmZV/EJxJKUlBQlJTErLprWBP3EnbfQLv076uLnpmvGb+t07r+n6bgde+u6Q4cpK41T7jaR0UH6/R3SiBOk/10srfhRmniO9N2z0u/vkjptGe4jBADUwr+QkVApxfA9AFGkqqpKy5Yt09q1a8N9KECr6dChg7p3787suGiSAV3a6b/njtZd7/+sBz75RS98s1iT5+fpvL0Hqn/nLG3RMVNd2qUpMZHfq1bVZ2fp/z6VJt0rfXKrNP9T6V+jpD0vk3a7WEpOC/cRAgACCKUioNE5PaUARBM/kOratasyMzP5ox0xF7oWFRVpxYoV7n6PHj3CfUiIMqnJifrzgUNcv6lLn5+uX1cX6c8vfR98PC05UX06ZrqAypbeuRne7U6Z6pObSVVVS7FG6Htc6g3re+NS6ZcPpY/+Ls14SdrxdKnrUG9p1yXcRwoAcY1/9cJoTaDReUeG7wGIoiF7fiDVqVOncB8O0CoyMjLc2oIp+11nKB+aY9cBnfTWxXvqXx/P1Q9L1mlhXpGWrC1WSXmlm63Plrp0bpeq3rnVoZUtLsTqlKnuOelKosqqaTr2l05+Wfrhv9Lbf5FWzfbWvszOUtetAyGVvx4ipbcP51EDQNwglIqAnlK5WTQ6BxAd/B5SViEFxDL/d9x+5wml0FztM1N05cFbB++XVVRq6dpiF1DZsmhNYB24v7aoTKsKSt0yfdHGQ6RTkhLUq0NGjUorP7TqmpOm3MxUpSQxj9FGrKJ322OkgftKkx+Vlk73+k3lzZeKVkm/fuYtoXJ6S91Cg6qtpc5bSSleaN1mSgqkguVSwYrAOrDYzILdt5EG7ufNQAggNlSUS+uXSusWS4UrpIoyqaLUW1fa7bLNv22v5+6Xe7cP+ae05T5h+8iEUmEcHkBPKQDRiiF7iHX8jqM1WGBkFU+21CW/uMwFVH5I5S0btDgQYJVVVLnhgLbUJzs92Z1bWkBla3/x7qcEt1v7iE5ZqcpJT4mfHlcZudJel1ffLy3yKqdWzPJCKreeJeX/JuUv9pY571bvn5AodRywcWVVxy2lpCb8WWV/CFoYZuHS+pCgyQVPy0ICqBVSad0VdTVYWDZof2ngGKnvaHpmAZHKZgLdsEZat0ha95sXPK2z2/bfm8B9C6SqKtv2uIrzFU6EUmGyvqRc5ZXe9LR2cgAAiD79+vXTJZdc4pbG+Pjjj7X33ntrzZo1rpE2AISygGhYz/Zuqa2iskrL86urrBbXCq7yCktkp5bri8vdsqCB4CqU5VF2LmohlbWUsAr+2qFW8LHMVFf9lZOeHBvBbWqm1HN7bwllfzSu+KlmULViprd99VxvmfW/6v2TUqXOgwMh1dZSl8FSebEXKq2vFTJZ6FS4yv46bfxxpmRK7boFlq5SdncpNUta+LW06Gtp1c/e8uV9UkqWNGAvadB+XhVVhz4t930BaFjZBil/SXXQ5IIn/3YgeCprxH+bE1Ok9r2kdt2l5FTvvzG2zcLvOm8HlgZv2+sk133bgu0wIpQKE79KKjM1SekpDAsAgNa0qT+errvuOl1//fVNft0pU6YoKyur0fuPHj1aS5cuVfv2bderZMiQIZo/f74WLFjgZpMDEJ2sl1TPDhlusX5VtVVWVrlKq9WFpe48M8/WRbYuc+vVBf796rWFVxZk2XNsacqxdMhIUYdMWyysqrm27RZgucczvKDL7kfNOa9VVPUd5S2hFQ4WKlk4VaOy6ieprFBaPsNbGsuqrrK6hIRNIYGTrUO3pWXX/zob1krzPpLmvC/Nfc8Lv2a/6S2my5DqgGqLUd4fuACax/47YMHS8h+9Kks/bPIXq4BsjKyuXujUvrfUvo+3zulVfdv+25AYP0OxCaXCxE4EDFVSAND6LAjyPf/887r22ms1e/bs4LZ27drVGF5tDd2Tkzf9T2SXLk2btSk1NbVNg6HPP/9cGzZs0DHHHKMnn3xSV1xxhcLJ+jOlpNBHEWgNNgTPC4RSpUb+p6m0vFJrLaDyw6rCMnfbD7VCAyxbrOfVhrIKV7VVHWQVNvoY01MSXUjlh1YWVrW30CokxAodWmi326VFSFWWHUN2N28J7b1SWSmtW1gzqFo1x6tkCg2W2gWe62/L7CQltkBIl9HBm2HQFjsWC8ZsyKGFVIsnSyt/8pZJ90qp7aQBv/OG+VlQZX/8Aqi/n5v9/3n5D9JyC6N/9G4Xr2v4eVat6MKmukKnwDolva0+RVQglAoT+wfe0OQcAFpfaBBkVUr2B46/zR9S9+abb+qaa67RjBkz9O6776pPnz669NJL9dVXX6mwsFBbb721xo8frzFjxtQ7fM9e95FHHtEbb7yhd955R7169dLtt9+uww47rM7hexMmTHDPtaDM1osWLdLuu++uJ554Qj169HDPKS8vd8fx1FNPuYbbZ511lpYtW6Z169Zp4sSJDX7uxx57TH/4wx+011576eKLL94olFq8eLEuv/xyd6wlJSXuM95///3aZZdd3OP/+9//dOONN7rvxIK7PfbYQ6+88krws9rtI444Ivh69pnuuusunXbaafr111/Vv39/Pffcc/rXv/6lr7/+Wg8++KAOPfRQXXDBBfr000/d97Dlllvqqquu0oknnhh8ncrKSv3zn//Uww8/7L6Tbt266f/+7/909dVXa5999tHQoUN13333BfdfuXKl+67feust7bvvvs36HQHiUWpyorrmpLulsYrLKlw4ZeeytrZQa03g/roNZS7QWhPYvnZD9eMWZBWXVWpZWbGW5Rc3/hiTEgNDCtNcUBUaWIXe9h+zcKtNZyi0aobcft4y+KC2e9/6jqXHCG/Z83KvGXqwiup9r2nyT697i7F+WC6g2l/aYldvmA/QkkrWS2sXSmsWeOu1C7zhq1YJlNOz5uIPVWtrlRVS3jwvePIXq4hc82vd+ycmS50GebN0dtiiOnTyAyertIyEID2KEEqFiZVSGyqlAEQ7qyyyK+fhkJGS1GJX0P/yl7+4IGTAgAHKzc11YcjBBx+sv//970pLS3OhkAUqVmG1xRZb1Ps6N9xwg2677Tb94x//0L333quTTjrJDZ3r2LFjnfsXFRW593366aeVmJiok08+WZdddpn+/e9/u8dvvfVWd9uCKguN7r77bhdGWbjVkPXr1+vFF190YZAN4bMQ67PPPnPBkikoKHBhlYU5r732mgvppk2b5gIhY8HakUce6YIg++ylpaUuuGvO92rB3Pbbb6/09HQVFxdr5MiRLiDLyclx73PKKae4cGrnnXd2z7nyyitduHfnnXe6kM4q3X766Sf3mIVyFmrZa9rPxTzzzDPuc1hgBaB12RC87u1tSW/SvxPWT3VdILwKhlYh4Za/PbRKy/5tKa2o1PL8Erc0hv2TYEMLQwOr6iXNNXvv3M4CrjR1budtT47VGQszO0rbHO0t9t/2Zd95AZVVUv32TaCy60dp0j1Sara0pVVR7edVUVlIgMaxYVtLv/OCFgsprBIuXkKJ0kJp7SIvbPJDp9AAyvqwNYUNa6sdVmXXum9ViM1lgZirfPoxEED94FUSWg+4ulhQ1m1YzcX6LzGZQIsilAoT+4fYMPMegGhnfzQMvfadsLz3jzceoMzUlvmnzCqC9ttvv+B9C5FGjBgRvH/TTTe5yiALcCwUqY9VCflVPzfffLPuueceTZ48WQceeGC9Q9qsgshCGWOvbcfis2DLQhoLiIxVCDUmHLIKpUGDBmnYsGHu/gknnOAqp/xQ6tlnn3UVRtYXyw/MBg4cGHy+hXH2HAvZfKHfR2NZBdhRRx1VY5uFbr4LL7zQVWq98MILLpSyMM2CN/ucp556qtvHvhsLp4y9ln1Hr776qo477ji3zSrO7HuPiCE+ADZi/9+0Ju629OlY98yDddlQWqHVhSVuWKGt/bDKX0L7Z9ltq9Syli9e5VaZ5q1s3NBCGz7YyQVVqeqcnabOFmi1s9AqTZ3apbrwyrudpqzUlrsY0uZVVH5T970CVVS/fCjNec+rorJeONa83W/g3m0br4rK+lD12sEbgojqIGbBJO/7m/uB11soVHK6F0516Cvl9g1ZB7ZFUyVNWbHXqLt22OTWC6XClZt+jYyOgc++hfc9ZHb2nmezzFlTcDfb5VKpssyr5rNl6fT6Xy+9fUhQ1cOrTqodXtnkAPZzceFTyPA767lWl+QMb5KC0PCp6zApa+P+fWh5hFJhQk8pAIgsO+64Y437Vklkzc+tkscqdWwYnfVnWrhwYYOvM3z48OBta4Ju1UArVqyod//MzMxgIGVs2J6/v1U3LV++PFhBZGwIn1Ua+RVN9Xn88cdd1ZXPbltllIVc2dnZmj59uqteqq+Cyx4fN26cWvp7tX5dFtZZCPXbb7+5CiwbOmjfg5k1a5a7X98wPKu2ssoq+3wWSll11w8//ODCQgCxJSM1Sb1TM9U7t3H7l1dUujDKC6m8MMtmJfTDK1u7xwq8x+12ZUiINbcR75GWnOgCKguqOoWsLdDqku1VYFmQtUXHTGWlJUd2FdW2x3iL/Xuy9NvqZumLvwn8If+D9MVd3v42RMkCLQuoetqynRcOxAPXq+sHL4T65QNp4VdSRWnNpvVdtpZK8r2Axapu/BkR65KWU39gZbc3pxKoIRVl3nC6jZb86ttW2WQhlB9A2WyRm5LWXsoNHL9bQgIo+71Jz2ncd1y0Wlq/pGZQZbeD25ZIpQVeTydbVs5qxpdg0432CwRP20jdhnpr29YSPd7QLBH8X8r46ClFpRSAaGdD6KxiKVzv3VJqz6Jn1TzvvfeeG1pnFUQZGRmuYbiFKA2p3cjbrqg3FCDVtb8NddkcP/74o+uFZRVaoX2kLBCyCioLm+zzNGRTj9d1nFb1tanv1YY1WiWU9Z7adttt3eNWTeV/r5t6X38I33bbbed6YtmwRhu217dv300+D0Bss2F4FgzZIjUwY12A9bnyZyZcXVCilQUlwcDK1qsKSrQqcH/Vem84YUl5pX5bu8Etm9I9J10DumR5S+d22rJrOw3onKVeHTJcY/qIqqLqNdJbfneFVLjaC2CsH9VvU6WVswPT2i+SZoVcALC+Ou55gaCq+7ax08B5/XLv81sllK1rVwRZ2GIN723pv6cX8pnyUil/cSDUqVVdZLetCshCoIZma7RKIj+w8sMdu20VQOUl9QdKm9pevunf2TpZg/waxxIInfxt1my/JX4H29lslF28nmj1Kc7fOKjyF3+bhVsmvUMgeBpWHT7ZbJRp1ZPbIDIQSoW7UopQCkCUs3CipYbQRZIvvvjCDQnzh81Z5ZQ1725L1pTdmnzbELs999wzGCxZdZCFMvWxYXq2vzUtD2UBjj1moZRVdD366KPKy8urs1rKHv/ggw90+umn1zvzYOishnPmzHH9sRrzvR5++OHBKi4L7H7++WfXvNzYkEMLpuy9LXyqi4VZVoFlfadsGGJo03MAaCxriO5VPTUuxCoqLXdhVTC8snVhqVau99Z234KsFetLXJ8sa+huy6RfAn8kh1Rb9e+cpS27tKsRWtk6Oz0Cmo3bkKXhx3qLHwRYz6Ql06TfpnlrC1pWz/GW75+rbgBtzdNDgyoLAZKSo2OY2sIvA9VQH3qVUbVnVOu/R3UQ1Wlg3UPwrFF3xwHeUpfSoppD4KyZdjC8WuBVANlQSlssEGwNNlQtLbvWkuOtrarJArfQMCyShhva8dliTcYb+llaRZXNcBkpx40GRcF/IWKTlRObjgzfA4CIZOHIyy+/7JqbW/D217/+dZND5lqD9VyyWf+sWssaltvwO5u1rr6eJlatZE3TrS/VNttsU+MxC3nuuOMOzZw50/W9smF0Nnuevb4NG/z222/Vs2dPjRo1Stddd50bQmdDC623lA1ftF5WfuWVVSdZGGT7WlBm22tXfdX3vb700kuaNGmSayhvx2NDFP1Qyobn2Wv9+c9/VmpqqnbbbTfX+8qO+cwzz6zxWay3lFVa+cEhALQmuwCT2TG5UX2xrKn7L6sKXF+rX1ba2ru9YHWRq7b6adl6t9TWNTstEFR5VVUWXNnSKzejbWcVDGUhgAUytoQ2jPYDKn9t1UTLvveWqU94+1lvn+7DvZDKwiobAmiBTbjDAqv0tQbXfl+oBV9s3Oy6x3bVIVSfnVumuXVqpheo1BeqbFhbq2F4SLWV9WCy77O+QKmx22N9lkWr1ouVir04QSgVJnmB4Xs2xS0AIPJYWHLGGWdo9OjR6ty5swtK8vPz2/w47H2XLVumsWPHun5SZ599tg444AB3uy7WW2n16tV1BjU2e58tVi1ln+/dd9/Vn/70JzfLoIVOFgz51VW/+93v3Ox91uD9lltucb2x/GotY7PfWRWVNU63IMuG5E2duumrutdcc43mzZvnPoP1kbLPY8GY9c/yWQCYnJysa6+9VkuWLHGB2TnnnFPjdSxUs2F/trYgCwAiSfvMFO2wRa5bave9Wrxmg+YFA6tCF1jZ2q+ysuWreXk1npeanKh+nTIDwwC9yqqBXb0lLL2rsjpLW+3vLX7IY8P7agRV06XS9dKir7zFZ8Oq/P5UFvzY0DdrDm6hT13rpNSWCbFsWKINxfvFlg+94V6hsntUh1ADfud9xrZmQ+Fs6VHdnxKIdQlVm9u4IgbZHx02ZMJOkO0kvDWMvOk9V+b71sV7aOserfMeANDSiouLNX/+fPXv358gIEysWsuCJWvybYFRvLKhlFbFZUMbd9hhhzb9XW+L84RowPcAtCybPXD+Kj+k8kIrW+avLlRpef2Vutajaqtu7TSoW7YGdfXWFla1C3ejdasutuF9oUHVshlSRUkTXyih4dBqo3WtbdaU/NfPvSGICvnT1x7vu1t1EGWzr4W7gguIw/MEKqXCoDLQVNHQ6BwA0JAFCxa4iiabOc9mpbMhcxaW/OEPf1A8suGJVglmFVe77rprqwRSABAO7TNStF2fDm6p3ZD9tzUbgsMB/dBq7ooC14jdb7z+0eyVG4VVFk65wKprtgZ18yqr2qxvlTWv7jLYW7Y7sboR+IqZ1UHV8plenyUbOmdNvK0Zt1uHDqWrCmxvZqPuUNbsesu9vRBqi1FSyqYn1wDQugilwiC/uMxNP2s6ZDJ8DwBQv8TERE2YMMHNBmjFzdYn6v3333fVUvHIGqXvvffe2mqrrVxvKgCIddZLaotOmW7Ze/DGkyfNWb5ec1Z4IdXPgdvWfN0Pqz75uWZY1aN9erCqygKrgYHAKqctwiprBG5D92xRdZ/AjdhgHqtwCoZVda0beiywtqbXVRVe03ULo7K7t/5nBNAkhFJhsKbIa3JuJbVpyS03nTkAIPb06dPHBTFQsNcVnQcAQMFRF7sM6OSWUGuLSl04NWd5geasWB9cL88v0dJ1xW75tFZY1T3HwqrqqioLrazBepd2aUpOSmzbD2bD6NwQvBZoLg4gohFKhYFd0TA0OQcAAADQ0jpkpmqnfh3dUntWwLkrvZDq55DAall+cXD5bM6qjfKhzu3SXGjVzS2B2+3Tg9tsnZORXO/MsABQH0KpMFgTCKU6ZtJPCgAAAEDbzQo4sm9Ht9RuL2LD/9xQQBdWecMBl+cXq7yyyg0HtGXGb9UzpdaWnpLowqmugZCqe/taIZZ7LI2RIgBqIJQKg7xAk/NcmpwDAAAACDPrJ7XDFrluqT1Bk80YbuHU8kAl1fJ1flVViVYEtq0tKlNxWaV+XV3klk0NOfSqq9KCwVVo5ZX1vLKm71RdAfGBUCoMqJQCAAAAEOkSExPUJTvNLdv0al/vfsVlFV5ota5Yy9eXhARXXoi1fL2tS1RaUelamdgya2n975uWnFgjsOrh3w5Zd81OU0pb97oC0OIIpcKASikAAAAAsSI9JUl9O2W5pT42SYVN+OSCq9DKq3yv8bq/3fYpKa/UgtVFbqlP7V5X3dunqUf7jGCQZfftdnZbzCoIoNkIpcJYKZWbyX8gAQAAAMQ+G45nQ/dsGdozp8GqqxVulsANwdBq2bqSQHi1wc0g2JReV5mpSUpNTlRiQoJbrLjKv52YKCW5deCx4G0pKbCt5m17foILxGxt+9vnSklKcDOrd8hMcUMPbckJrGsvbT6TIRDhCKXCIK+wzK2plAKA6PK73/1O2223ne666y53v1+/frrkkkvcUh87WX3llVd0xBFHbNZ7t9TrIDaNHz9eL7/8sn766SdlZGRo9OjRuvXWWzV48OB6nzNhwgSdfvrpNbalpaWpuLi4DY4YAOqvutqiU6Zb6hPa68pVWYX0uvK32f31JeUqKq1wS6TISk3yAqrMVLXPSK4zuKodaNlsijnpyQRaiEmEUmGwJjB8j55SANA2Dj30UJWVlentt9/e6LHPPvtMe+65p7777jsNHz68Sa87ZcoUZWXVP1ShOa6//npNnDhR06dPr7F96dKlys2t2YC2tWzYsEG9evVSYmKifvvtNxdUILJ98sknOv/887XTTjupvLxcV111lfbff3/9+OOPDf6O5uTkaPbs2cH7NBYGEEu9rgpLyl0llVVVVVZVqaLSW6qqpIrA/Sp/e1Vge/C2bffuu9uB/ex1Km27W9t9qbyyUvkbyrRuo6U8uL2gpNw7ptIKtyxZ1/QLAFbxZZVfmSlJyrB1anJg7S0ZKcnVt4PrZLd/9TZvn+DzUrzXsNcGwoFQKoyhFJVSANA2zjzzTB199NFavHixevfuXeOxJ554QjvuuGOTAynTpUsXtZXu3bu32Xv997//1bBhw9xJuAVkxx9/vMLF/SFQUaHkZE5ZGlI7cLUqqK5du2rq1KkudK2PhVBt+bsFAG0pKy3ZLZGgvKJS+cXldQRXZdWBVlHdj1nFlyktr3TLWnkjb1pScmKCC6msKsvazNjahlrakMTckG12223L8rZlpCRxQQObJTL+Hxqvs+8RSgFAm/j973/vAiT7Q/2aa64Jbi8oKNCLL76of/zjH1q9erUuuOACffrpp1qzZo223HJLV21y4okn1vu6tYfvzZkzxwVgkydP1oABA3T33Xdv9JwrrrjCDcOzgMzCgJNOOknXXnutUlJS3PHdcMMNbj//BM9Cs9NOO22j4XszZszQxRdfrC+//FKZmZkudLvjjjvUrl0797g9Z+3atdp99911++23q7S0VCeccIIbemjv1ZDHHntMJ598sguE7HbtUGrmzJnuc9h3ZfvYkEY7dvvOzOOPP+7ec+7cuerYsaM7tvvuu0+//vqr+vfvr2+//dY9x9gxWgXYRx995IZHfvzxx9p777315ptvup+Vfc53331Xffr00aWXXqqvvvpKhYWF2nrrrd2QtTFjxgSPq6SkxH2Xzz77rFasWOGec+WVV+qMM87QoEGDdM455+iyyy4L7m/VaNtvv737uQ0cOFCxZN06r7+Kff8Nsf8P9O3bV5WVldphhx108803u0ASANCybOid31OrOYHW+uJyFZVVaENp9ZDEDYF1UWm5NpT5t6v3CT4e8rzazymrqPLeo7LKhWa2LMxr/LFZhVVuMLhKVW6WH15520JDLltb4/myikrXO8wa2tu6uKxSJeWh67ofq2t7iW0PWdtjVr3WxZrgu9ka09Q1O32j2zZqySruEH6EUm3MSj7Xbgj0lGL4HoBYYLXuZfXPjtOqUjK96Xc2wapsxo4d64KTq6++Ohj4WCBlVTgWPNkf5yNHjnRhiw1peuONN3TKKae4oGXnnXfe5HvYH/VHHXWUunXrpq+//tqFAnX1msrOznbH0bNnTxe4jBs3zm3785//7MKfH374wVW9vP/++27/9u03HpZgocwBBxygUaNGuSGEFsCcddZZLlSz1/ZZ0NOjRw+3toDIXt/CIHvP+vzyyy8u6LL+RBY4/fGPf9SCBQtccGFsOJ9V3liA9OGHH7rv6osvvnBDxswDDzzgwqNbbrlFBx10kPse7PGm+stf/qJ//vOfLtyz0GrRokU6+OCD9fe//90NJ3zqqafcsEwberbFFlu459jP2I79nnvu0YgRIzR//nytWrXK/bwtmLKALzSUsvv2WWItkLLfRfvd22233bTNNtvUu5/1m7IA0aoE7edk37f1orLQsXZFoR/62eLLz89vtc8AAKgZaLnKpFZ4bQuI/LDKhhiu21DqeiDb6J61RaVuNkS3Dm4rc7PJ2zYLtKxyy2s+X/3vQySwYZs/Ls1vsDKsa3aaullYle0FVtW3vdkbu9rsjWnJVIK1MkKpNmYlmPb3m7GyRwCIehZI3dwzPO991RIptXE9nSyUsIoo671jgYofSlgVjwU/toQGFhdeeKHeeecdvfDCC40KpSxEsibT9hwLnIxVnVgwEyq0Ussqrew9n3vuORdKWYNqq3SyEK2hIVVWCWTNqC2Y8fsFWSWShTTW3NqCMWNhjm1PSkrSkCFDdMghh+iDDz5oMJSykMKO2e9fZeGXfU/W68rcf//97ruyY/Yrrrbaaqvg8//2t7/pT3/6k6vi8lmfo6a68cYbtd9++wXvW8WPBU2+m266yVWOvfbaay6M+/nnn93P6r333gtWT1mg5bPKMauisio2+3lajzH7Hi2IiTXWW8rCzc8//7zB/SzUtMVngZRVoD300EPu+63NKtP8Sj4AQGxISUpU+wxbmva3qV24st5YNgrIgioLrPzQyt0u9AKt0G22tuArNSlRaSmJrql9WrK3Tk9JVFpyzXV6cpLbz7u/iX1DHjcrC0pcs3sXmK33Gt/b2mZyXF3o9Rmzvl6b6u1lwxOtssoFWC6s8m5bP7Oc9BQ3PLSdv6TbcFE7Du8Y0DiEUm0sLzB0z2ZPsP8AAADahoUy9ke3hS4WSlnlkDU5t/DDWMWUhUgWbFg1kA13s6oQGxrXGLNmzXLDxfxAyoT+we97/vnnXSWPVSRZdZZVGFm1UVPYe1lAE9rA2qpirELGKof8UMqGYVkg5bOqKavOqo99B08++WSNYYc2jM+CMwt0rPG5DXnbY4896hwCaBVbS5Ys0b777qvNZX2+Qtl3ZcGYVbBZ03f73qwh+8KFC93jdlz2Wffaa686X89+LhbK2c/fQqn//e9/7ud77LHHKpZYQPf666+7oZV1VTs1xH6mNpzR/r9RFxsKaVVwoZVS9jsPAIg/Vj3khzF9Gh4pvlGYFe7KI6sOW1VQomWB0GqFC6tq3y52QxltiOP8VYVuaayUJO+72TiwSla71OrbVoWVFXisXVqS2qVZyJUUfI41pU9KTHBVXbE81JBQqo3R5BxAzLEhdFaxFK73bgLr92QVUFbtY9U/NjTPDzGsisrCGOu5tO2227rAx4ZAWTjVUmxomfWQsmoTq0DyK46s/1JrqB0c2UmgBVf1sSovC+Rq95CysMoqrKxyyaq56tPQY8ZCLf+E1GcVS3WpPWOcBWNWBWWVTTbczt7rmGOOCf58NvXexoY42pDMO++80/387XM2NnSMdPad2u+2VY9ZXy7r3dVU9nO20NKGSdbFhk0yEyMAYHOEO5AyVhzSo32GWxpiQxotnLJlWX6xVrhhit5tC7UKS7whj24JBFjGhjV6VWIt25A+KTHBWxKqgyp/bdv8x2s8FrK9xvOTqh8773dbasd+TUgWWxihVJgqpegnBSBm2MlFI4fQhdtxxx3nhpXZsC0b+nbuuecGT46s79Hhhx/uKoOMhTc2JGzo0KGNem0b9mR9j6yKxyqSjDXlDjVp0iTXm8n6WvmsX1Oo1NRUFw5s6r2sd5T1lvLDGzt+C32sT1BzWVNza4YeenzG+jjZYxZKWf8hq6ayMKl26GW9sWxIogVY1qy8vtkK7Tuyihy/wqkx7PPZELwjjzwyWDlljdN9FiTaz8yGZ4Y2Pw9lYYt9X9b3yvp2WTVRLA3Zs9/rV1991f0cli1b5rZb8OkHdtZzq1evXm4YnrEqwV133dWFfNZw3oJZ+3208A4AgHiXkZqkfp2z3NLYhvQ2pLGwpNwt6wNrC6z88Mrdd2FWmQu11hf726rXtlifr7r6U9vS0o7bsWmV1S2NUKqNbdurve44boQrxQMAtC3r12TVMTYMyYYeWcjhs9nZXnrpJRccWT8lm8lu+fLljQ6lLAix3kqnnnqq++PeXr92uGPvYcPNrDrK+izZUDSrbAlloY416LawxoZfWcBQuzrFqq2uu+469142pG3lypWuSsaqgPyhe01lr2FD2qxHU+3m2BZmWBiUl5fnhofde++9Lryy79FCDwvfbEicBWJ2PDbLXdeuXV1vqvXr17tAyY7PwhELQawJulXy2HC/0B5bDbHvzpqvW98sCxL/+te/1qj6su/Nvg/rHeY3OreAxd7Dwkhjw/vsZ27Hba9X1/DKaGVBm/H7pfn82RuN/e751WrGZpm0/mIWYNnvvDX6t9//xv7OAwCAmg3pm9Ofqy4WPlnlla0rK6tcD6zKqsA6cL+i9lJV37ZKVVQquC6vrPReq8J7zWE9N55Upy2RjLSxnh0ydNQO4U0iASCe2RA+q/qxqpnQ/k8WjsybN88Nq7MhXWeffbaOOOIINytZY9gf+xYw2etbQGMhiYUjBx54YHCfww47zM1mZ8GO9TOyHkcWrvhNxI01XrfwxSqNrHolNFTw2fHZUDur+rJwy+7b8yxIay6/aXpd/aBsmwVKzzzzjC666CI3697ll1/uhj5a0GMz+llPK2PBkDVhtyFyNuSuc+fObpidz3o62XdkAYiFWLfddpv233//TR6ffTYLnKwvmL2mzZJYe/Y3C2auuuoqnXfeeVq9erWblc/uh7L3tt5hp59+umJJ6JDI+tiwvlD2M7IFAABElqREry9VPEioasxZTJyxk1y78mt/iDS1+SwAxDILG6yKx6pc0tPTw304QJNZc3sL2WyoZUNVZQ39rnOe4OF7AAAAm3ueEB/RGwAAiGtWmWZDFK0qzWbca+4wRwAAALSc6sYCAAAAMeo///mPazJvQyJtyCAAAADCj1AKAADEPOvLZbMaTp061c1ABwAAgPAjlAIAAAAAAECbI5QCAAAAAABAmyOUAgA0GRO3ItbxOw4AAND6CKUAAI2WkpLi1kVFReE+FKBV+b/j/u88AAAAWl5yK7wmACBGJSUlqUOHDlqxYoW7n5mZqYSEhHAfFtCiFVIWSNnvuP2u2+88AAAAWgehFACgSbp37+7WfjAFxCILpPzfdQAAALQOQikAQJNYZVSPHj3UtWtXlZWVhftwgBZnQ/aokAIAAGh9hFIAgGaxP9r5wx0AAABAc9HoHAAAAAAAAG2OUAoAAAAAAABtjlAKAAAAAAAAbY6eUvVMB23y8/PDfSgAACDC+OcH/vlCvOJ8CQAAbO75EqFUHdavX+/Wffr0CfehAACACD5faN++veIV50sAAGBzz5cSquL9Ml8dKisrtWTJEmVnZ7upz1sjMbQTuEWLFiknJ0fxIl4/dzx/dj53fH3ueP7s8fq54/Wz26mTnWD17NlTiYnx2wmB86XWEa+fO54/e7x+7nj+7Hzu+Prc8frZqxp5vkSlVB3sC+vdu3erv4/9MsbLL2SoeP3c8fzZ+dzxJ14/e7x+7nj87PFcIeXjfKl1xevnjufPHq+fO54/O587/sTbZ2/fiPOl+L28BwAAAAAAgLAhlAIAAAAAAECbI5QKg7S0NF133XVuHU/i9XPH82fnc8fX547nzx6vnzvePztaV7z+bsXr547nzx6vnzuePzufO74+d7x/9k2h0TkAAAAAAADaHJVSAAAAAAAAaHOEUgAAAAAAAGhzhFIAAAAAAABoc4RSreT+++9Xv379lJ6erl122UWTJ09ucP8XX3xRQ4YMcftvu+22evPNNxVNxo8fr5122knZ2dnq2rWrjjjiCM2ePbvB50yYMEEJCQk1Fvv80eb666/f6HPYzzKWf97Gfr9rf25bzj///Jj7eX/66ac69NBD1bNnT3fcEydOrPG4tea79tpr1aNHD2VkZGjMmDGaM2dOi/93IpI+d1lZma644v/bu/PYKMo/juNfSgtCI2ex5VBuCJTQeBJAY6SEMwEFrSUESjyQcgSiJJhoA4QYDwwm+keFBApGUq5QMDZCLAJRpEA4pCKSQAjGQC1IwBYsJPQx3+eX7m+37ZZt2c7uzLxfycLOzrPbffrdmf302dlnltnXb3Jysm0ze/ZsuXz5ctS3l3ir95w5c+r1YcKECa6vdyR9b2ib18vq1atdXXPEDnmJvOTleivy0v+Rl7yVl/ycmchL0cWgVAvYunWrvP3223Z2/RMnTkhGRoaMHz9eKioqGmz/888/y4wZM+T111+XkydP2oCil19//VXc4uDBg/bNtbS0VL7//nu7Ax43bpzcunWr0ft16NBBrly5ErhcunRJ3Cg9PT2kHz/99FPYtl6otzp27FhIn7Xu6pVXXvFcvfV1rNuxvkE25JNPPpHPP/9cvvzySzly5IgNHbrNV1dXR20/EW/9vn37tn3eeXl59v+dO3faP6ymTJkS1e0lHuutNFAF96GwsLDRx3RDvSPpe3Cf9bJhwwYbmqZPn+7qmiM2yEvkJfKSt+pNXvJXXvJzZiIvRZmefQ/R9cwzz5gFCxYElu/du2d69OhhPvzwwwbbZ2VlmcmTJ4fcNmLECPPWW28Zt6qoqNCzOpqDBw+GbVNQUGA6duxo3G758uUmIyMj4vZerLdavHix6d+/v6mpqfF0vfV1XVRUFFjW/qalpZnVq1cHbrtx44Zp27atKSwsjNp+It763ZCjR4/adpcuXYra9hKP/c7JyTFTp05t0uO4rd6R1lx/D2PGjGm0jdtqDueQl8hLjfFivRV5ibzkxbzk58xEXnpwHCkVZXfv3pXjx4/bw1FrJSQk2OXDhw83eB+9Pbi90tHgcO3d4ObNm/b/Ll26NNquqqpKevfuLY8++qhMnTpVzpw5I26khx7r4Zv9+vWTmTNnyh9//BG2rRfrra/7r7/+Wl577TX7KYDX6x3s4sWLUl5eHlLTjh072kONw9W0OfsJt2z3Wv9OnTpFbXuJVwcOHLBfvRk8eLDk5ubK33//HbatV+v9119/SXFxsT2K4X68UHNEF3npf8hL5CUv1zsYecmfeUn5PTORl+6PQakou3btmty7d09SU1NDbtdl3RE3RG9vSvt4V1NTI0uWLJHRo0fLsGHDwrbTHZMeyrh79277Bq33GzVqlPz555/iJvpmqt//37Nnj+Tn59s33eeee04qKyt9UW+l36O+ceOG/d641+tdV23dmlLT5uwn4p0eeq9zJuhXLfRrB9HaXuKRHob+1Vdfyb59++Tjjz+2X8eZOHGiralf6q02bdpk58WZNm1ao+28UHNEH3mJvERe8na96yIv+S8vKTITeSkSiRG1AppA50rQ7/vf7zuwI0eOtJda+oY7ZMgQWbt2raxatUrcQnestYYPH253KPrp1rZt2yIaEfeC9evX29+Djux7vd6oT+dEycrKshOY6puo17eX7OzswHWduFT70b9/f/tJYGZmpviF/tGkn+LdbwJeL9QcaAnkJf/tC8hL/ua3vKTITOSlSHCkVJSlpKRI69at7WF6wXQ5LS2twfvo7U1pH88WLlwo3377rezfv1969erVpPsmJSXJ448/LufPnxc300NxBw0aFLYfXqq30sk3S0pK5I033vBlvWvr1pSaNmc/Ee8BS18HOnlrY5/6NWd7cQM9xFprGq4PXqp3rR9//NFO1NrU7d4rNceDIy+Rl8hL/qo3eYm85MfMRF6KDINSUdamTRt58skn7SGKtfSwW10O/tQjmN4e3F7pzipc+3ikI/4asIqKiuSHH36Qvn37Nvkx9FDNsrIye5pYN9N5AC5cuBC2H16od7CCggL7PfHJkyf7st76Wtc3yeCa/vPPP/asMuFq2pz9RDwHLP3+uwbtrl27Rn17cQP9SoXOjxCuD16pd91P+7VPeuYZP9YcD468RF4iL/mr3uQl8pIfMxN5KUJRmCwddWzZssWeSWLjxo3mt99+M3PnzjWdOnUy5eXldv2sWbPMu+++G2h/6NAhk5iYaD799FNz9uxZO/N+UlKSKSsrM26Rm5trzxRy4MABc+XKlcDl9u3bgTZ1+71y5Uqzd+9ec+HCBXP8+HGTnZ1tHnroIXPmzBnjJu+8847t98WLF20tx44da1JSUuwZdbxa7+CzYTz22GNm2bJl9dZ5qd6VlZXm5MmT9qK7zTVr1tjrtWdN+eijj+w2vnv3bnP69Gl7ho2+ffuaf//9N/AYesaNL774IuL9RLz3++7du2bKlCmmV69e5tSpUyHb/Z07d8L2+37bS7z3W9ctXbrUHD582PahpKTEPPHEE2bgwIGmurra1fWO5LWubt68adq3b2/y8/MbfAw31hyxQV4iL5GXvFVv8pK/8pKfMxN5KboYlGoh+gLTN582bdrY01qWlpYG1j3//PP29JjBtm3bZgYNGmTbp6enm+LiYuMmujE2dNHT2obr95IlSwK/o9TUVDNp0iRz4sQJ4zavvvqq6d69u+1Hz5497fL58+c9Xe9aGpq0zufOnau3zkv13r9/f4Ov79r+6WmO8/LybL/0TTQzM7Pe76R37942UEe6n4j3fusbZrjtXu8Xrt/3217ivd/6h+O4ceNMt27d7B9H2r8333yzXlByY70jea2rtWvXmnbt2tlTeTfEjTVH7JCXyEternct8hJ5yYt5yc+ZibwUXa30n0iPqgIAAAAAAACigTmlAAAAAAAA4DgGpQAAAAAAAOA4BqUAAAAAAADgOAalAAAAAAAA4DgGpQAAAAAAAOA4BqUAAAAAAADgOAalAAAAAAAA4DgGpQAAAAAAAOA4BqUAoIW0atVKdu3aFeunAQAAELfIS4C/MSgFwJPmzJljQ07dy4QJE2L91AAAAOICeQlArCXG+gkAQEvRQFVQUBByW9u2bWP2fAAAAOINeQlALHGkFADP0kCVlpYWcuncubNdp58C5ufny8SJE6Vdu3bSr18/2bFjR8j9y8rKZMyYMXZ9165dZe7cuVJVVRXSZsOGDZKenm5/Vvfu3WXhwoUh669duyYvvfSStG/fXgYOHCjffPONAz0HAACIDHkJQCwxKAXAt/Ly8mT69Onyyy+/yMyZMyU7O1vOnj1r1926dUvGjx9vQ9mxY8dk+/btUlJSEhKiNKQtWLDAhi8NZBqgBgwYEPIzVq5cKVlZWXL69GmZNGmS/TnXr193vK8AAADNQV4C0KIMAHhQTk6Oad26tUlOTg65fPDBB3a97v7mzZsXcp8RI0aY3Nxce33dunWmc+fOpqqqKrC+uLjYJCQkmPLycrvco0cP895774V9Dvoz3n///cCyPpbe9t1330W9vwAAAE1FXgIQa8wpBcCzXnjhBfvpXLAuXboEro8cOTJknS6fOnXKXtdPADMyMiQ5OTmwfvTo0VJTUyPnzp2zh7NfvnxZMjMzG30Ow4cPD1zXx+rQoYNUVFQ8cN8AAACigbwEIJYYlALgWRpq6h4eHi06b0IkkpKSQpY1nGlQAwAAiAfkJQCxxJxSAHyrtLS03vKQIUPsdf1f507QuRJqHTp0SBISEmTw4MHy8MMPS58+fWTfvn2OP28AAACnkJcAtCSOlALgWXfu3JHy8vKQ2xITEyUlJcVe18k4n3rqKXn22Wdl8+bNcvToUVm/fr1dpxNsLl++XHJycmTFihVy9epVWbRokcyaNUtSU1NtG7193rx58sgjj9iz0lRWVtogpu0AAADcgLwEIJYYlALgWXv27LGnHQ6mn9r9/vvvgTO9bNmyRebPn2/bFRYWytChQ+06PSXx3r17ZfHixfL000/bZT3zzJo1awKPpQGsurpaPvvsM1m6dKkNby+//LLDvQQAAGg+8hKAWGqls53H9BkAQAzoXAVFRUXy4osvxvqpAAAAxCXyEoCWxpxSAAAAAAAAcByDUgAAAAAAAHAcX98DAAAAAACA4zhSCgAAAAAAAI5jUAoAAAAAAACOY1AKAAAAAAAAjmNQCgAAAAAAAI5jUAoAAAAAAACOY1AKAAAAAAAAjmNQCgAAAAAAAI5jUAoAAAAAAACOY1AKAAAAAAAA4rT/ABY3UXJhnIHEAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting Training and Validation Accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting Training and Validation Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "43e978d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Predicted Answer: <No Prediction>\n"
     ]
    }
   ],
   "source": [
    "# Create index_to_word dictionary\n",
    "index_to_word = {index: word for word, index in tokenizer.word_index.items()}\n",
    "index_to_word[0] = \"<PAD>\"\n",
    "index_to_word[1] = \"<OOV>\"\n",
    "\n",
    "def preprocess_question(question, tokenizer, max_len):\n",
    "    \"\"\"Preprocess the input question to convert it into a padded sequence.\"\"\"\n",
    "    question = preprocess(question)  # Apply same preprocessing as training data\n",
    "    seq = tokenizer.texts_to_sequences([question])\n",
    "    padded_seq = pad_sequences(seq, maxlen=max_len, padding='post')\n",
    "    return padded_seq\n",
    "\n",
    "def predict_answer(question, tokenizer, max_len, model, index_to_word):\n",
    "    \"\"\"Predict answer for a given question.\"\"\"\n",
    "    input_seq = preprocess_question(question, tokenizer, max_len)\n",
    "    answer = []\n",
    "    max_answer_len = max_len  # Limit answer length\n",
    "    \n",
    "    for _ in range(max_answer_len):\n",
    "        predicted_probs = model.predict(input_seq, verbose=0)\n",
    "        predicted_token = np.argmax(predicted_probs[0, -1, :])\n",
    "        print(np.argmax(predicted_probs[:,-1]))\n",
    "        if predicted_token == 0:  # Stop at padding token\n",
    "            break\n",
    "            \n",
    "        word = index_to_word.get(predicted_token, \"<OOV>\")\n",
    "        if word == \"<OOV>\":  # Stop if we hit unknown word\n",
    "            break\n",
    "            \n",
    "        answer.append(word)\n",
    "        \n",
    "        # Update input sequence\n",
    "        input_seq = np.roll(input_seq, -1)\n",
    "        input_seq[0, -1] = predicted_token\n",
    "    \n",
    "    return ' '.join(answer) if answer else \"<No Prediction>\"\n",
    "\n",
    "# Example usage\n",
    "question = \"What is the purpose of the restoration indicators in the VLR?\"\n",
    "predicted_answer = predict_answer(question, tokenizer, max_len, model, index_to_word)\n",
    "print(\"Predicted Answer:\", predicted_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
